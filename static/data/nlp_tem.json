{
  "api templates": {
    "fir": [
      {
        "cat_Preprocessing": {
          "color": "rgb(246, 183, 60)",
          "num": 29,
          "codes": [
            "fir_4.py",
            "fir_16.py",
            "fir_17.py",
            "fir_23.py",
            "fir_1.py",
            "fir_2.py",
            "fir_3.py",
            "fir_6.py",
            "fir_8.py",
            "fir_9.py",
            "fir_10.py",
            "fir_11.py",
            "fir_12.py",
            "fir_13.py",
            "fir_14.py",
            "fir_18.py",
            "fir_19.py",
            "fir_20.py",
            "fir_21.py",
            "fir_25.py",
            "fir_29.py",
            "fir_30.py",
            "fir_24.py",
            "fir_5.py",
            "fir_7.py",
            "fir_28.py",
            "fir_22.py",
            "fir_27.py",
            "fir_26.py"
          ]
        }
      },
      {
        "fea_parsing": {
          "color": "rgb(246, 183, 60)",
          "num": 4,
          "codes": [
            "fir_4.py",
            "fir_16.py",
            "fir_17.py",
            "fir_23.py"
          ]
        }
      },
      {
        "fea_tokenization": {
          "color": "rgb(246, 183, 60)",
          "num": 22,
          "codes": [
            "fir_4.py",
            "fir_16.py",
            "fir_17.py",
            "fir_23.py",
            "fir_1.py",
            "fir_2.py",
            "fir_3.py",
            "fir_6.py",
            "fir_8.py",
            "fir_9.py",
            "fir_10.py",
            "fir_11.py",
            "fir_12.py",
            "fir_13.py",
            "fir_14.py",
            "fir_18.py",
            "fir_19.py",
            "fir_20.py",
            "fir_21.py",
            "fir_25.py",
            "fir_29.py",
            "fir_30.py"
          ]
        }
      },
      {
        "fea_lemmatization": {
          "color": "rgb(246, 183, 60)",
          "num": 12,
          "codes": [
            "fir_4.py",
            "fir_1.py",
            "fir_3.py",
            "fir_6.py",
            "fir_9.py",
            "fir_10.py",
            "fir_12.py",
            "fir_14.py",
            "fir_25.py",
            "fir_29.py",
            "fir_30.py",
            "fir_24.py"
          ]
        }
      },
      {
        "fea_word_vectors": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_nlp_datasets": {
          "color": "rgb(246, 183, 60)",
          "num": 16,
          "codes": [
            "fir_1.py",
            "fir_2.py",
            "fir_3.py",
            "fir_8.py",
            "fir_9.py",
            "fir_12.py",
            "fir_13.py",
            "fir_14.py",
            "fir_20.py",
            "fir_21.py",
            "fir_29.py",
            "fir_30.py",
            "fir_24.py",
            "fir_5.py",
            "fir_7.py",
            "fir_28.py"
          ]
        }
      },
      {
        "fea_stemming": {
          "color": "rgb(246, 183, 60)",
          "num": 4,
          "codes": [
            "fir_2.py",
            "fir_8.py",
            "fir_20.py",
            "fir_21.py"
          ]
        }
      },
      {
        "fea_regular_expression": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "fir_5.py"
          ]
        }
      },
      {
        "fea_word_frequency": {
          "color": "rgb(246, 183, 60)",
          "num": 3,
          "codes": [
            "fir_24.py",
            "fir_22.py",
            "fir_27.py"
          ]
        }
      },
      {
        "fea_tagger": {
          "color": "rgb(246, 183, 60)",
          "num": 3,
          "codes": [
            "fir_4.py",
            "fir_6.py",
            "fir_27.py"
          ]
        }
      },
      {
        "fea_text_simplify": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_n_grams": {
          "color": "rgb(246, 183, 60)",
          "num": 2,
          "codes": [
            "fir_6.py",
            "fir_26.py"
          ]
        }
      },
      {
        "cat_Basic_Analysis": {
          "color": "rgb(246, 183, 60)",
          "num": 14,
          "codes": [
            "fir_4.py",
            "fir_6.py",
            "fir_11.py",
            "fir_12.py",
            "fir_16.py",
            "fir_17.py",
            "fir_23.py",
            "fir_24.py",
            "fir_30.py",
            "fir_19.py",
            "fir_8.py",
            "fir_20.py",
            "fir_21.py",
            "fir_29.py"
          ]
        }
      },
      {
        "fea_Part_of_Speech": {
          "color": "rgb(246, 183, 60)",
          "num": 9,
          "codes": [
            "fir_4.py",
            "fir_6.py",
            "fir_11.py",
            "fir_12.py",
            "fir_16.py",
            "fir_17.py",
            "fir_23.py",
            "fir_24.py",
            "fir_30.py"
          ]
        }
      },
      {
        "fea_named_entity_recognition": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "fir_4.py"
          ]
        }
      },
      {
        "fea_dependency_parsing": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "fir_4.py"
          ]
        }
      },
      {
        "fea_spellcheck": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_text_similarity": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "fir_19.py"
          ]
        }
      },
      {
        "fea_text_scoring": {
          "color": "rgb(246, 183, 60)",
          "num": 4,
          "codes": [
            "fir_8.py",
            "fir_20.py",
            "fir_21.py",
            "fir_29.py"
          ]
        }
      },
      {
        "cat_Advanced_Analysis": {
          "color": "rgb(246, 183, 60)",
          "num": 10,
          "codes": [
            "fir_28.py",
            "fir_15.py",
            "fir_22.py",
            "fir_24.py",
            "fir_27.py",
            "fir_30.py",
            "fir_9.py",
            "fir_3.py",
            "fir_8.py",
            "fir_21.py"
          ]
        }
      },
      {
        "fea_sentiment_analysis": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "fir_28.py"
          ]
        }
      },
      {
        "fea_translation": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_language_detection": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_classification": {
          "color": "rgb(246, 183, 60)",
          "num": 6,
          "codes": [
            "fir_28.py",
            "fir_15.py",
            "fir_22.py",
            "fir_24.py",
            "fir_27.py",
            "fir_30.py"
          ]
        }
      },
      {
        "fea_chatbot": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "fir_9.py"
          ]
        }
      },
      {
        "fea_summarizer": {
          "color": "rgb(246, 183, 60)",
          "num": 3,
          "codes": [
            "fir_3.py",
            "fir_8.py",
            "fir_21.py"
          ]
        }
      },
      {
        "fea_text_segmentation": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      }
    ],
    "sec": [
      {
        "cat_Preprocessing": {
          "color": "rgb(246, 183, 60)",
          "num": 9,
          "codes": [
            "sec_7.py",
            "sec_10.py",
            "sec_2.py",
            "sec_12.py",
            "sec_6.py",
            "sec_9.py",
            "sec_27.py",
            "sec_1.py",
            "sec_8.py"
          ]
        }
      },
      {
        "fea_parsing": {
          "color": "rgb(246, 183, 60)",
          "num": 2,
          "codes": [
            "sec_7.py",
            "sec_10.py"
          ]
        }
      },
      {
        "fea_tokenization": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_lemmatization": {
          "color": "rgb(246, 183, 60)",
          "num": 2,
          "codes": [
            "sec_2.py",
            "sec_12.py"
          ]
        }
      },
      {
        "fea_word_vectors": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_nlp_datasets": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_stemming": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_regular_expression": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_word_frequency": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_tagger": {
          "color": "rgb(246, 183, 60)",
          "num": 2,
          "codes": [
            "sec_10.py",
            "sec_6.py"
          ]
        }
      },
      {
        "fea_text_simplify": {
          "color": "rgb(246, 183, 60)",
          "num": 3,
          "codes": [
            "sec_2.py",
            "sec_9.py",
            "sec_27.py"
          ]
        }
      },
      {
        "fea_n_grams": {
          "color": "rgb(246, 183, 60)",
          "num": 3,
          "codes": [
            "sec_27.py",
            "sec_1.py",
            "sec_8.py"
          ]
        }
      },
      {
        "cat_Basic_Analysis": {
          "color": "rgb(246, 183, 60)",
          "num": 6,
          "codes": [
            "sec_2.py",
            "sec_6.py",
            "sec_12.py",
            "sec_17.py",
            "sec_26.py",
            "sec_29.py"
          ]
        }
      },
      {
        "fea_Part_of_Speech": {
          "color": "rgb(246, 183, 60)",
          "num": 2,
          "codes": [
            "sec_2.py",
            "sec_6.py"
          ]
        }
      },
      {
        "fea_named_entity_recognition": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_dependency_parsing": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_spellcheck": {
          "color": "rgb(246, 183, 60)",
          "num": 2,
          "codes": [
            "sec_12.py",
            "sec_17.py"
          ]
        }
      },
      {
        "fea_text_similarity": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_text_scoring": {
          "color": "rgb(246, 183, 60)",
          "num": 2,
          "codes": [
            "sec_26.py",
            "sec_29.py"
          ]
        }
      },
      {
        "cat_Advanced_Analysis": {
          "color": "rgb(246, 183, 60)",
          "num": 21,
          "codes": [
            "sec_15.py",
            "sec_20.py",
            "sec_21.py",
            "sec_24.py",
            "sec_25.py",
            "sec_26.py",
            "sec_28.py",
            "sec_29.py",
            "sec_30.py",
            "sec_12.py",
            "sec_14.py",
            "sec_16.py",
            "sec_19.py",
            "sec_22.py",
            "sec_23.py",
            "sec_11.py",
            "sec_18.py",
            "sec_4.py",
            "sec_5.py",
            "sec_9.py",
            "sec_13.py"
          ]
        }
      },
      {
        "fea_sentiment_analysis": {
          "color": "rgb(246, 183, 60)",
          "num": 9,
          "codes": [
            "sec_15.py",
            "sec_20.py",
            "sec_21.py",
            "sec_24.py",
            "sec_25.py",
            "sec_26.py",
            "sec_28.py",
            "sec_29.py",
            "sec_30.py"
          ]
        }
      },
      {
        "fea_translation": {
          "color": "rgb(246, 183, 60)",
          "num": 6,
          "codes": [
            "sec_12.py",
            "sec_14.py",
            "sec_16.py",
            "sec_19.py",
            "sec_22.py",
            "sec_23.py"
          ]
        }
      },
      {
        "fea_language_detection": {
          "color": "rgb(246, 183, 60)",
          "num": 5,
          "codes": [
            "sec_12.py",
            "sec_19.py",
            "sec_23.py",
            "sec_11.py",
            "sec_18.py"
          ]
        }
      },
      {
        "fea_classification": {
          "color": "rgb(246, 183, 60)",
          "num": 5,
          "codes": [
            "sec_20.py",
            "sec_4.py",
            "sec_5.py",
            "sec_9.py",
            "sec_13.py"
          ]
        }
      },
      {
        "fea_chatbot": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_summarizer": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_text_segmentation": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      }
    ],
    "thr": [
      {
        "cat_Preprocessing": {
          "color": "rgb(246, 183, 60)",
          "num": 15,
          "codes": [
            "thr_17.py",
            "thr_10.py",
            "thr_12.py",
            "thr_18.py",
            "thr_20.py",
            "thr_27.py",
            "thr_22.py",
            "thr_26.py",
            "thr_13.py",
            "thr_5.py",
            "thr_6.py",
            "thr_25.py",
            "thr_24.py",
            "thr_11.py",
            "thr_19.py"
          ]
        }
      },
      {
        "fea_parsing": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_17.py"
          ]
        }
      },
      {
        "fea_tokenization": {
          "color": "rgb(246, 183, 60)",
          "num": 5,
          "codes": [
            "thr_10.py",
            "thr_12.py",
            "thr_18.py",
            "thr_20.py",
            "thr_27.py"
          ]
        }
      },
      {
        "fea_lemmatization": {
          "color": "rgb(246, 183, 60)",
          "num": 4,
          "codes": [
            "thr_17.py",
            "thr_12.py",
            "thr_22.py",
            "thr_26.py"
          ]
        }
      },
      {
        "fea_word_vectors": {
          "color": "rgb(246, 183, 60)",
          "num": 2,
          "codes": [
            "thr_17.py",
            "thr_13.py"
          ]
        }
      },
      {
        "fea_nlp_datasets": {
          "color": "rgb(246, 183, 60)",
          "num": 3,
          "codes": [
            "thr_17.py",
            "thr_5.py",
            "thr_6.py"
          ]
        }
      },
      {
        "fea_stemming": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_regular_expression": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_27.py"
          ]
        }
      },
      {
        "fea_word_frequency": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_25.py"
          ]
        }
      },
      {
        "fea_tagger": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_24.py"
          ]
        }
      },
      {
        "fea_text_simplify": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_27.py"
          ]
        }
      },
      {
        "fea_n_grams": {
          "color": "rgb(246, 183, 60)",
          "num": 3,
          "codes": [
            "thr_24.py",
            "thr_11.py",
            "thr_19.py"
          ]
        }
      },
      {
        "cat_Basic_Analysis": {
          "color": "rgb(246, 183, 60)",
          "num": 6,
          "codes": [
            "thr_12.py",
            "thr_24.py",
            "thr_18.py",
            "thr_8.py",
            "thr_10.py",
            "thr_7.py"
          ]
        }
      },
      {
        "fea_Part_of_Speech": {
          "color": "rgb(246, 183, 60)",
          "num": 2,
          "codes": [
            "thr_12.py",
            "thr_24.py"
          ]
        }
      },
      {
        "fea_named_entity_recognition": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_18.py"
          ]
        }
      },
      {
        "fea_dependency_parsing": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_spellcheck": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_8.py"
          ]
        }
      },
      {
        "fea_text_similarity": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_10.py"
          ]
        }
      },
      {
        "fea_text_scoring": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_7.py"
          ]
        }
      },
      {
        "cat_Advanced_Analysis": {
          "color": "rgb(246, 183, 60)",
          "num": 4,
          "codes": [
            "thr_7.py",
            "thr_9.py",
            "thr_17.py",
            "thr_6.py"
          ]
        }
      },
      {
        "fea_sentiment_analysis": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_7.py"
          ]
        }
      },
      {
        "fea_translation": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_language_detection": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_9.py"
          ]
        }
      },
      {
        "fea_classification": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_17.py"
          ]
        }
      },
      {
        "fea_chatbot": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      },
      {
        "fea_summarizer": {
          "color": "rgb(246, 183, 60)",
          "num": 1,
          "codes": [
            "thr_6.py"
          ]
        }
      },
      {
        "fea_text_segmentation": {
          "color": "#12232E",
          "num": 0,
          "codes": []
        }
      }
    ]
  },
  "all templates": [
    {
      "name": "cat_Preprocessing",
      "color": "",
      "fir": 29,
      "sec": 9,
      "thr": 15
    },
    {
      "name": "fea_parsing",
      "color": "",
      "fir": 4,
      "sec": 2,
      "thr": 1
    },
    {
      "name": "fea_tokenization",
      "color": "",
      "fir": 22,
      "sec": 0,
      "thr": 5
    },
    {
      "name": "fea_lemmatization",
      "color": "",
      "fir": 12,
      "sec": 2,
      "thr": 4
    },
    {
      "name": "fea_word_vectors",
      "color": "",
      "fir": 0,
      "sec": 0,
      "thr": 2
    },
    {
      "name": "fea_nlp_datasets",
      "color": "",
      "fir": 16,
      "sec": 0,
      "thr": 3
    },
    {
      "name": "fea_stemming",
      "color": "",
      "fir": 4,
      "sec": 0,
      "thr": 0
    },
    {
      "name": "fea_regular_expression",
      "color": "",
      "fir": 1,
      "sec": 0,
      "thr": 1
    },
    {
      "name": "fea_word_frequency",
      "color": "",
      "fir": 3,
      "sec": 0,
      "thr": 1
    },
    {
      "name": "fea_tagger",
      "color": "",
      "fir": 3,
      "sec": 2,
      "thr": 1
    },
    {
      "name": "fea_text_simplify",
      "color": "",
      "fir": 0,
      "sec": 3,
      "thr": 1
    },
    {
      "name": "fea_n_grams",
      "color": "",
      "fir": 2,
      "sec": 3,
      "thr": 3
    },
    {
      "name": "cat_Basic_Analysis",
      "color": "",
      "fir": 14,
      "sec": 6,
      "thr": 6
    },
    {
      "name": "fea_Part_of_Speech",
      "color": "",
      "fir": 9,
      "sec": 2,
      "thr": 2
    },
    {
      "name": "fea_named_entity_recognition",
      "color": "",
      "fir": 1,
      "sec": 0,
      "thr": 1
    },
    {
      "name": "fea_dependency_parsing",
      "color": "",
      "fir": 1,
      "sec": 0,
      "thr": 0
    },
    {
      "name": "fea_spellcheck",
      "color": "",
      "fir": 0,
      "sec": 2,
      "thr": 1
    },
    {
      "name": "fea_text_similarity",
      "color": "",
      "fir": 1,
      "sec": 0,
      "thr": 1
    },
    {
      "name": "fea_text_scoring",
      "color": "",
      "fir": 4,
      "sec": 2,
      "thr": 1
    },
    {
      "name": "cat_Advanced_Analysis",
      "color": "",
      "fir": 10,
      "sec": 21,
      "thr": 4
    },
    {
      "name": "fea_sentiment_analysis",
      "color": "",
      "fir": 1,
      "sec": 9,
      "thr": 1
    },
    {
      "name": "fea_translation",
      "color": "",
      "fir": 0,
      "sec": 6,
      "thr": 0
    },
    {
      "name": "fea_language_detection",
      "color": "",
      "fir": 0,
      "sec": 5,
      "thr": 1
    },
    {
      "name": "fea_classification",
      "color": "",
      "fir": 6,
      "sec": 5,
      "thr": 1
    },
    {
      "name": "fea_chatbot",
      "color": "",
      "fir": 1,
      "sec": 0,
      "thr": 0
    },
    {
      "name": "fea_summarizer",
      "color": "",
      "fir": 3,
      "sec": 0,
      "thr": 1
    },
    {
      "name": "fea_text_segmentation",
      "color": "",
      "fir": 0,
      "sec": 0,
      "thr": 0
    }
  ],
  "labeled files": {
    "fir_4.py": "<div class=\"codeBlock hljs python\" id=\"fir_4\"><pre id=\"fir_4_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">from</span> nltk.parse.stanford <span class=\"hljs-keyword\">import</span> StanfordParser, StanfordDependencyParser\n<span class=\"hljs-keyword\">from</span> nltk.tag.stanford <span class=\"hljs-keyword\">import</span> StanfordPOSTagger\n<span class=\"hljs-keyword\">from</span> nltk.tag <span class=\"hljs-keyword\">import</span> StanfordNERTagger\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize, sent_tokenize\n<span class=\"hljs-keyword\">from</span> nltk.stem <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> wordnet\n<span class=\"hljs-keyword\">from</span> config <span class=\"hljs-keyword\">import</span> *\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Text_processing</span>:</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span>\n\t\t\n\t\t<span class=\"hljs-comment\"># user need to download Stanford Parser, NER and POS tagger from stanford website</span>\n\t\t<div style=\"display: inline;\" id=\"parsing_0\" class=\"highlights fea_parsing\">self.constituent_parse_tree = StanfordParser()</div>  <span class=\"hljs-comment\">#user need to set as environment variable</span>\n\t\t<div style=\"display: inline;\" id=\"parsing_1\" class=\"highlights fea_parsing\">self.stanford_dependency = StanfordDependencyParser()</div> <span class=\"hljs-comment\">#user need to set as environment variable</span>\n\t\t<div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">self.lemma = WordNetLemmatizer()</div>\n\t\tself.home = <span class=\"hljs-string\">'/home/ramesh'</span>\n\t\t<span class=\"hljs-comment\">#user needs to download stanford packages and change directory</span>\n\t\t<div style=\"display: inline;\" id=\"tagger_0\" class=\"highlights fea_tagger\">self.ner = StanfordNERTagger(self.home + <span class=\"hljs-string\">'/stanford-ner-2017-06-09/classifiers/english.all.3class.distsim.crf.ser.gz'</span>,self.home + <span class=\"hljs-string\">'/stanford-ner-2017-06-09/stanford-ner.jar'</span>)</div>\n\t\t<div style=\"display: inline;\" id=\"tagger_1\" class=\"highlights fea_tagger\">self.pos_tag = StanfordPOSTagger(self.home + <span class=\"hljs-string\">'/stanford-postagger-2017-06-09/models/english-bidirectional-distsim.tagger'</span>,self.home + <span class=\"hljs-string\">'/stanford-postagger-2017-06-09/stanford-postagger-3.8.0.jar'</span>)</div>\n\t\tself.CharacterOffsetEnd = <span class=\"hljs-number\">0</span> \n\t\tself.CharacterOffsetBegin = <span class=\"hljs-number\">0</span>\n\t\t\n\n\t<span class=\"hljs-string\">'''\n\tInput: sentence\n\tReturns: \n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">parser</span>(<span class=\"hljs-params\">self,sentence</span>):</span>\n\n\n\t\tself.parseResult = {<span class=\"hljs-string\">'parseTree'</span>:[], <span class=\"hljs-string\">'text'</span>:[], <span class=\"hljs-string\">'dependencies'</span>:[],<span class=\"hljs-string\">'words'</span>:[] }\n\t\tparseText, sentences = self.get_parseText(sentence)\n\t\t<span class=\"hljs-comment\"># print \"sentences \", sentences</span>\n\t\t<span class=\"hljs-comment\"># if source/target sent consist of 1 sentence </span>\n\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(sentences) == <span class=\"hljs-number\">1</span>:\n\t\t\t<span class=\"hljs-keyword\">return</span> parseText\n\t\t\n\t\twordOffSet = <span class=\"hljs-number\">0</span> <span class=\"hljs-comment\"># offset is number of words in first sentence </span>\n\n\t\t<span class=\"hljs-comment\"># if source/target sentence has more than 1 sentence</span>\n\n\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(parseText[<span class=\"hljs-string\">'text'</span>])):\n\t\t\t<span class=\"hljs-keyword\">if</span> i &gt; <span class=\"hljs-number\">0</span>:\n\n\t\t\t\t<span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(parseText[<span class=\"hljs-string\">'dependencies'</span>][i])):\n\t\t\t\t\t<span class=\"hljs-comment\"># [root, Root-0, dead-4]</span>\n\t\t\t\t\t<span class=\"hljs-keyword\">for</span> k <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">3</span>):\n\t\t\t\t\t\ttokens = parseText[<span class=\"hljs-string\">'dependencies'</span>][i][j][k].split(<span class=\"hljs-string\">'-'</span>)\n\n\t\t\t\t\t\t<span class=\"hljs-keyword\">if</span> tokens[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'Root'</span>:\n\t\t\t\t\t\t\tnewWordIndex = <span class=\"hljs-number\">0</span>\n\n\t\t\t\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\t\t\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> tokens[<span class=\"hljs-built_in\">len</span>(tokens)-<span class=\"hljs-number\">1</span>].isdigit():\n\t\t\t\t\t\t\t\t<span class=\"hljs-keyword\">continue</span> \n\n\t\t\t\t\t\t\tnewWordIndex = <span class=\"hljs-built_in\">int</span>(tokens[<span class=\"hljs-built_in\">len</span>(tokens)-<span class=\"hljs-number\">1</span>]) + wordOffSet\n\n\t\t\t\t\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(tokens) == <span class=\"hljs-number\">2</span>:\n\n\t\t\t\t\t\t\t parseText[<span class=\"hljs-string\">'dependencies'</span>][i][j][k] = tokens[<span class=\"hljs-number\">0</span>]+ <span class=\"hljs-string\">'-'</span> + <span class=\"hljs-built_in\">str</span>(newWordIndex)\n\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\t\t\t\tw = <span class=\"hljs-string\">''</span>\n\t\t\t\t\t\t\t<span class=\"hljs-keyword\">for</span> l <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(tokens)-<span class=\"hljs-number\">1</span>):\n\t\t\t\t\t\t\t\tw += tokens[l]\n\t\t\t\t\t\t\t\t<span class=\"hljs-keyword\">if</span> l&lt;<span class=\"hljs-built_in\">len</span>(tokens)-<span class=\"hljs-number\">2</span>:\n\t\t\t\t\t\t\t\t\tw += <span class=\"hljs-string\">'-'</span>\n\n\t\t\t\t\t\t\tparseText[<span class=\"hljs-string\">'dependencies'</span>][i][j][k] = w + <span class=\"hljs-string\">'-'</span> + <span class=\"hljs-built_in\">str</span>(newWordIndex)\n\n\t\t\twordOffSet += <span class=\"hljs-built_in\">len</span>(parseText[<span class=\"hljs-string\">'words'</span>][i])\n\n\t\t<span class=\"hljs-keyword\">return</span> parseText\n\n\n\t<span class=\"hljs-string\">'''\n\tInput: parserResult \n\tReturns: [[charBegin,charEnd], wordIndex(starts from 1), word, word_lemma]] \n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_lemma</span>(<span class=\"hljs-params\">self,parserResult</span>):</span>\n\n\n\t\tres = []\t\t\n\t\twordIndex = <span class=\"hljs-number\">1</span>\n\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(parserResult[<span class=\"hljs-string\">'words'</span>])):\n\t\t\t\n\t\t\t<span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(parserResult[<span class=\"hljs-string\">'words'</span>][i])):\n\t\t\t\t\n\t\t\t\ttag = [ [parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'CharacterOffsetBegin'</span>], parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'CharacterOffsetEnd'</span>]], wordIndex,parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">0</span>] ,parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'Lemma'</span>] ]\n\t\t\t\twordIndex += <span class=\"hljs-number\">1</span>\n\t\t\t\tres.append(tag)\n\n\t\t<span class=\"hljs-keyword\">return</span> res\n\n\n\n\t<span class=\"hljs-string\">'''\n\tUsing Stanford POS Tagger\n\tInput: parserResult \n\tReturns: [[charBegin,charEnd], wordIndex(starts from 1), word, word_POS]] \n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">combine_lemmaAndPosTags</span>(<span class=\"hljs-params\">self,parserResult</span>):</span>\n\n\t\tres = []\n\t\t\n\t\twordIndex = <span class=\"hljs-number\">1</span>\n\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(parserResult[<span class=\"hljs-string\">'words'</span>])):\n\t\t\t\n\t\t\t<span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(parserResult[<span class=\"hljs-string\">'words'</span>][i])):\n\t\t\t\t\n\t\t\t\ttag = [ [parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'CharacterOffsetBegin'</span>], parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'CharacterOffsetEnd'</span>]], wordIndex,parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">0</span>] ,parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'Lemma'</span>] ,parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'PartOfSpeech'</span>] ]\n\t\t\t\twordIndex += <span class=\"hljs-number\">1</span>\n\t\t\t\tres.append(tag)\n\n\t\t<span class=\"hljs-keyword\">return</span> res\n\n\n\t<span class=\"hljs-string\">'''\n\tInput: parserResult\n\tReturns: ([charOffsetBegin,charOffsetEnd], wordindex,word, NER ])\n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">nerWordAnnotator</span>(<span class=\"hljs-params\">self,parserResult</span>):</span>\n\n\t\tres = []\n\t\t\n\t\twordIndex = <span class=\"hljs-number\">1</span>\n\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(parserResult[<span class=\"hljs-string\">'words'</span>])):\n\t\t\t\n\t\t\t<span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(parserResult[<span class=\"hljs-string\">'words'</span>][i])):\n\t\t\t\t\n\t\t\t\ttag = [ [parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'CharacterOffsetBegin'</span>], parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'CharacterOffsetEnd'</span>]], wordIndex,parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">0</span>] ,parserResult[<span class=\"hljs-string\">'words'</span>][i][j][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'NamedEntityTag'</span>] ]\n\t\t\t\t<span class=\"hljs-comment\"># print \"tag \", tag</span>\n\t\t\t\twordIndex += <span class=\"hljs-number\">1</span>\n\t\t\t\t<span class=\"hljs-comment\"># if there is valid named entity then add in list</span>\n\t\t\t\t<span class=\"hljs-keyword\">if</span> tag[<span class=\"hljs-number\">3</span>] != <span class=\"hljs-string\">'O'</span>:\n\n\t\t\t\t\tres.append(tag)\n\n\t\t<span class=\"hljs-keyword\">return</span> res\n\n\n\t<span class=\"hljs-string\">'''\n\tInput : ParserResult\n\tReturns : list containing NamedEntites\n\t1. Group words in same list if they share same NE (Location), \n    2. Save other words in list that have any entity\n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_ner</span>(<span class=\"hljs-params\">self,parserResult</span>):</span>\n\n\n\t\t<div style=\"display: inline;\" id=\"named_entity_recognition_0\" class=\"highlights fea_named_entity_recognition\">nerWordAnnotations = self.nerWordAnnotator(parserResult)</div> <span class=\"hljs-comment\">#[[ [charbegin,charEnd], wordIndex, word, NE ]]</span>\n\t\tnamedEntities = []\n\t\tcurrentWord = []\n\t\tcurrentCharacterOffSets = []\n\t\tcurrentWordOffSets = []\n\n\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(nerWordAnnotations)):\n\n\t\t\t<span class=\"hljs-keyword\">if</span> i == <span class=\"hljs-number\">0</span>:\n\n\t\t\t\tcurrentWord.append(nerWordAnnotations[i][<span class=\"hljs-number\">2</span>]) <span class=\"hljs-comment\"># word having NE</span>\n\t\t\t\tcurrentCharacterOffSets.append(nerWordAnnotations[i][<span class=\"hljs-number\">0</span>]) <span class=\"hljs-comment\"># [begin,end]</span>\n\t\t\t\tcurrentWordOffSets.append(nerWordAnnotations[i][<span class=\"hljs-number\">1</span>]) <span class=\"hljs-comment\"># Word Index</span>\n\t\t\t\t<span class=\"hljs-comment\"># if there is only one ner Word tag</span>\n\t\t\t\t<span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">len</span>(nerWordAnnotations) == <span class=\"hljs-number\">1</span>):\n\t\t\t\t\tnamedEntities.append([ currentCharacterOffSets, currentWordOffSets, \\\n\t\t\t\t\t\tcurrentWord, nerWordAnnotations[i-<span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">3</span>] ])\n\t\t\t\t\t<span class=\"hljs-comment\"># print \"named Entities \", namedEntities</span>\n\t\t\t\t\t<span class=\"hljs-keyword\">break</span> \n\t\t\t\t<span class=\"hljs-keyword\">continue</span>\n\t\t\t<span class=\"hljs-comment\"># if consecutive tags have same NER Tag, save them in one list</span>\n\t\t\t<span class=\"hljs-keyword\">if</span> nerWordAnnotations[i][<span class=\"hljs-number\">3</span>] == nerWordAnnotations[i-<span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">3</span>] <span class=\"hljs-keyword\">and</span> \\\n\t\t\t\t\tnerWordAnnotations[i][<span class=\"hljs-number\">1</span>] == nerWordAnnotations[i-<span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">1</span>] + <span class=\"hljs-number\">1</span>:\n\t\t\t\t\n\t\t\t\tcurrentWord.append(nerWordAnnotations[i][<span class=\"hljs-number\">2</span>]) <span class=\"hljs-comment\"># word having NE</span>\n\t\t\t\tcurrentCharacterOffSets.append(nerWordAnnotations[i][<span class=\"hljs-number\">0</span>]) <span class=\"hljs-comment\"># [begin,end]</span>\n\t\t\t\tcurrentWordOffSets.append(nerWordAnnotations[i][<span class=\"hljs-number\">1</span>]) <span class=\"hljs-comment\"># Word Index</span>\n\n\t\t\t\t<span class=\"hljs-keyword\">if</span> i == (<span class=\"hljs-built_in\">len</span>(nerWordAnnotations) - <span class=\"hljs-number\">1</span>):\n\t\t\t\t\tnamedEntities.append([ currentCharacterOffSets, \\\n\t\t\t\t\t\tcurrentWordOffSets, currentWord, nerWordAnnotations[i][<span class=\"hljs-number\">3</span>] ])\n\t\t\t<span class=\"hljs-comment\"># if consecutive tags do not match</span>\n\t\t\t<span class=\"hljs-keyword\">else</span>:\n\n\t\t\t\tnamedEntities.append([ currentCharacterOffSets, \\\n\t\t\t\t\t\tcurrentWordOffSets, currentWord, nerWordAnnotations[i-<span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">3</span>] ])\n\t\t\t\tcurrentWord = [nerWordAnnotations[i][<span class=\"hljs-number\">2</span>]]\n\t\t\t\t<span class=\"hljs-comment\"># remove everything from currentCharacterOffSets and currentWordOffSets</span>\n\t\t\t\tcurrentCharacterOffSets = []\n\t\t\t\tcurrentWordOffSets = []\n\t\t\t\t<span class=\"hljs-comment\"># add charac offsets and currentWordOffSets of current word</span>\n\t\t\t\tcurrentCharacterOffSets.append(nerWordAnnotations[i][<span class=\"hljs-number\">0</span>])\n\t\t\t\tcurrentWordOffSets.append(nerWordAnnotations[i][<span class=\"hljs-number\">1</span>])\n\n\t\t\t\t<span class=\"hljs-comment\"># if it is last iteration then update named Entities</span>\n\t\t\t\t<span class=\"hljs-keyword\">if</span> i == <span class=\"hljs-built_in\">len</span>(nerWordAnnotations)-<span class=\"hljs-number\">1</span>:\n\t\t\t\t\tnamedEntities.append([ currentCharacterOffSets, currentWordOffSets, \\\n\t\t\t\t\t\t\tcurrentWord, nerWordAnnotations[i][<span class=\"hljs-number\">3</span>] ])\n\t\t<span class=\"hljs-comment\">#sort out according to len of characters in ascending order</span>\n\t\tnamedEntities = <span class=\"hljs-built_in\">sorted</span>(namedEntities, key=<span class=\"hljs-built_in\">len</span>)\n\n\t\t<span class=\"hljs-keyword\">return</span> namedEntities\n\n\n\t<span class=\"hljs-string\">'''\n\tInput: Word(Word whose NE is not found), NE(word already have NE Tag) \n\tReturns: Boolean; True if word is acronym\n\t\t\t\t\tFalse if word is not acronym\n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">is_Acronym</span>(<span class=\"hljs-params\">self,word,NE</span>):</span>\n\n\n\t\tqueryWord = word.replace(<span class=\"hljs-string\">'.'</span>,<span class=\"hljs-string\">''</span>)\n\t\t<span class=\"hljs-comment\"># If all words of queryWord is not capital or length of word != </span>\n\t\t\t\t<span class=\"hljs-comment\">#length of NE(word already have NE Tag) or </span>\n\t\t   <span class=\"hljs-comment\">#  if word is 'a' or 'i' </span>\n\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> queryWord.isupper() <span class=\"hljs-keyword\">or</span> <span class=\"hljs-built_in\">len</span>(queryWord) != <span class=\"hljs-built_in\">len</span>(NE) <span class=\"hljs-keyword\">or</span> queryWord.lower() <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\">'a'</span>, <span class=\"hljs-string\">'i'</span>]:\n\t\t\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span>\n\n\t\tacronym = <span class=\"hljs-literal\">True</span>\n\n\t\t<span class=\"hljs-comment\">#we run for loop till length of query word(i.e 3)(if word is 'UAE')</span>\n\t\t<span class=\"hljs-comment\">#Compare 1st letter(U) of query word with first letter of first element in named entity(U = U(united))</span>\n\t\t<span class=\"hljs-comment\"># again we take second letter of canonical word (A) with second element in named entity(Arab)</span>\n\t\t<span class=\"hljs-comment\"># and so on </span>\n\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(queryWord)):\n\t\t\t<span class=\"hljs-comment\"># print \"queryword[i], NE \", queryWord, NE</span>\n\t\t\t<span class=\"hljs-keyword\">if</span> queryWord[i] != NE[i][<span class=\"hljs-number\">0</span>]:\n\t\t\t\tacronym = <span class=\"hljs-literal\">False</span>\n\t\t\t\t<span class=\"hljs-keyword\">break</span>\n\n\t\t<span class=\"hljs-keyword\">return</span> acronym\n\n\n\t<span class=\"hljs-string\">'''\n\tInput: sentence\n\tReturns: parse(\t{ParseTree, text, Dependencies, \n\t  'word : [] NamedEntityTag, CharacterOffsetEnd, \n\t  \t\tCharacterOffsetBegin, PartOfSpeech, Lemma}']}) \n\t  \t\tsentence and\n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_parseText</span>(<span class=\"hljs-params\">self,sentence</span>):</span>\n\n\t\tself.count = <span class=\"hljs-number\">0</span>\n\t\tself.length_of_sentence = [] <span class=\"hljs-comment\"># stores length of each sentence</span>\n\t\t<div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">tokenized_sentence = sent_tokenize(sentence)</div>\n\t\t<span class=\"hljs-comment\"># print \"len of tokenized \",len(tokenized_sentence)</span>\n\t\t<span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">len</span>(tokenized_sentence) == <span class=\"hljs-number\">1</span>):\n\t\t\tself.count += <span class=\"hljs-number\">1</span>\n\t\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> tokenized_sentence:\n\t\t\t\tparse = self.get_combine_words_param(i)\n\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\ttmp = <span class=\"hljs-number\">0</span>\n\t\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> tokenized_sentence:\n\t\t\t\tself.count += <span class=\"hljs-number\">1</span>\n\t\t\t\tparse = self.get_combine_words_param(i)\n\t\t\t\ts = <span class=\"hljs-built_in\">len</span>(i) + tmp\n\t\t\t\tself.length_of_sentence.append(s)\n\t\t\t\ttmp = s\n\n\t\t<span class=\"hljs-keyword\">return</span> parse,tokenized_sentence\n\t\t\n\n\t<span class=\"hljs-string\">'''\n\tInput: sentences\n    Return: constituency tree that represents relations between sub-phrases in sentences\n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_constituency_Tree</span>(<span class=\"hljs-params\">self,sentence</span>):</span>\n\t\t\n\t\t<div style=\"display: inline;\" id=\"tokenization_1\" class=\"highlights fea_tokenization\">sentence = sent_tokenize(sentence)</div>\n\t\t<div style=\"display: inline;\" id=\"parsing_2\" class=\"highlights fea_parsing\">constituency_parser = self.constituent_parse_tree.raw_parse_sents(sentence)</div>\n\t\t<span class=\"hljs-keyword\">for</span> parser <span class=\"hljs-keyword\">in</span> constituency_parser:\n\t\t\t<span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> parser:\n\t\t\t\ttree = <span class=\"hljs-built_in\">str</span>(sent)\n\t\tparse_string = <span class=\"hljs-string\">' '</span>.join(<span class=\"hljs-built_in\">str</span>(tree).split()) \n        \n\t\t<span class=\"hljs-keyword\">return</span> parse_string\n\n\n\t<span class=\"hljs-string\">'''\n\tInput: sentence\n\treturns: relation between words with their index\n\t'''</span>\t\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_dependencies</span>(<span class=\"hljs-params\">self,sentence</span>):</span>\n\n\n\t\tdependency_tree = []\n\t\t<div style=\"display: inline;\" id=\"dependency_parsing_0\" class=\"highlights fea_dependency_parsing\">dependency_parser = self.stanford_dependency.raw_parse(sentence)</div>\n\t\t<div style=\"display: inline;\" id=\"tokenization_2\" class=\"highlights fea_tokenization\">token = word_tokenize(sentence)</div>\n\t\t<div style=\"display: inline;\" id=\"dependency_parsing_1\" class=\"highlights fea_dependency_parsing\">parsetree = <span class=\"hljs-built_in\">list</span>(self.stanford_dependency.raw_parse(sentence))[<span class=\"hljs-number\">0</span>]</div>\n\t\t<span class=\"hljs-comment\"># Find root(head) of the sentence </span>\n\t\t<span class=\"hljs-keyword\">for</span> k <span class=\"hljs-keyword\">in</span> parsetree.nodes.values():\n\t\t\t<span class=\"hljs-keyword\">if</span> k[<span class=\"hljs-string\">\"head\"</span>] == <span class=\"hljs-number\">0</span>:\n\t\t\n\t\t\t\tdependency_tree.append([<span class=\"hljs-built_in\">str</span>(k[<span class=\"hljs-string\">\"rel\"</span>]), <span class=\"hljs-string\">\"Root-\"</span> + <span class=\"hljs-built_in\">str</span>(k[<span class=\"hljs-string\">\"head\"</span>]), <span class=\"hljs-built_in\">str</span>(k[<span class=\"hljs-string\">\"word\"</span>]) \n\t\t\t\t\t+ <span class=\"hljs-string\">\"-\"</span> + <span class=\"hljs-built_in\">str</span>(k[<span class=\"hljs-string\">\"address\"</span>]) ])\t    \t\n\t\t<span class=\"hljs-comment\"># Find relation between words in sentence</span>\n\t\t<span class=\"hljs-keyword\">for</span> dep <span class=\"hljs-keyword\">in</span> dependency_parser:\n\t\t\t<span class=\"hljs-keyword\">for</span> triple <span class=\"hljs-keyword\">in</span> dep.triples():\n\t\t\t\tindex_word = token.index(triple[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>]) + <span class=\"hljs-number\">1</span> <span class=\"hljs-comment\"># because index starts from 0 </span>\n\t\t\t\tindex2_word = token.index(triple[<span class=\"hljs-number\">2</span>][<span class=\"hljs-number\">0</span>]) + <span class=\"hljs-number\">1</span>\n\t\t\t\tdependency_tree.append([<span class=\"hljs-built_in\">str</span>(triple[<span class=\"hljs-number\">1</span>]),<span class=\"hljs-built_in\">str</span>(triple[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>]) + <span class=\"hljs-string\">\"-\"</span> + <span class=\"hljs-built_in\">str</span>(index_word),\\\n\t\t\t\t\t\t\t <span class=\"hljs-built_in\">str</span>(triple[<span class=\"hljs-number\">2</span>][<span class=\"hljs-number\">0</span>]) + <span class=\"hljs-string\">\"-\"</span> + <span class=\"hljs-built_in\">str</span>(index2_word)])\n\n\t\t<span class=\"hljs-keyword\">return</span> dependency_tree\n\n\n\t<span class=\"hljs-string\">'''\n\tInput: sentence, word(of which offset to determine)\n\tReturn: [CharacterOffsetEnd,CharacterOffsetBegin] for each word\n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_charOffset</span>(<span class=\"hljs-params\">self,sentence, word</span>):</span>\n\n\t\t<span class=\"hljs-comment\"># word containing '.' causes problem in counting</span>\n\n\t\tCharacterOffsetBegin = sentence.find(word)\n\t\tCharacterOffsetEnd = CharacterOffsetBegin + <span class=\"hljs-built_in\">len</span>(word)\n\t\t\n\t\t<span class=\"hljs-keyword\">return</span> [CharacterOffsetEnd,CharacterOffsetBegin]\n\n\n\t<span class=\"hljs-string\">'''\n\tInput: sentence\n\tReturns: dictionary: \n\t{ParseTree, text, Dependencies, \n\t  #'word : [] NamedEntityTag, CharacterOffsetEnd, CharacterOffsetBegin, PartOfSpeech, Lemma}']}\n\t'''</span>\n\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_combine_words_param</span>(<span class=\"hljs-params\">self,sentence</span>):</span>\n\t\t\n\n\t\twords_in_each_sentence = []\n\t\twords_list = [] \n\t\t<div style=\"display: inline;\" id=\"tokenization_3\" class=\"highlights fea_tokenization\">tokenized_words = word_tokenize(sentence)</div>\n\t\t<div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">posTag = self.pos_tag.tag(tokenized_words)</div>\n\t\t<div style=\"display: inline;\" id=\"named_entity_recognition_1\" class=\"highlights fea_named_entity_recognition\">ner = self.ner.tag(tokenized_words)</div>\n\t\t\n\t\t<span class=\"hljs-comment\"># if source sentence/target sentence has one sentence</span>\n\t\t<span class=\"hljs-keyword\">if</span> (self.count == <span class=\"hljs-number\">1</span>):\n\t\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(tokenized_words)):\n\t\t\t\tword_lemma = <span class=\"hljs-built_in\">str</span>()\n\t\t\t\tword = tokenized_words[i]\n\t\t\t\tname_entity = ner[i]\n\t\t\t\tword_posTag = posTag[i][-<span class=\"hljs-number\">1</span>]  <span class=\"hljs-comment\"># access tuple [(United, NNP),..]</span>\n\t\t\t\t<span class=\"hljs-comment\"># print \"word and pos tag \", word, word_posTag[0]\t</span>\n\t\t\t\t<span class=\"hljs-comment\">#wordNet lemmatizer needs pos tag with words else it considers noun</span>\n\t\t\t\t<span class=\"hljs-keyword\">if</span> (word_posTag[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'V'</span>):\n\t\t\t\t\t<div style=\"display: inline;\" id=\"lemmatization_1\" class=\"highlights fea_lemmatization\">word_lemma = self.lemma.lemmatize(tokenized_words[i], wordnet.VERB)</div>\n\n\t\t\t\t<span class=\"hljs-keyword\">elif</span> (word_posTag[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'J'</span>):\n\t\t\t\t\t<div style=\"display: inline;\" id=\"lemmatization_2\" class=\"highlights fea_lemmatization\">word_lemma = self.lemma.lemmatize(tokenized_words[i], wordnet.ADJ)</div>\n\n\t\t\t\t<span class=\"hljs-keyword\">elif</span> (word_posTag[<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">1</span>] == <span class=\"hljs-string\">'RB'</span>):\n\t\t\t\t\t<div style=\"display: inline;\" id=\"lemmatization_3\" class=\"highlights fea_lemmatization\">word_lemma = self.lemma.lemmatize(tokenized_words[i], wordnet.ADV)</div>\n\n\t\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\t\t<div style=\"display: inline;\" id=\"lemmatization_4\" class=\"highlights fea_lemmatization\">word_lemma = self.lemma.lemmatize(tokenized_words[i])</div>\n\n\t\t\t\tself.CharacterOffsetEnd, self.CharacterOffsetBegin = self.get_charOffset(sentence,tokenized_words[i])\n\t\t\t\t\n\n\t\t\t\twords_list.append([word, {<span class=\"hljs-string\">\"NamedEntityTag\"</span> : <span class=\"hljs-built_in\">str</span>(name_entity[<span class=\"hljs-number\">1</span>]),\n\t\t\t\t\t<span class=\"hljs-string\">\"CharacterOffsetEnd\"</span> : <span class=\"hljs-built_in\">str</span>(self.CharacterOffsetEnd), <span class=\"hljs-string\">\"CharacterOffsetBegin\"</span> : <span class=\"hljs-built_in\">str</span>(self.CharacterOffsetBegin) \n\t\t\t\t\t,<span class=\"hljs-string\">\"PartOfSpeech\"</span> : <span class=\"hljs-built_in\">str</span>(word_posTag) , <span class=\"hljs-string\">\"Lemma\"</span> : <span class=\"hljs-built_in\">str</span>(word_lemma)}])\n\n\t\t\tself.parseResult[<span class=\"hljs-string\">'parseTree'</span>] = [self.get_constituency_Tree(sentence)]\n\t\t\tself.parseResult[<span class=\"hljs-string\">'text'</span>] = [sentence]\n\t\t\tself.parseResult[<span class=\"hljs-string\">'dependencies'</span>] = [self.get_dependencies(sentence)]\n\t\t\tself.parseResult[<span class=\"hljs-string\">'words'</span>] = [words_list]\n\n\t\t<span class=\"hljs-keyword\">else</span>:\n\n\t\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(tokenized_words)):\n\t\t\t\tword = tokenized_words[i]\n\t\t\t\tname_entity = ner[i] \n\t\t\t\tword_posTag = posTag[i][-<span class=\"hljs-number\">1</span>]\n\n\t\t\t\t<span class=\"hljs-keyword\">if</span> (word_posTag[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'V'</span>):\n\t\t\t\t\tword_lemma = self.lemma.lemmatize(tokenized_words[i], wordnet.VERB)\n\n\t\t\t\t<span class=\"hljs-keyword\">elif</span> (word_posTag[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'J'</span>):\n\t\t\t\t\tword_lemma = self.lemma.lemmatize(tokenized_words[i], wordnet.ADJ)\n\n\t\t\t\t<span class=\"hljs-keyword\">elif</span> (word_posTag[<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">1</span>] == <span class=\"hljs-string\">'RB'</span>):\n\t\t\t\t\tword_lemma = self.lemma.lemmatize(tokenized_words[i], wordnet.ADV)\n\n\t\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\t\tword_lemma = self.lemma.lemmatize(tokenized_words[i])\n\n\t\t\t\tend, begin = self.get_charOffset(sentence,tokenized_words[i])\n\t\t\t\tend = end + self.length_of_sentence[self.count-<span class=\"hljs-number\">2</span>] + <span class=\"hljs-number\">1</span>\n\t\t\t\tbegin = begin + self.length_of_sentence[self.count-<span class=\"hljs-number\">2</span>] + <span class=\"hljs-number\">1</span>\t\n\t\t\t\twords_list.append([word, {<span class=\"hljs-string\">\"NamedEntityTag\"</span> : <span class=\"hljs-built_in\">str</span>(name_entity[<span class=\"hljs-number\">1</span>]),\n\t\t\t\t\t<span class=\"hljs-string\">\"CharacterOffsetEnd\"</span> : <span class=\"hljs-built_in\">str</span>(end), <span class=\"hljs-string\">\"CharacterOffsetBegin\"</span> : <span class=\"hljs-built_in\">str</span>(begin) \n\t\t\t\t\t,<span class=\"hljs-string\">\"PartOfSpeech\"</span> : <span class=\"hljs-built_in\">str</span>(word_posTag) , <span class=\"hljs-string\">\"Lemma\"</span> : <span class=\"hljs-built_in\">str</span>(word_lemma)}])\n\t\t\tself.parseResult[<span class=\"hljs-string\">'parseTree'</span>].append(self.get_constituency_Tree(sentence))\n\t\t\tself.parseResult[<span class=\"hljs-string\">'text'</span>].append(sentence)\n\t\t\tself.parseResult[<span class=\"hljs-string\">'dependencies'</span>].append(self.get_dependencies(sentence))\n\t\t\tself.parseResult[<span class=\"hljs-string\">'words'</span>].append(words_list)\n\n\t\t<span class=\"hljs-keyword\">return</span> self.parseResult\n\t\t<span class=\"hljs-comment\">#https://github.com/rameshjes/Semantic-Textual-Similarity/blob/master/monolingualWordAligner/nltkUtil.py</span></code></pre></div>",
    "fir_16.py": "<div class=\"codeBlock hljs python\" id=\"fir_16\"><pre id=\"fir_16_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># Copyright 2020 The `Kumar Nityan Suman` (https://github.com/nityansuman/).</span>\n<span class=\"hljs-comment\"># All Rights Reserved.</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\">#                     GNU GENERAL PUBLIC LICENSE</span>\n<span class=\"hljs-comment\">#                        Version 3, 29 June 2007</span>\n<span class=\"hljs-comment\">#  Copyright (C) 2007 Free Software Foundation, Inc. &lt;http://fsf.org/&gt;</span>\n<span class=\"hljs-comment\">#  Everyone is permitted to copy and distribute verbatim copies</span>\n<span class=\"hljs-comment\">#  of this license document, but changing it is not allowed.</span>\n<span class=\"hljs-comment\"># ==============================================================================</span>\n\n<span class=\"hljs-keyword\">import</span> logging\n<span class=\"hljs-keyword\">from</span> typing <span class=\"hljs-keyword\">import</span> Tuple\n\n<span class=\"hljs-keyword\">import</span> nltk <span class=\"hljs-keyword\">as</span> nlp\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">SubjectiveTest</span>:</span>\n\t<span class=\"hljs-string\">\"\"\"Class abstraction for subjective test generation module.\n\t\"\"\"</span>\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, filepath: <span class=\"hljs-built_in\">str</span></span>):</span>\n\t\t<span class=\"hljs-string\">\"\"\"Class constructor.\n\n\t\tArgs:\n\t\t\tfilepath (str): Absolute filepath to the subject corpus.\n\t\t\"\"\"</span>\n\t\tself.question_pattern = [\n\t\t\t<span class=\"hljs-string\">\"Explain in detail \"</span>,\n\t\t\t<span class=\"hljs-string\">\"Define \"</span>,\n\t\t\t<span class=\"hljs-string\">\"Write a short note on \"</span>,\n\t\t\t<span class=\"hljs-string\">\"What do you mean by \"</span>\n\t\t]\n\n\t\tself.grammar = <span class=\"hljs-string\">r\"\"\"\n\t\t\tCHUNK: {&lt;NN&gt;+&lt;IN|DT&gt;*&lt;NN&gt;+}\n\t\t\t{&lt;NN&gt;+&lt;IN|DT&gt;*&lt;NNP&gt;+}\n\t\t\t{&lt;NNP&gt;+&lt;NNS&gt;*}\n\t\t\"\"\"</span>\n\n\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\t<span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(filepath, mode=<span class=\"hljs-string\">\"r\"</span>) <span class=\"hljs-keyword\">as</span> fp:\n\t\t\t\tself.summary = fp.read()\n\t\t<span class=\"hljs-keyword\">except</span> FileNotFoundError:\n\t\t\tlogging.exception(<span class=\"hljs-string\">\"Corpus file not found.\"</span>, exc_info=<span class=\"hljs-literal\">True</span>)\n\n<span class=\"hljs-meta\">\t@staticmethod</span>\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">word_tokenizer</span>(<span class=\"hljs-params\">sequence: <span class=\"hljs-built_in\">str</span></span>) -&gt; list:</span>\n\t\t<span class=\"hljs-string\">\"\"\"Tokenize string sequences to words.\n\n\t\tArgs:\n\t\t\tsequence (str): Corpus sequences.\n\n\t\tReturns:\n\t\t\tlist: Word tokens.\n\t\t\"\"\"</span>\n\t\tword_tokens = <span class=\"hljs-built_in\">list</span>()\n\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\t<span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">nlp.sent_tokenize(sequence)</div>:\n\t\t\t\t<span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"tokenization_1\" class=\"highlights fea_tokenization\">nlp.word_tokenize(sent)</div>:\n\t\t\t\t\tword_tokens.append(w)\n\t\t<span class=\"hljs-keyword\">except</span> Exception:\n\t\t\tlogging.exception(<span class=\"hljs-string\">\"Word tokenization failed.\"</span>, exc_info=<span class=\"hljs-literal\">True</span>)\n\t\t<span class=\"hljs-keyword\">return</span> word_tokens\n\n<span class=\"hljs-meta\">\t@staticmethod</span>\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">create_vector</span>(<span class=\"hljs-params\">answer_tokens: <span class=\"hljs-built_in\">list</span>, tokens: <span class=\"hljs-built_in\">list</span></span>) -&gt; np.array:</span>\n\t\t<span class=\"hljs-string\">\"\"\"Create a one-hot encoded vector for the answer_tokens.\n\n\t\tArgs:\n\t\t\tanswer_tokens (list): Tokenized user response.\n\t\t\ttokens (list): Tokenized answer corpus.\n\n\t\tReturns:\n\t\t\tnp.array: A one-hot encoded vector of the answer.\n\t\t\"\"\"</span>\n\t\t<span class=\"hljs-keyword\">return</span> np.array([<span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">if</span> tok <span class=\"hljs-keyword\">in</span> answer_tokens <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">for</span> tok <span class=\"hljs-keyword\">in</span> tokens])\n\n<span class=\"hljs-meta\">\t@staticmethod</span>\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">cosine_similarity_score</span>(<span class=\"hljs-params\">vector1: np.array, vector2: np.array</span>) -&gt; float:</span>\n\t\t<span class=\"hljs-string\">\"\"\"Compute the euclidean distance between two vectors.\n\n\t\tArgs:\n\t\t\tvector1 (np.array): Actual answer vector.\n\t\t\tvector2 (np.array): User response vector.\n\n\t\tReturns:\n\t\t\tfloat: Euclidean distance between two vectors.\n\t\t\"\"\"</span>\n\t\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">vector_value</span>(<span class=\"hljs-params\">vector</span>):</span>\n\t\t\t<span class=\"hljs-keyword\">return</span> np.sqrt(np.<span class=\"hljs-built_in\">sum</span>(np.square(vector)))\n\n\t\tv1 = vector_value(vector1)\n\t\tv2 = vector_value(vector2)\n\n\t\tv1_v2 = np.dot(vector1, vector2)\n\t\t<span class=\"hljs-keyword\">return</span> (v1_v2 / (v1 * v2)) * <span class=\"hljs-number\">100</span>\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">generate_test</span>(<span class=\"hljs-params\">self, num_questions: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">2</span></span>) -&gt; Tuple[list, list]:</span>\n\t\t<span class=\"hljs-string\">\"\"\"Method to generate subjective test.\n\n\t\tArgs:\n\t\t\tnum_questions (int, optional): Maximum number of questions\n\t\t\t\tto be generated. Defaults to 2.\n\n\t\tReturns:\n\t\t\tTuple[list, list]: Generated `Questions` and `Answers` respectively\n\t\t\"\"\"</span>\n\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\tsentences = nlp.sent_tokenize(self.summary)\n\t\t<span class=\"hljs-keyword\">except</span> Exception:\n\t\t\tlogging.exception(<span class=\"hljs-string\">\"Sentence tokenization failed.\"</span>, exc_info=<span class=\"hljs-literal\">True</span>)\n\n\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\t<div style=\"display: inline;\" id=\"parsing_0\" class=\"highlights fea_parsing\">cp = nlp.RegexpParser(self.grammar)</div>\n\t\t<span class=\"hljs-keyword\">except</span> Exception:\n\t\t\tlogging.exception(<span class=\"hljs-string\">\"Regex grammar train failed.\"</span>, exc_info=<span class=\"hljs-literal\">True</span>)\n\n\t\tquestion_answer_dict = <span class=\"hljs-built_in\">dict</span>()\n\t\t<span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sentences:\n\n\t\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\t\t<div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">tagged_words = nlp.pos_tag(nlp.word_tokenize(sentence))</div>\n\t\t\t<span class=\"hljs-keyword\">except</span> Exception:\n\t\t\t\tlogging.exception(<span class=\"hljs-string\">\"Word tokenization failed.\"</span>, exc_info=<span class=\"hljs-literal\">True</span>)\n\n\t\t\ttree = cp.parse(tagged_words)\n\t\t\t<span class=\"hljs-keyword\">for</span> subtree <span class=\"hljs-keyword\">in</span> tree.subtrees():\n\t\t\t\t<span class=\"hljs-keyword\">if</span> subtree.label() == <span class=\"hljs-string\">\"CHUNK\"</span>:\n\t\t\t\t\ttemp = <span class=\"hljs-string\">\"\"</span>\n\t\t\t\t\t<span class=\"hljs-keyword\">for</span> sub <span class=\"hljs-keyword\">in</span> subtree:\n\t\t\t\t\t\ttemp += sub[<span class=\"hljs-number\">0</span>]\n\t\t\t\t\t\ttemp += <span class=\"hljs-string\">\" \"</span>\n\t\t\t\t\ttemp = temp.strip()\n\t\t\t\t\ttemp = temp.upper()\n\t\t\t\t\t<span class=\"hljs-keyword\">if</span> temp <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> question_answer_dict:\n\t\t\t\t\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(<div style=\"display: inline;\" id=\"tokenization_2\" class=\"highlights fea_tokenization\">nlp.word_tokenize(sentence)</div>) &gt; <span class=\"hljs-number\">20</span>:\n\t\t\t\t\t\t\tquestion_answer_dict[temp] = sentence\n\t\t\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\t\t\tquestion_answer_dict[temp] += sentence\n\n\t\tkeyword_list = <span class=\"hljs-built_in\">list</span>(question_answer_dict.keys())\n\t\tquestion_answer = <span class=\"hljs-built_in\">list</span>()\n\n\t\t<span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>):\n\t\t\trand_num = np.random.randint(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(keyword_list))\n\t\t\tselected_key = keyword_list[rand_num]\n\t\t\tanswer = question_answer_dict[selected_key]\n\t\t\trand_num %= <span class=\"hljs-number\">4</span>\n\t\t\tquestion = self.question_pattern[rand_num] + selected_key + <span class=\"hljs-string\">\".\"</span>\n\t\t\tquestion_answer.append({<span class=\"hljs-string\">\"Question\"</span>: question, <span class=\"hljs-string\">\"Answer\"</span>: answer})\n\n\t\tque = <span class=\"hljs-built_in\">list</span>()\n\t\tans = <span class=\"hljs-built_in\">list</span>()\n\t\t<span class=\"hljs-keyword\">while</span> <span class=\"hljs-built_in\">len</span>(que) &lt; num_questions:\n\t\t\trand_num = np.random.randint(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(question_answer))\n\t\t\t<span class=\"hljs-keyword\">if</span> question_answer[rand_num][<span class=\"hljs-string\">\"Question\"</span>] <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> que:\n\t\t\t\tque.append(question_answer[rand_num][<span class=\"hljs-string\">\"Question\"</span>])\n\t\t\t\tans.append(question_answer[rand_num][<span class=\"hljs-string\">\"Answer\"</span>])\n\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\t<span class=\"hljs-keyword\">continue</span>\n\t\t<span class=\"hljs-keyword\">return</span> que, ans\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">evaluate_subjective_answer</span>(<span class=\"hljs-params\">self, original_answer: <span class=\"hljs-built_in\">str</span>, user_answer: <span class=\"hljs-built_in\">str</span></span>) -&gt; float:</span>\n\t\t<span class=\"hljs-string\">\"\"\"Evaluate the subjective answer given by the user.\n\n\t\tArgs:\n\t\t\toriginal_answer (str): A string representing the original answer.\n\t\t\tuser_answer (str): A string representing the answer given by the user.\n\n\t\tReturns:\n\t\t\tfloat: Similarity/correctness score of the user answer\n\t\t\t\tbased on the original asnwer.\n\t\t\"\"\"</span>\n\t\tscore_obt = <span class=\"hljs-number\">0</span>\n\t\toriginal_ans_list = self.word_tokenizer(original_answer)\n\t\tuser_ans_list = self.word_tokenizer(user_answer)\n\n\t\toverall_list = original_ans_list + user_ans_list\n\n\t\tvector1 = self.create_vector(original_ans_list, overall_list)\n\t\tvector2 = self.create_vector(user_answer, overall_list)\n\n\t\tscore_obt = self.cosine_similarity_score(vector1, vector2)\n\t\t<span class=\"hljs-keyword\">return</span> score_obt\n\t\t<span class=\"hljs-comment\">#https://github.com/nityansuman/marvin/blob/main/src/subjective.py</span></code></pre></div>",
    "fir_17.py": "<div class=\"codeBlock hljs python\" id=\"fir_17\"><pre id=\"fir_17_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># Copyright 2020 The `Kumar Nityan Suman` (https://github.com/nityansuman/).</span>\n<span class=\"hljs-comment\"># All Rights Reserved.</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\">#                     GNU GENERAL PUBLIC LICENSE</span>\n<span class=\"hljs-comment\">#                        Version 3, 29 June 2007</span>\n<span class=\"hljs-comment\">#  Copyright (C) 2007 Free Software Foundation, Inc. &lt;http://fsf.org/&gt;</span>\n<span class=\"hljs-comment\">#  Everyone is permitted to copy and distribute verbatim copies</span>\n<span class=\"hljs-comment\">#  of this license document, but changing it is not allowed.</span>\n<span class=\"hljs-comment\"># ==============================================================================</span>\n\n<span class=\"hljs-keyword\">import</span> logging\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">from</span> typing <span class=\"hljs-keyword\">import</span> Tuple\n\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> wordnet <span class=\"hljs-keyword\">as</span> wn\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ObjectiveTest</span>:</span>\n\t<span class=\"hljs-string\">\"\"\"Class abstraction for objective test generation module.\n\t\"\"\"</span>\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, filepath: <span class=\"hljs-built_in\">str</span></span>):</span>\n\t\t<span class=\"hljs-string\">\"\"\"Class constructor.\n\n\t\tArgs:\n\t\t\tfilepath (str): filepath (str): Absolute filepath to the subject corpus.\n\t\t\"\"\"</span>\n\t\t<span class=\"hljs-comment\"># Load subject corpus</span>\n\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\t<span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(filepath, mode=<span class=\"hljs-string\">\"r\"</span>) <span class=\"hljs-keyword\">as</span> fp:\n\t\t\t\tself.summary = fp.read()\n\t\t<span class=\"hljs-keyword\">except</span> FileNotFoundError:\n\t\t\tlogging.exception(<span class=\"hljs-string\">\"Corpus file not found.\"</span>, exc_info=<span class=\"hljs-literal\">True</span>)\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">generate_test</span>(<span class=\"hljs-params\">self, num_questions: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">3</span></span>) -&gt; Tuple[list, list]:</span>\n\t\t<span class=\"hljs-string\">\"\"\"Method to generate an objective test.\n\n\t\tArgs:\n\t\t\tnum_questions (int, optional): Number of questions in a test.\n\t\t\t\tDefaults to 3.\n\n\t\tReturns:\n\t\t\tTuple[list, list]: Questions and answer options respectively.\n\t\t\"\"\"</span>\n\t\t<span class=\"hljs-comment\"># Identify potential question sets</span>\n\t\tquestion_sets = self.get_question_sets()\n\n\t\t<span class=\"hljs-comment\"># Identify potential question answers</span>\n\t\tquestion_answers = <span class=\"hljs-built_in\">list</span>()\n\t\t<span class=\"hljs-keyword\">for</span> question_set <span class=\"hljs-keyword\">in</span> question_sets:\n\t\t\t<span class=\"hljs-keyword\">if</span> question_set[<span class=\"hljs-string\">\"Key\"</span>] &gt; <span class=\"hljs-number\">3</span>:\n\t\t\t\tquestion_answers.append(question_set)\n\n\t\t<span class=\"hljs-comment\"># Create objective test set</span>\n\t\tquestions, answers = <span class=\"hljs-built_in\">list</span>(), <span class=\"hljs-built_in\">list</span>()\n\t\t<span class=\"hljs-keyword\">while</span> <span class=\"hljs-built_in\">len</span>(questions) &lt; num_questions:\n\t\t\trand_num = np.random.randint(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(question_answers))\n\t\t\t<span class=\"hljs-keyword\">if</span> question_answers[rand_num][<span class=\"hljs-string\">\"Question\"</span>] <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> questions:\n\t\t\t\tquestions.append(question_answers[rand_num][<span class=\"hljs-string\">\"Question\"</span>])\n\t\t\t\tanswers.append(question_answers[rand_num][<span class=\"hljs-string\">\"Answer\"</span>])\n\t\t<span class=\"hljs-keyword\">return</span> questions, answers\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_question_sets</span>(<span class=\"hljs-params\">self</span>) -&gt; list:</span>\n\t\t<span class=\"hljs-string\">\"\"\"Method to dentify sentences with potential objective questions.\n\n\t\tReturns:\n\t\t\tlist: Sentences with potential objective questions.\n\t\t\"\"\"</span>\n\t\t<span class=\"hljs-comment\"># Tokenize corpus into sentences</span>\n\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\t<div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">sentences = nltk.sent_tokenize(self.summary)</div>\n\t\t<span class=\"hljs-keyword\">except</span> Exception:\n\t\t\tlogging.exception(<span class=\"hljs-string\">\"Sentence tokenization failed.\"</span>, exc_info=<span class=\"hljs-literal\">True</span>)\n\n\t\t<span class=\"hljs-comment\"># Identify potential question sets</span>\n\t\t<span class=\"hljs-comment\"># Each question set consists:</span>\n\t\t<span class=\"hljs-comment\"># \tQuestion: Objective question.</span>\n\t\t<span class=\"hljs-comment\"># \tAnswer: Actual asnwer.</span>\n\t\t<span class=\"hljs-comment\">#\tKey: Other options.</span>\n\t\tquestion_sets = <span class=\"hljs-built_in\">list</span>()\n\t\t<span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> sentences:\n\t\t\tquestion_set = self.identify_potential_questions(sent)\n\t\t\t<span class=\"hljs-keyword\">if</span> question_set <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>:\n\t\t\t\tquestion_sets.append(question_set)\n\t\t<span class=\"hljs-keyword\">return</span> question_sets\n\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">identify_potential_questions</span>(<span class=\"hljs-params\">self, sentence: <span class=\"hljs-built_in\">str</span></span>) -&gt; dict:</span>\n\t\t<span class=\"hljs-string\">\"\"\"Method to identiyf potential question sets.\n\n\t\tArgs:\n\t\t\tsentence (str): Tokenized sequence from corpus.\n\n\t\tReturns:\n\t\t\tdict: Question formed along with the correct answer in case of\n\t\t\t\tpotential sentence else return None.\n\t\t\"\"\"</span>\n\t\t<span class=\"hljs-comment\"># POS tag sequences</span>\n\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\t<div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">tags = nltk.pos_tag(sentence)</div>\n\t\t\t<span class=\"hljs-keyword\">if</span> tags[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">1</span>] == <span class=\"hljs-string\">\"RB\"</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-built_in\">len</span>(<div style=\"display: inline;\" id=\"tokenization_1\" class=\"highlights fea_tokenization\">nltk.word_tokenize(sentence)</div>) &lt; <span class=\"hljs-number\">4</span>:\n\t\t\t\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">None</span>\n\t\t<span class=\"hljs-keyword\">except</span> Exception:\n\t\t\tlogging.exception(<span class=\"hljs-string\">\"POS tagging failed.\"</span>, exc_info=<span class=\"hljs-literal\">True</span>)\n\n\t\t<span class=\"hljs-comment\"># Define regex grammar to chunk keywords</span>\n\t\tnoun_phrases = <span class=\"hljs-built_in\">list</span>()\n\t\tgrammar = <span class=\"hljs-string\">r\"\"\"\n\t\t\tCHUNK: {&lt;NN&gt;+&lt;IN|DT&gt;*&lt;NN&gt;+}\n\t\t\t\t{&lt;NN&gt;+&lt;IN|DT&gt;*&lt;NNP&gt;+}\n\t\t\t\t{&lt;NNP&gt;+&lt;NNS&gt;*}\n\t\t\t\"\"\"</span>\n\n\t\t<span class=\"hljs-comment\"># Create parser tree</span>\n\t\t<div style=\"display: inline;\" id=\"parsing_0\" class=\"highlights fea_parsing\">chunker = nltk.RegexpParser(grammar)</div>\n\t\t<div style=\"display: inline;\" id=\"tokenization_2\" class=\"highlights fea_tokenization\">tokens = nltk.word_tokenize(sentence)</div>\n\t\t<div style=\"display: inline;\" id=\"Part_of_Speech_1\" class=\"highlights fea_Part_of_Speech\">pos_tokens = nltk.tag.pos_tag(tokens)</div>\n\t\t<div style=\"display: inline;\" id=\"parsing_1\" class=\"highlights fea_parsing\">tree = chunker.parse(pos_tokens)</div>\n\n\t\t<span class=\"hljs-comment\"># Parse tree to identify tokens</span>\n\t\t<span class=\"hljs-keyword\">for</span> subtree <span class=\"hljs-keyword\">in</span> tree.subtrees():\n\t\t\t<span class=\"hljs-keyword\">if</span> subtree.label() == <span class=\"hljs-string\">\"CHUNK\"</span>:\n\t\t\t\ttemp = <span class=\"hljs-string\">\"\"</span>\n\t\t\t\t<span class=\"hljs-keyword\">for</span> sub <span class=\"hljs-keyword\">in</span> subtree:\n\t\t\t\t\ttemp += sub[<span class=\"hljs-number\">0</span>]\n\t\t\t\t\ttemp += <span class=\"hljs-string\">\" \"</span>\n\t\t\t\ttemp = temp.strip()\n\t\t\t\tnoun_phrases.append(temp)\n\n\t\t<span class=\"hljs-comment\"># Handle nouns</span>\n\t\treplace_nouns = []\n\t\t<span class=\"hljs-keyword\">for</span> word, _ <span class=\"hljs-keyword\">in</span> tags:\n\t\t\t<span class=\"hljs-keyword\">for</span> phrase <span class=\"hljs-keyword\">in</span> noun_phrases:\n\t\t\t\t<span class=\"hljs-keyword\">if</span> phrase[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'\\''</span>:\n\t\t\t\t\t<span class=\"hljs-comment\"># If it starts with an apostrophe, ignore it</span>\n\t\t\t\t\t<span class=\"hljs-comment\"># (this is a weird error that should probably be handled elsewhere)</span>\n\t\t\t\t\t<span class=\"hljs-keyword\">break</span>\n\t\t\t\t<span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> phrase:\n\t\t\t\t\t<span class=\"hljs-comment\"># Blank out the last two words in this phrase</span>\n\t\t\t\t\t[replace_nouns.append(phrase_word) <span class=\"hljs-keyword\">for</span> phrase_word <span class=\"hljs-keyword\">in</span> phrase.split()[-<span class=\"hljs-number\">2</span>:]]\n\t\t\t\t\t<span class=\"hljs-keyword\">break</span>\n\t\t\t<span class=\"hljs-comment\"># If we couldn't find the word in any phrases</span>\n\t\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(replace_nouns) == <span class=\"hljs-number\">0</span>:\n\t\t\t\treplace_nouns.append(word)\n\t\t\t<span class=\"hljs-keyword\">break</span>\n\n\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(replace_nouns) == <span class=\"hljs-number\">0</span>:\n\t\t\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">None</span>\n\n\t\tval = <span class=\"hljs-number\">99</span>\n\t\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> replace_nouns:\n\t\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(i) &lt; val:\n\t\t\t\tval = <span class=\"hljs-built_in\">len</span>(i)\n\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\t<span class=\"hljs-keyword\">continue</span>\n\n\t\ttrivial = {\n\t\t\t<span class=\"hljs-string\">\"Answer\"</span>: <span class=\"hljs-string\">\" \"</span>.join(replace_nouns),\n\t\t\t<span class=\"hljs-string\">\"Key\"</span>: val\n\t\t}\n\n\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(replace_nouns) == <span class=\"hljs-number\">1</span>:\n\t\t\t<span class=\"hljs-comment\"># If we're only replacing one word, use WordNet to find similar words</span>\n\t\t\ttrivial[<span class=\"hljs-string\">\"Similar\"</span>] = self.answer_options(replace_nouns[<span class=\"hljs-number\">0</span>])\n\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t<span class=\"hljs-comment\"># If we're replacing a phrase, don't bother - it's too unlikely to make sense</span>\n\t\t\ttrivial[<span class=\"hljs-string\">\"Similar\"</span>] = []\n\n\t\treplace_phrase = <span class=\"hljs-string\">\" \"</span>.join(replace_nouns)\n\t\tblanks_phrase = (<span class=\"hljs-string\">\"__________\"</span> * <span class=\"hljs-built_in\">len</span>(replace_nouns)).strip()\n\t\texpression = re.<span class=\"hljs-built_in\">compile</span>(re.escape(replace_phrase), re.IGNORECASE)\n\t\tsentence = expression.sub(blanks_phrase, <span class=\"hljs-built_in\">str</span>(sentence), count=<span class=\"hljs-number\">1</span>)\n\t\ttrivial[<span class=\"hljs-string\">\"Question\"</span>] = sentence\n\t\t<span class=\"hljs-keyword\">return</span> trivial\n\n<span class=\"hljs-meta\">\t@staticmethod</span>\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">answer_options</span>(<span class=\"hljs-params\">word: <span class=\"hljs-built_in\">str</span></span>) -&gt; list:</span>\n\t\t<span class=\"hljs-string\">\"\"\"Method to identify incorrect answer options.\n\n\t\tArgs:\n\t\t\tword (str): Actual answer to the question which is to be used\n\t\t\t\tfor generating other deceiving options.\n\n\t\tReturns:\n\t\t\tlist: Answer options.\n\t\t\"\"\"</span>\n\t\t<span class=\"hljs-comment\"># In the absence of a better method, take the first synset</span>\n\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\tsynsets = wn.synsets(word, pos=<span class=\"hljs-string\">\"n\"</span>)\n\t\t<span class=\"hljs-keyword\">except</span> Exception:\n\t\t\tlogging.exception(<span class=\"hljs-string\">\"Synsets creation failed.\"</span>, exc_info=<span class=\"hljs-literal\">True</span>)\n\n\t\t<span class=\"hljs-comment\"># If there aren't any synsets, return an empty list</span>\n\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(synsets) == <span class=\"hljs-number\">0</span>:\n\t\t\t<span class=\"hljs-keyword\">return</span> []\n\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\tsynset = synsets[<span class=\"hljs-number\">0</span>]\n\n\t\t<span class=\"hljs-comment\"># Get the hypernym for this synset (again, take the first)</span>\n\t\thypernym = synset.hypernyms()[<span class=\"hljs-number\">0</span>]\n\n\t\t<span class=\"hljs-comment\"># Get some hyponyms from this hypernym</span>\n\t\thyponyms = hypernym.hyponyms()\n\n\t\t<span class=\"hljs-comment\"># Take the name of the first lemma for the first 8 hyponyms</span>\n\t\tsimilar_words = []\n\t\t<span class=\"hljs-keyword\">for</span> hyponym <span class=\"hljs-keyword\">in</span> hyponyms:\n\t\t\tsimilar_word = hyponym.lemmas()[<span class=\"hljs-number\">0</span>].name().replace(<span class=\"hljs-string\">\"_\"</span>, <span class=\"hljs-string\">\" \"</span>)\n\t\t\t<span class=\"hljs-keyword\">if</span> similar_word != word:\n\t\t\t\tsimilar_words.append(similar_word)\n\t\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(similar_words) == <span class=\"hljs-number\">8</span>:\n\t\t\t\t<span class=\"hljs-keyword\">break</span>\n\t\t<span class=\"hljs-keyword\">return</span> similar_words\n\t\t<span class=\"hljs-comment\">#https://github.com/nityansuman/marvin/blob/main/src/objective.py</span></code></pre></div>",
    "fir_23.py": "<div class=\"codeBlock hljs python\" id=\"fir_23\"><pre id=\"fir_23_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> wikipedia <span class=\"hljs-keyword\">as</span> wiki\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> sent_tokenize\n<span class=\"hljs-keyword\">import</span> re\n\n<span class=\"hljs-keyword\">import</span> text2num <span class=\"hljs-keyword\">as</span> t2n\n\n<span class=\"hljs-keyword\">from</span> Quiz <span class=\"hljs-keyword\">import</span> Quiz\n<span class=\"hljs-keyword\">from</span> QuestionSentence <span class=\"hljs-keyword\">import</span> QuestionSentence\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Article</span>():</span>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span> (<span class=\"hljs-params\">self, name</span>):</span>\n        self.name = name\n        self.page = wiki.page(name)\n\n        self.quiz = Quiz([])\n\n        self.generate_questions_for(\n            self.page.content.encode(<span class=\"hljs-string\">'ascii'</span>, <span class=\"hljs-string\">'ignore'</span>))\n\n    <span class=\"hljs-string\">''' \n    NOT CURRENTLY USED, but maye be useful at a later point when knowing the\n    section a question was sourced from might be of use.\n    '''</span>\n    <span class=\"hljs-comment\"># def iterate_sections(self):</span>\n    <span class=\"hljs-comment\">#     # Iterate through article's sections</span>\n    <span class=\"hljs-comment\">#     for section in self.page.sections:</span>\n    <span class=\"hljs-comment\">#         print section</span>\n    <span class=\"hljs-comment\">#         sec = self.page.section(section).encode('ascii', 'ignore')</span>\n    <span class=\"hljs-comment\">#         if sec is None: </span>\n    <span class=\"hljs-comment\">#             continue</span>\n    <span class=\"hljs-comment\">#         self.generate_questions_for(sec)</span>\n\n    <span class=\"hljs-string\">'''\n    tokenizes and chunks a sentence based on a simple grammar\n    '''</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_question_data</span>(<span class=\"hljs-params\">self, s</span>):</span>\n        <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">tokens = nltk.word_tokenize(s)</div>\n        <div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">tagged = nltk.pos_tag(tokens)</div>\n        grammar =   <span class=\"hljs-string\">\"\"\"  \n                    NUMBER: {&lt;$&gt;*&lt;CD&gt;+&lt;NN&gt;*}\n                    LOCATION: {&lt;IN&gt;&lt;NNP&gt;+&lt;,|IN&gt;&lt;NNP&gt;+} \n                    PROPER: {&lt;NNP|NNPS&gt;&lt;NNP|NNPS&gt;+}\n                    \"\"\"</span>       \n        <span class=\"hljs-comment\"># </span>\n        <span class=\"hljs-comment\"># HIT!: {&lt;PROPER&gt;&lt;NN&gt;?&lt;VBZ|VBN&gt;+}</span>\n        <span class=\"hljs-comment\"># DATE: {&lt;IN&gt;(&lt;$&gt;*&lt;CD&gt;+&lt;NN&gt;*)}</span>\n\n        <div style=\"display: inline;\" id=\"parsing_0\" class=\"highlights fea_parsing\">chunker = nltk.RegexpParser(grammar)</div>\n        <div style=\"display: inline;\" id=\"parsing_1\" class=\"highlights fea_parsing\">result = chunker.parse(tagged)</div>\n        <span class=\"hljs-keyword\">return</span> result\n\n    <span class=\"hljs-string\">'''\n    splits a Wikipedia section into sentences and then chunks/tokenizes each\n    sentence\n    '''</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">generate_questions_for</span>(<span class=\"hljs-params\">self, sec</span>):</span>\n        <span class=\"hljs-comment\"># Rid of all parentheses for easier processing</span>\n        _sec = <span class=\"hljs-string\">\"\"</span>.join(re.split(<span class=\"hljs-string\">'\\('</span>, \n            sec.decode(<span class=\"hljs-string\">\"utf-8\"</span>).replace(<span class=\"hljs-string\">\")\"</span>, <span class=\"hljs-string\">\"(\"</span>))[<span class=\"hljs-number\">0</span>::<span class=\"hljs-number\">2</span>])\n\n        <span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sent_tokenize(_sec):\n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">\"==\"</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> sentence:\n                qdata = self.get_question_data(sentence)\n                <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(qdata) &gt;= <span class=\"hljs-number\">75</span> <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\">len</span>(qdata) &lt;= <span class=\"hljs-number\">150</span>:\n                    qdata = []\n\n                self.create_questions(sentence, qdata)\n\n    <span class=\"hljs-string\">'''\n    given a setence in chunked and original form, produce the params necessary\n    to create a Question, and then add that to our Quiz object\n    '''</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">create_questions</span>(<span class=\"hljs-params\">self, sentence, chunked</span>):</span>\n        gaps = []\n        <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> chunked:\n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">type</span>(word) != <span class=\"hljs-built_in\">tuple</span>:                \n                target = []\n                <span class=\"hljs-keyword\">for</span> y <span class=\"hljs-keyword\">in</span> word:\n                    target.append(y[<span class=\"hljs-number\">0</span>])\n                orig_phrase = <span class=\"hljs-string\">\" \"</span>.join(target)\n\n                <span class=\"hljs-keyword\">if</span> word.label() == <span class=\"hljs-string\">\"NUMBER\"</span>:\n                    modified_phrase = orig_phrase[:]\n\n                    <span class=\"hljs-keyword\">try</span>:\n                        <span class=\"hljs-comment\"># convert spelled out word to numerical value</span>\n                        modified_phrase = t2n.text2num(phrase)\n                    <span class=\"hljs-keyword\">except</span>:\n                        <span class=\"hljs-keyword\">try</span>:\n                            test = <span class=\"hljs-built_in\">int</span>(modified_phrase) + <span class=\"hljs-built_in\">float</span>(modified_phrase)\n                        <span class=\"hljs-keyword\">except</span>:\n                            <span class=\"hljs-comment\"># if the word could not be converted and </span>\n                            <span class=\"hljs-comment\"># was not already numerical, ignore it</span>\n                            <span class=\"hljs-keyword\">continue</span>\n\n                    <span class=\"hljs-keyword\">if</span> self.probably_range(modified_phrase):\n                        <span class=\"hljs-keyword\">return</span>\n\n                    gaps.append((word.label(), orig_phrase, modified_phrase))\n                <span class=\"hljs-keyword\">elif</span> word.label() <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\">\"LOCATION\"</span>, <span class=\"hljs-string\">\"PROPER\"</span>]: \n                    gaps.append((word.label(), orig_phrase, orig_phrase))\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(gaps) &gt;= <span class=\"hljs-number\">2</span> <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\">len</span>(gaps) == <span class=\"hljs-built_in\">len</span>(<span class=\"hljs-built_in\">set</span>(gaps)):\n            gaps_filtered = [gap <span class=\"hljs-keyword\">for</span> gap <span class=\"hljs-keyword\">in</span> gaps <span class=\"hljs-keyword\">if</span> gap[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'NUMBER'</span> <span class=\"hljs-keyword\">or</span> gap[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'LOCATION'</span>]\n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(gaps_filtered) <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\">len</span>(gaps) - <span class=\"hljs-built_in\">len</span>(gaps_filtered) &gt; <span class=\"hljs-number\">2</span>:\n                self.quiz.add(QuestionSentence(sentence, gaps_filtered))\n\n    <span class=\"hljs-string\">'''\n    Wikipedia returns non-hyphenated number ranges, so we need to check for mushed together years\n    and remove them. Not a complete solution to the problem, but most of the incidents are years\n    '''</span> \n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">probably_range</span>(<span class=\"hljs-params\">self, val</span>):</span>\n        s = <span class=\"hljs-built_in\">str</span>(val)\n        <span class=\"hljs-keyword\">if</span> s.count(<span class=\"hljs-string\">\"19\"</span>) &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">or</span> s.count(<span class=\"hljs-string\">\"20\"</span>) &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">or</span> (s.count(<span class=\"hljs-string\">\"19\"</span>) == <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">and</span> s.count(<span class=\"hljs-string\">\"20\"</span>) == <span class=\"hljs-number\">1</span>):\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">True</span>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span>\n        <span class=\"hljs-comment\">#https://github.com/alexgreene/WikiQuiz/blob/master/python/Article.py</span></code></pre></div>",
    "fir_1.py": "<div class=\"codeBlock hljs python\" id=\"fir_1\"><pre id=\"fir_1_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># Stopwords removal and lemmatizing them.</span>\n<span class=\"hljs-comment\"># import nltk</span>\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize\n<span class=\"hljs-keyword\">from</span> nltk.stem <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\n\nstop_keywords = [\n    <span class=\"hljs-string\">'i'</span>,\n    <span class=\"hljs-string\">'stack'</span>,\n    <span class=\"hljs-string\">'overflow'</span>,\n    <span class=\"hljs-string\">'web'</span>,\n    <span class=\"hljs-string\">'tutorials'</span>,\n    <span class=\"hljs-string\">'lesson'</span>,\n    <span class=\"hljs-string\">'tip'</span>,\n    <span class=\"hljs-string\">'learn'</span>,\n    <span class=\"hljs-string\">'reference'</span>,\n    <span class=\"hljs-string\">'demo'</span>,\n    <span class=\"hljs-string\">'name'</span>,\n    <span class=\"hljs-string\">'company'</span>,\n    <span class=\"hljs-string\">'w3schools'</span>,\n    <span class=\"hljs-string\">'w3resource'</span>,\n    <span class=\"hljs-string\">'online'</span>,\n    <span class=\"hljs-string\">'this'</span>,\n]\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">text_process</span>(<span class=\"hljs-params\">data</span>):</span>\n\n    return_words = []\n\n    <span class=\"hljs-keyword\">for</span> d <span class=\"hljs-keyword\">in</span> data:\n        stop_words = <span class=\"hljs-built_in\">set</span>(<div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stopwords.words(<span class=\"hljs-string\">'english'</span>)</div>)\n\n        <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">word_tokens = word_tokenize(d)</div>\n\n        filtered_sentence = []\n\n        <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> word_tokens:\n            <span class=\"hljs-keyword\">if</span> w <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> stop_words:\n                filtered_sentence.append(w)\n        <span class=\"hljs-comment\"># print(filtered_sentence)</span>\n\n        <span class=\"hljs-comment\"># Lemmatizing the words.</span>\n        lemma_word = []\n        <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">wordnet_lemmatizer = WordNetLemmatizer()\n        <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> filtered_sentence:\n            word1 = wordnet_lemmatizer.lemmatize(w, pos=<span class=\"hljs-string\">\"n\"</span>)\n            word2 = wordnet_lemmatizer.lemmatize(word1, pos=<span class=\"hljs-string\">\"v\"</span>)\n            worfir = wordnet_lemmatizer.lemmatize(word2, pos=(<span class=\"hljs-string\">\"a\"</span>))</div>\n            lemma_word.append(worfir.lower())\n\n        <span class=\"hljs-comment\"># print(lemma_word)</span>\n        <span class=\"hljs-comment\"># Removing unwanted lemmatized words.</span>\n        lemma_word = <span class=\"hljs-built_in\">set</span>(lemma_word)\n        <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> lemma_word.copy():\n            <span class=\"hljs-keyword\">if</span> ((<span class=\"hljs-built_in\">len</span>(word) &lt;= <span class=\"hljs-number\">3</span>) | (word <span class=\"hljs-keyword\">in</span> stop_keywords)):\n                lemma_word.remove(word)\n        <span class=\"hljs-comment\"># lemma_word = list(lemma_word)</span>\n\n        lemma_word = <span class=\"hljs-built_in\">list</span>(lemma_word)\n    <span class=\"hljs-keyword\">return</span> return_words\n    <span class=\"hljs-comment\">#https://github.com/dhyeythumar/Search-Engine/blob/master/Python_scripts/text_processing.py</span></code></pre></div>",
    "fir_2.py": "<div class=\"codeBlock hljs python\" id=\"fir_2\"><pre id=\"fir_2_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># Tokenize and Stem Data</span>\n<span class=\"hljs-comment\"># Convert words to Vector Space using TFIDF matrix</span>\n<span class=\"hljs-comment\"># Calculate Cosine Similarity and generate the distance matrix</span>\n<span class=\"hljs-comment\"># Uses Ward method to generate an hierarchy</span>\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n<span class=\"hljs-keyword\">from</span> nltk.stem.snowball <span class=\"hljs-keyword\">import</span> SnowballStemmer\n<span class=\"hljs-keyword\">from</span> sklearn.feature_extraction.text <span class=\"hljs-keyword\">import</span> TfidfVectorizer\n<span class=\"hljs-keyword\">from</span> sklearn.metrics.pairwise <span class=\"hljs-keyword\">import</span> cosine_similarity\n<span class=\"hljs-keyword\">from</span> sklearn.manifold <span class=\"hljs-keyword\">import</span> MDS\n<span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> thr\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">from</span> scipy.cluster.hierarchy <span class=\"hljs-keyword\">import</span> ward, dendrogram\n<span class=\"hljs-keyword\">import</span> os\n\n\n<span class=\"hljs-comment\"># Function to return a list of stemmed words</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">tokenize_and_stem</span>(<span class=\"hljs-params\">text_file</span>):</span>\n    <span class=\"hljs-comment\"># declaring stemmer and stopwords language</span>\n    <div style=\"display: inline;\" id=\"stemming_0\" class=\"highlights fea_stemming\">stemmer = SnowballStemmer(<span class=\"hljs-string\">\"english\"</span>)</div>\n    <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stop_words = <span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">'english'</span>))</div>\n    <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">words = word_tokenize(text_file)</div>\n    filtered = [w <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> words <span class=\"hljs-keyword\">if</span> w <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> stop_words]\n    stems = [stemmer.stem(t) <span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> filtered]\n    <span class=\"hljs-keyword\">return</span> stems\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">main</span>():</span>\n\n    path = os.path.abspath(os.path.dirname(__file__))\n    data = pd.read_csv(os.path.join(path, <span class=\"hljs-string\">'data\\headlines_cleaned.txt'</span>), names=[<span class=\"hljs-string\">'text'</span>])\n\n    <span class=\"hljs-comment\"># text data in dataframe and removing stops words</span>\n    stop_words = <span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">'english'</span>))\n    data[<span class=\"hljs-string\">'text'</span>] = data[<span class=\"hljs-string\">'text'</span>].apply(<span class=\"hljs-keyword\">lambda</span> x: <span class=\"hljs-string\">' '</span>.join([word <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> x.split() <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> stop_words]))\n\n    <span class=\"hljs-comment\"># Using TFIDF vectorizer to convert convert words to Vector Space</span>\n    tfidf_vectorizer = TfidfVectorizer(max_features=<span class=\"hljs-number\">200000</span>,\n                                       use_idf=<span class=\"hljs-literal\">True</span>,\n                                       stop_words=<span class=\"hljs-string\">'english'</span>,\n                                       tokenizer=tokenize_and_stem)\n    <span class=\"hljs-comment\">#                                   ngram_range=(1, 3))</span>\n\n    <span class=\"hljs-comment\"># Fit the vectorizer to text data</span>\n    tfidf_matrix = tfidf_vectorizer.fit_transform(data[<span class=\"hljs-string\">'text'</span>])\n\n    <span class=\"hljs-comment\"># Calculating the distance measure derived from cosine similarity</span>\n    distance = <span class=\"hljs-number\">1</span> - cosine_similarity(tfidf_matrix)\n\n    <span class=\"hljs-comment\"># Wards method produces a hierarchy of clusterings</span>\n    linkage_matrix = ward(distance)\n    fig, ax = thr.subplots(figsize=(<span class=\"hljs-number\">15</span>, <span class=\"hljs-number\">20</span>)) <span class=\"hljs-comment\"># set size</span>\n    ax = dendrogram(linkage_matrix, orientation=<span class=\"hljs-string\">\"top\"</span>, labels=data.values)\n    thr.tight_layout()\n    thr.title(<span class=\"hljs-string\">'News Headlines using Ward Hierarchical Method'</span>)\n    thr.savefig(os.path.join(path, <span class=\"hljs-string\">'results\\hierarchical.png'</span>))\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    main()\n    <span class=\"hljs-comment\">#https://github.com/maneeshavinayak/Clustering-News-Headlines/blob/master/clustering/hierarchical.py</span></code></pre></div>",
    "fir_3.py": "<div class=\"codeBlock hljs python\" id=\"fir_3\"><pre id=\"fir_3_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np \n<span class=\"hljs-keyword\">import</span> urllib\n<span class=\"hljs-keyword\">from</span> urllib.request <span class=\"hljs-keyword\">import</span> urlopen\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n<span class=\"hljs-keyword\">from</span> nltk.stem <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> sent_tokenize,word_tokenize\n<span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">from</span> flask <span class=\"hljs-keyword\">import</span> Flask,request,jsonify,make_response\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">from</span> flask_cors <span class=\"hljs-keyword\">import</span> CORS\n<span class=\"hljs-keyword\">import</span> newspaper\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">import</span> time\n\nurl = <span class=\"hljs-string\">\"https://graph.facebook.com/v2.6/me/messages\"</span>\nngrok_url = <span class=\"hljs-string\">'https://the-daily-news-app.herokuapp.com/api/'</span>\n\nsource_csv = pd.read_csv(<span class=\"hljs-string\">'https://raw.githubusercontent.com/codequipo/TheDailyNews/deploy/sites.csv'</span>)\n\napp = Flask(__name__)\nCORS(app)\n\nPORT=<span class=\"hljs-number\">8087</span>\n\n<span class=\"hljs-keyword\">import</span> csv\n\nli_all=[]\nkey_name_all=[]\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">'/'</span>,methods = [<span class=\"hljs-string\">'GET'</span>,<span class=\"hljs-string\">'POST'</span>]</span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">base</span>():</span>\n\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">'hello world'</span>\n\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">'/webhook'</span>, methods=[<span class=\"hljs-string\">'GET'</span>, <span class=\"hljs-string\">'POST'</span>]</span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">webhook</span>():</span>\n\treq = request.get_json(force=<span class=\"hljs-literal\">True</span>)\n\tprint(<span class=\"hljs-string\">\"-\"</span>*<span class=\"hljs-number\">80</span>)\n\tprint(req.get(<span class=\"hljs-string\">'queryResult'</span>).get(<span class=\"hljs-string\">'intent'</span>).get(<span class=\"hljs-string\">'displayName'</span>))\n\tprint(<span class=\"hljs-string\">\"-\"</span>*<span class=\"hljs-number\">80</span>)\n\t<span class=\"hljs-keyword\">if</span> req.get(<span class=\"hljs-string\">'queryResult'</span>).get(<span class=\"hljs-string\">'intent'</span>).get(<span class=\"hljs-string\">'displayName'</span>) == <span class=\"hljs-string\">'summarize_intent'</span>:\n\t\tdatabase_id = req.get(<span class=\"hljs-string\">'queryResult'</span>).get(<span class=\"hljs-string\">'queryText'</span>).strip(<span class=\"hljs-string\">'Summarize:'</span>)\n\t\tsummary_url = ngrok_url + <span class=\"hljs-string\">'getSummary'</span>\n\t\tdata2 = {<span class=\"hljs-string\">'unique_id'</span>: database_id }\n\t\tsummary = requests.post(summary_url,data = data2)\n\t\tarticle_dict = json.loads(summary.text)\n\t\tarticle_summary = article_dict[<span class=\"hljs-string\">'article'</span>][<span class=\"hljs-number\">0</span>][<span class=\"hljs-string\">'text'</span>]\n\t\tarticl_image = article_dict[<span class=\"hljs-string\">'article'</span>][<span class=\"hljs-number\">0</span>][<span class=\"hljs-string\">'top_image'</span>]\n\t\t<span class=\"hljs-keyword\">return</span> {<span class=\"hljs-string\">'fulfillmentText'</span>: article_summary}\n\n\t<span class=\"hljs-keyword\">if</span> req.get(<span class=\"hljs-string\">'queryResult'</span>).get(<span class=\"hljs-string\">'intent'</span>).get(<span class=\"hljs-string\">'displayName'</span>) == <span class=\"hljs-string\">'source_intent'</span>:\n\t\tsource_name = req.get(<span class=\"hljs-string\">'queryResult'</span>).get(<span class=\"hljs-string\">'queryText'</span>)[<span class=\"hljs-number\">7</span>:]\n\t\tsource_csv.columns = [<span class=\"hljs-string\">'name'</span>,<span class=\"hljs-string\">'link'</span>]\n\t\tsource_link = source_csv[<span class=\"hljs-string\">'link'</span>][source_csv.loc[source_csv[<span class=\"hljs-string\">'name'</span>]==source_name].index[<span class=\"hljs-number\">0</span>]]\n\t\tnews_url = ngrok_url + <span class=\"hljs-string\">'getnewsbysources'</span>\n\t\tdata1 = {<span class=\"hljs-string\">'main_urls'</span>:source_link }\n\t\tpost_articles = requests.post(news_url,data = data1)\n\t\tlist_of_articles = json.loads(post_articles.text)\n\t\tli = list_of_articles[<span class=\"hljs-string\">'articles'</span>]\n\t\tmessages = []\n\t\tprint(<span class=\"hljs-built_in\">len</span>(li))\n\t\t<span class=\"hljs-keyword\">for</span> index,item <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(li):\n\t\t\ttemp = <span class=\"hljs-built_in\">dict</span>()\n\t\t\t\n\t\t\treq = urllib.request.Request(<span class=\"hljs-string\">'https://raw.githubusercontent.com/codequipo/TheDailyNews/flask_deploy/format.json'</span>)\n\t\t\t<span class=\"hljs-keyword\">with</span> urllib.request.urlopen(req) <span class=\"hljs-keyword\">as</span> f:\n    \t\t\t\ttemp = json.load(f)\n\t\t\t\n\t\t\t\t\n\t\t\ttemp[<span class=\"hljs-string\">'card'</span>][<span class=\"hljs-string\">'buttons'</span>][<span class=\"hljs-number\">0</span>][<span class=\"hljs-string\">'postback'</span>] = <span class=\"hljs-string\">'Summarize:'</span>+item[<span class=\"hljs-string\">'unique_id'</span>]\n\t\t\ttemp[<span class=\"hljs-string\">'card'</span>][<span class=\"hljs-string\">'title'</span>] = item[<span class=\"hljs-string\">'title'</span>]\n\t\t\ttemp[<span class=\"hljs-string\">'card'</span>][<span class=\"hljs-string\">'imageUri'</span>] = item[<span class=\"hljs-string\">'top_image'</span>]\n\t\t\tprint(item[<span class=\"hljs-string\">'url'</span>])\n\t\t\ttemp[<span class=\"hljs-string\">'card'</span>][<span class=\"hljs-string\">'buttons'</span>][<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'postback'</span>] = item[<span class=\"hljs-string\">'url'</span>]\n\t\t\tmessages.append(temp)\n\n\t\tmessages = messages[:<span class=\"hljs-number\">10</span>]\n\t\t<span class=\"hljs-comment\"># print(messages)</span>\n\t\t<span class=\"hljs-keyword\">return</span> jsonify({<span class=\"hljs-string\">'fulfillmentMessages'</span>: messages })  \n\t\n\n\t<span class=\"hljs-keyword\">return</span>{<span class=\"hljs-string\">'fulfillmentText'</span>:<span class=\"hljs-string\">\"Please check your responses again  \"</span>}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">getSourceData</span>():</span>\n\turl = <span class=\"hljs-string\">'https://raw.githubusercontent.com/codequipo/TheDailyNews/deploy/sites.csv'</span>\n\tdf = pd.read_csv(url, error_bads=<span class=\"hljs-literal\">False</span>)\n\turl_list = []\n\tkey_list = []\n\turl_list = df[<span class=\"hljs-string\">\"http://www.huffingtonpost.com\"</span>].values.tolist()\n\tkey_list = df[<span class=\"hljs-string\">\"huffingtonpost\"</span>].values.tolist()\n\turl_list = [<span class=\"hljs-string\">\"http://www.huffingtonpost.com\"</span>] + url_list\n\tkey_list = [<span class=\"hljs-string\">\"huffingtonpost\"</span>] + key_list\n\t<span class=\"hljs-keyword\">return</span> key_list,url_list\n\nkey_list, url_list= getSourceData()\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/db\"</span>,methods=[<span class=\"hljs-string\">'POST'</span>,<span class=\"hljs-string\">'GET'</span>]</span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">build_database</span>():</span>\n\ttic=time.time()\n\t<span class=\"hljs-comment\"># key_list,url_list = getSourceData()</span>\n\tjson_body=request.get_json(force=<span class=\"hljs-literal\">True</span>)\n\tcurrCount = <span class=\"hljs-built_in\">int</span>(json_body.get(<span class=\"hljs-string\">'currCount'</span>))\n\tnumOfSources = <span class=\"hljs-built_in\">int</span>(json_body.get(<span class=\"hljs-string\">'numOfSources'</span>))\n\tnumOfArticlesPerSources = <span class=\"hljs-built_in\">int</span>(json_body.get(<span class=\"hljs-string\">'numOfArticlesPerSources'</span>))\n\tnum_of_sentences_in_summary = <span class=\"hljs-built_in\">int</span>(json_body.get(<span class=\"hljs-string\">'num_of_sentences_in_summary'</span>))\n\n\tprint(<span class=\"hljs-string\">'currCount : '</span>+<span class=\"hljs-built_in\">str</span>(currCount))\n\n\t\n\tresponse_data=<span class=\"hljs-built_in\">dict</span>()\n\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(currCount,currCount+numOfSources):\n\t\turl=url_list[i]\n\t\tsource = newspaper.build( url, memoize_articles=<span class=\"hljs-literal\">True</span>, language=<span class=\"hljs-string\">'en'</span>)\n\t\t\n\t\td=<span class=\"hljs-built_in\">dict</span>() <span class=\"hljs-comment\"># Holds articles from current selected source </span>\n\t\tk=<span class=\"hljs-number\">0</span>\n\t\t\n\t\t<span class=\"hljs-keyword\">for</span> article <span class=\"hljs-keyword\">in</span> source.articles:\n\t\t\t<span class=\"hljs-keyword\">try</span>:\n\t\t\t\tarticle.download() \n\t\t\t\tarticle.parse() \n\t\t\t\tsummary = driver(article.text,num_of_sentences_in_summary)\n\t\t\t\t\n\t\t\t\tarticle_info=<span class=\"hljs-built_in\">dict</span>()\n\t\t\t\tarticle_info[<span class=\"hljs-string\">'url'</span>]=article.url\n\t\t\t\tarticle_info[<span class=\"hljs-string\">'title'</span>]=article.title\n\t\t\t\tprint(<span class=\"hljs-string\">'i:'</span>+<span class=\"hljs-built_in\">str</span>(i)+<span class=\"hljs-string\">'  k:'</span>+<span class=\"hljs-built_in\">str</span>(k)+<span class=\"hljs-string\">'  title  =&gt; '</span>+article_info[<span class=\"hljs-string\">'title'</span>])\n\t\t\t\tarticle_info[<span class=\"hljs-string\">'text'</span>]=summary\n\t\t\t\tarticle_info[<span class=\"hljs-string\">'top_image'</span>]=article.top_image\n\n\t\t\t\td[k]=article_info\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tk+=<span class=\"hljs-number\">1</span>\n\t\t\t\t<span class=\"hljs-keyword\">if</span> k == numOfArticlesPerSources:\n\t\t\t\t\t<span class=\"hljs-keyword\">break</span>\n\t\t\t<span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:\n\t\t\t\tprint(<span class=\"hljs-string\">\"Entered except block :\"</span>+<span class=\"hljs-built_in\">str</span>(e))\n\t\t\t\t<span class=\"hljs-keyword\">pass</span>\n\t\td[<span class=\"hljs-string\">'length'</span>]=k\n\t\tresponse_data[url]=d\n\n\t\tprint(url+<span class=\"hljs-string\">\"   NewArticles : \"</span>+<span class=\"hljs-built_in\">str</span>(k))\n\n\tresult={\n\t\t<span class=\"hljs-string\">'success'</span>:<span class=\"hljs-literal\">True</span>,\n\t\t<span class=\"hljs-string\">'alldata'</span>:response_data,\n\t\t<span class=\"hljs-string\">'allsite'</span>:url_list[currCount:currCount+numOfSources],\n\t\t<span class=\"hljs-string\">'allsite_key'</span>:key_list[currCount:currCount+numOfSources]\n\t}\n\ttoc=time.time()\n\tdiff=toc-tic\n\tprint(<span class=\"hljs-string\">\"# Time required for function to execute is :\"</span>+<span class=\"hljs-built_in\">str</span>(diff)+<span class=\"hljs-string\">\" # \"</span>)\n\tprint()\n\tprint()\n\t<span class=\"hljs-keyword\">return</span> json.dumps(result)\n\t\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">clean</span>(<span class=\"hljs-params\">sentences</span>):</span>\n\tlemmatizer = WordNetLemmatizer()\n\tcleaned_sentences = []\n\t<span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sentences:\n\t\tsentence = sentence.lower()\n\t\tsentence = re.sub(<span class=\"hljs-string\">r'[^a-zA-Z]'</span>,<span class=\"hljs-string\">' '</span>,sentence)\n\t\tsentence = sentence.split()\n\t\tsentence = [<div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">lemmatizer.lemmatize(word)</div> <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> sentence <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\"></span><div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\"><span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">'english'</span>))</div>]\n\t\tsentence = <span class=\"hljs-string\">' '</span>.join(sentence)\n\t\tcleaned_sentences.append(sentence)\n\t<span class=\"hljs-keyword\">return</span> cleaned_sentences\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">init_probability</span>(<span class=\"hljs-params\">sentences</span>):</span>\n\tprobability_dict = {}\n\t<div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">words = word_tokenize(<span class=\"hljs-string\">'. '</span>.join(sentences))</div>\n\ttotal_words = <span class=\"hljs-built_in\">len</span>(<span class=\"hljs-built_in\">set</span>(words))\n\t<span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> words:\n\t\t<span class=\"hljs-keyword\">if</span> word!=<span class=\"hljs-string\">'.'</span>:\n\t\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> probability_dict.get(word):\n\t\t\t\tprobability_dict[word] = <span class=\"hljs-number\">1</span>\n\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\tprobability_dict[word] += <span class=\"hljs-number\">1</span>\n\n\t<span class=\"hljs-keyword\">for</span> word,count <span class=\"hljs-keyword\">in</span> probability_dict.items():\n\t\tprobability_dict[word] = count/total_words \n\t\n\t<span class=\"hljs-keyword\">return</span> probability_dict\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">update_probability</span>(<span class=\"hljs-params\">probability_dict,word</span>):</span>\n\t<span class=\"hljs-keyword\">if</span> probability_dict.get(word):\n\t\tprobability_dict[word] = probability_dict[word]**<span class=\"hljs-number\">2</span>\n\t<span class=\"hljs-keyword\">return</span> probability_dict\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">average_sentence_weights</span>(<span class=\"hljs-params\">sentences,probability_dict</span>):</span>\n\tsentence_weights = {}\n\t<span class=\"hljs-keyword\">for</span> index,sentence <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(sentences):\n\t\t<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(sentence) != <span class=\"hljs-number\">0</span>:\n\t\t\taverage_proba = <span class=\"hljs-built_in\">sum</span>([probability_dict[word] <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> sentence <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> probability_dict.keys()])\n\t\t\taverage_proba /= <span class=\"hljs-built_in\">len</span>(sentence)\n\t\t\tsentence_weights[index] = average_proba \n\t<span class=\"hljs-keyword\">return</span> sentence_weights\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">generate_summary</span>(<span class=\"hljs-params\">sentence_weights,probability_dict,cleaned_article,tokenized_article,summary_length = <span class=\"hljs-number\">30</span></span>):</span>\n\tsummary = <span class=\"hljs-string\">\"\"</span>\n\tcurrent_length = <span class=\"hljs-number\">0</span>\n\t<span class=\"hljs-keyword\">while</span> current_length &lt; summary_length :\n\t\thighest_probability_word = <span class=\"hljs-built_in\">max</span>(probability_dict,key=probability_dict.get)\n\t\tsentences_with_max_word= [index <span class=\"hljs-keyword\">for</span> index,sentence <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(cleaned_article) <span class=\"hljs-keyword\">if</span> highest_probability_word <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\"></span><div style=\"display: inline;\" id=\"tokenization_1\" class=\"highlights fea_tokenization\"><span class=\"hljs-built_in\">set</span>(word_tokenize(sentence))</div>]\n\t\tsentence_list = <span class=\"hljs-built_in\">sorted</span>([[index,sentence_weights[index]] <span class=\"hljs-keyword\">for</span> index <span class=\"hljs-keyword\">in</span> sentences_with_max_word],key=<span class=\"hljs-keyword\">lambda</span> x:x[<span class=\"hljs-number\">1</span>],reverse=<span class=\"hljs-literal\">True</span>)\n\t\tsummary += tokenized_article[sentence_list[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>]] + <span class=\"hljs-string\">\"\\n\"</span>\n\t\t<span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"tokenization_2\" class=\"highlights fea_tokenization\">word_tokenize(cleaned_article[sentence_list[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>]])</div>:\n\t\t\tprobability_dict = update_probability(probability_dict,word)\n\t\tcurrent_length+=<span class=\"hljs-number\">1</span>\n\t<span class=\"hljs-keyword\">return</span> summary\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">driver</span>(<span class=\"hljs-params\">article,required_length</span>):</span>\n\trequired_length = <span class=\"hljs-built_in\">int</span>(required_length)\n\t<div style=\"display: inline;\" id=\"tokenization_3\" class=\"highlights fea_tokenization\">tokenized_article = sent_tokenize(article)</div>\n\tcleaned_article = clean(tokenized_article) \n\tprobability_dict = init_probability(cleaned_article)\n\tsentence_weights = average_sentence_weights(cleaned_article,probability_dict)\n\t<div style=\"display: inline;\" id=\"summarizer_0\" class=\"highlights fea_summarizer\">summary = generate_summary(sentence_weights,probability_dict,cleaned_article,tokenized_article,required_length)</div>\n\t<span class=\"hljs-keyword\">return</span> summary\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    app.run(port=PORT)\n    <span class=\"hljs-comment\">#https://github.com/codequipo/TheDailyNews/blob/master/flask_server/app.py</span></code></pre></div>",
    "fir_6.py": "<div class=\"codeBlock hljs python\" id=\"fir_6\"><pre id=\"fir_6_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> os,re,math,csv,string,random,logging,glob,itertools,operator,sys\n<span class=\"hljs-keyword\">from</span> os <span class=\"hljs-keyword\">import</span> listdir\n<span class=\"hljs-keyword\">from</span> os.path <span class=\"hljs-keyword\">import</span> isfile, join\n<span class=\"hljs-keyword\">from</span> collections <span class=\"hljs-keyword\">import</span> Counter, defaultdict, OrderedDict\n<span class=\"hljs-keyword\">from</span> itertools <span class=\"hljs-keyword\">import</span> chain, combinations\n\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">import</span> scipy\n<span class=\"hljs-keyword\">from</span> scipy <span class=\"hljs-keyword\">import</span> spatial\n\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize\n<span class=\"hljs-keyword\">from</span> nltk.stem <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> wordnet <span class=\"hljs-keyword\">as</span> wn\n<span class=\"hljs-keyword\">from</span> nltk.tag.stanford <span class=\"hljs-keyword\">import</span> StanfordPOSTagger\n<span class=\"hljs-keyword\">from</span> nltk.util <span class=\"hljs-keyword\">import</span> ngrams\n\n<span class=\"hljs-keyword\">import</span> gensim\n<span class=\"hljs-keyword\">from</span> gensim.models <span class=\"hljs-keyword\">import</span> word2vec\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">InitialCleanup</span>(<span class=\"hljs-params\">dataframe,\n                   minwords=<span class=\"hljs-number\">2</span>,\n                   use_filler_list=<span class=\"hljs-literal\">None</span>,\n                   filler_regex_and_list=<span class=\"hljs-literal\">False</span></span>):</span>\n\n    <span class=\"hljs-string\">\"\"\"\n    Perform basic text cleaning to prepare dataframe\n    for analysis. Remove non-letter/-space characters,\n    empty turns, turns below a minimum length, and\n    fillers.\n\n    By default, preserves turns 2 words or longer.\n    If desired, this may be changed by updating the\n    `minwords` argument.\n\n    By default, remove common fillers through regex.\n    If desired, remove other words by passing a list\n    of literal strings to `use_filler_list` argument,\n    and if both regex and list of additional literal\n    strings are to be used, update `filler_regex_and_list=True`.\n    \"\"\"</span>\n\n    <span class=\"hljs-comment\"># only allow strings, spaces, and newlines to pass</span>\n    WHITELIST = string.ascii_letters + <span class=\"hljs-string\">'\\''</span> + <span class=\"hljs-string\">' '</span>\n\n    <span class=\"hljs-comment\"># remove inadvertent empty turns</span>\n    dataframe = dataframe[pd.notnull(dataframe[<span class=\"hljs-string\">'content'</span>])]\n\n    <span class=\"hljs-comment\"># internal function: remove fillers via regular expressions</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">applyRegExpression</span>(<span class=\"hljs-params\">textFiller</span>):</span>\n        textClean = re.sub(<span class=\"hljs-string\">'^(?!mom|am|ham)[u*|h*|m*|o*|a*]+[m*|h*|u*|a*]+\\s'</span>, <span class=\"hljs-string\">' '</span>, textFiller) <span class=\"hljs-comment\"># at the start of a string</span>\n        textClean = re.sub(<span class=\"hljs-string\">'\\s(?!mom|am|ham)[u*|h*|m*|o*|a*]+[m*|h*|u*|a*]+\\s'</span>, <span class=\"hljs-string\">' '</span>, textClean) <span class=\"hljs-comment\"># within a string</span>\n        textClean = re.sub(<span class=\"hljs-string\">'\\s(?!mom|am|ham)[u*|h*|m*|o*|a*]+[m*|h*|u*|a*]$'</span>, <span class=\"hljs-string\">' '</span>, textClean) <span class=\"hljs-comment\"># end of a string</span>\n        textClean = re.sub(<span class=\"hljs-string\">'^(?!mom|am|ham)[u*|h*|m*|o*|a*]+[m*|h*|u*|a*]$'</span>, <span class=\"hljs-string\">' '</span>, textClean) <span class=\"hljs-comment\"># if entire turn string</span>\n        <span class=\"hljs-keyword\">return</span> textClean\n\n    <span class=\"hljs-comment\"># create a new column with only approved text before cleaning per user-specified settings</span>\n    dataframe[<span class=\"hljs-string\">'clean_content'</span>] = dataframe[<span class=\"hljs-string\">'content'</span>].apply(<span class=\"hljs-keyword\">lambda</span> utterance: <span class=\"hljs-string\">''</span>.join([char <span class=\"hljs-keyword\">for</span> char <span class=\"hljs-keyword\">in</span> utterance <span class=\"hljs-keyword\">if</span> char <span class=\"hljs-keyword\">in</span> WHITELIST]).lower())\n\n    <span class=\"hljs-comment\"># DEFAULT: remove typical speech fillers via regular expressions (examples: \"um, mm, oh, hm, uh, ha\")</span>\n    <span class=\"hljs-keyword\">if</span> use_filler_list <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span> <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> filler_regex_and_list:\n        dataframe[<span class=\"hljs-string\">'clean_content'</span>] = dataframe[<span class=\"hljs-string\">'clean_content'</span>].apply(applyRegExpression)\n\n    <span class=\"hljs-comment\"># OPTION 1: remove speech fillers or other words specified by user in a list</span>\n    <span class=\"hljs-keyword\">elif</span> use_filler_list <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span> <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> filler_regex_and_list:\n        dataframe[<span class=\"hljs-string\">'clean_content'</span>] = dataframe[<span class=\"hljs-string\">'clean_content'</span>].apply(<span class=\"hljs-keyword\">lambda</span> utterance: <span class=\"hljs-string\">' '</span>.join([word <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> utterance.split(<span class=\"hljs-string\">\" \"</span>) <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> use_filler_list]))\n\n    <span class=\"hljs-comment\"># OPTION 2: remove speech fillers via regular expression and any additional words from user-specified list</span>\n    <span class=\"hljs-keyword\">elif</span> use_filler_list <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span> <span class=\"hljs-keyword\">and</span> filler_regex_and_list:\n        dataframe[<span class=\"hljs-string\">'clean_content'</span>] = dataframe[<span class=\"hljs-string\">'clean_content'</span>].apply(applyRegExpression)\n        dataframe[<span class=\"hljs-string\">'clean_content'</span>] = dataframe[<span class=\"hljs-string\">'clean_content'</span>].apply(<span class=\"hljs-keyword\">lambda</span> utterance: <span class=\"hljs-string\">' '</span>.join([word <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> utterance.split(<span class=\"hljs-string\">\" \"</span>) <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> use_filler_list]))\n\n    <span class=\"hljs-comment\"># OPTION 3: nothing is filtered</span>\n    <span class=\"hljs-keyword\">else</span>:\n        dataframe[<span class=\"hljs-string\">'clean_content'</span>] = dataframe[<span class=\"hljs-string\">'clean_content'</span>]\n\n    <span class=\"hljs-comment\"># drop the old \"content\" column and rename the clean \"content\" column</span>\n    dataframe = dataframe.drop([<span class=\"hljs-string\">'content'</span>],axis=<span class=\"hljs-number\">1</span>)\n    dataframe = dataframe.rename(index=<span class=\"hljs-built_in\">str</span>,\n                                 columns ={<span class=\"hljs-string\">'clean_content'</span>: <span class=\"hljs-string\">'content'</span>})\n\n    <span class=\"hljs-comment\"># remove rows that are now blank or do not meet `minwords` requirement, then drop length column</span>\n    dataframe[<span class=\"hljs-string\">'utteranceLen'</span>] = dataframe[<span class=\"hljs-string\">'content'</span>].apply(<span class=\"hljs-keyword\">lambda</span> x: <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">word_tokenize(x)).<span class=\"hljs-built_in\">str</span>.<span class=\"hljs-built_in\">len</span>()</div>\n    dataframe = dataframe.drop(dataframe[dataframe.utteranceLen &lt; <span class=\"hljs-built_in\">int</span>(minwords)].index).drop([<span class=\"hljs-string\">'utteranceLen'</span>],axis=<span class=\"hljs-number\">1</span>)\n    dataframe = dataframe.reset_index(drop=<span class=\"hljs-literal\">True</span>)\n\n    <span class=\"hljs-comment\"># return the cleaned dataframe</span>\n    <span class=\"hljs-keyword\">return</span> dataframe\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">AdjacentMerge</span>(<span class=\"hljs-params\">dataframe</span>):</span>\n\n    <span class=\"hljs-string\">\"\"\"\n    Given a dataframe of conversation turns,\n    merge adjacent turns by the same speaker.\n    \"\"\"</span>\n\n    repeat=<span class=\"hljs-number\">1</span>\n    <span class=\"hljs-keyword\">while</span> repeat==<span class=\"hljs-number\">1</span>:\n        l1=<span class=\"hljs-built_in\">len</span>(dataframe)\n        DfMerge = []\n        k = <span class=\"hljs-number\">0</span>\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(dataframe) &gt; <span class=\"hljs-number\">0</span>:\n            <span class=\"hljs-keyword\">while</span> k &lt; <span class=\"hljs-built_in\">len</span>(dataframe)-<span class=\"hljs-number\">1</span>:\n                <span class=\"hljs-keyword\">if</span> dataframe[<span class=\"hljs-string\">'participant'</span>].iloc[k] != dataframe[<span class=\"hljs-string\">'participant'</span>].iloc[k+<span class=\"hljs-number\">1</span>]:\n                    DfMerge.append([dataframe[<span class=\"hljs-string\">'participant'</span>].iloc[k], dataframe[<span class=\"hljs-string\">'content'</span>].iloc[k]])\n                    k = k + <span class=\"hljs-number\">1</span>\n                <span class=\"hljs-keyword\">elif</span> dataframe[<span class=\"hljs-string\">'participant'</span>].iloc[k] == dataframe[<span class=\"hljs-string\">'participant'</span>].iloc[k+<span class=\"hljs-number\">1</span>]:\n                    DfMerge.append([dataframe[<span class=\"hljs-string\">'participant'</span>].iloc[k], dataframe[<span class=\"hljs-string\">'content'</span>].iloc[k] + <span class=\"hljs-string\">\" \"</span> + dataframe[<span class=\"hljs-string\">'content'</span>].iloc[k+<span class=\"hljs-number\">1</span>]])\n                    k = k + <span class=\"hljs-number\">2</span>\n            <span class=\"hljs-keyword\">if</span> k == <span class=\"hljs-built_in\">len</span>(dataframe)-<span class=\"hljs-number\">1</span>:\n                DfMerge.append([dataframe[<span class=\"hljs-string\">'participant'</span>].iloc[k], dataframe[<span class=\"hljs-string\">'content'</span>].iloc[k]])\n\n        dataframe=pd.DataFrame(DfMerge,columns=(<span class=\"hljs-string\">'participant'</span>,<span class=\"hljs-string\">'content'</span>))\n        <span class=\"hljs-keyword\">if</span> l1==<span class=\"hljs-built_in\">len</span>(dataframe):\n            repeat=<span class=\"hljs-number\">0</span>\n\n    <span class=\"hljs-keyword\">return</span> dataframe\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">Tokenize</span>(<span class=\"hljs-params\">text,nwords</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Given list of text to be processed and a list\n    of known words, return a list of edited and\n    tokenized words.\n\n    Spell-checking is implemented using a\n    Bayesian spell-checking algorithm\n    (http://norvig.com/spell-correct.html).\n\n    By default, this is based on the Project Gutenberg\n    corpus, a collection of approximately 1 million texts\n    (http://www.gutenberg.org). A copy of this is included\n    within this package. If desired, users may specify a\n    different spell-check training corpus in the\n    `training_dictionary` argument of the\n    `prepare_transcripts()` function.\n\n    \"\"\"</span>\n\n    <span class=\"hljs-comment\"># internal function: identify possible spelling errors for a given word</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">edits1</span>(<span class=\"hljs-params\">word</span>):</span>\n        splits     = [(word[:i], word[i:]) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(word) + <span class=\"hljs-number\">1</span>)]\n        deletes    = [a + b[<span class=\"hljs-number\">1</span>:] <span class=\"hljs-keyword\">for</span> a, b <span class=\"hljs-keyword\">in</span> splits <span class=\"hljs-keyword\">if</span> b]\n        transposes = [a + b[<span class=\"hljs-number\">1</span>] + b[<span class=\"hljs-number\">0</span>] + b[<span class=\"hljs-number\">2</span>:] <span class=\"hljs-keyword\">for</span> a, b <span class=\"hljs-keyword\">in</span> splits <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(b)&gt;<span class=\"hljs-number\">1</span>]\n        replaces   = [a + c + b[<span class=\"hljs-number\">1</span>:] <span class=\"hljs-keyword\">for</span> a, b <span class=\"hljs-keyword\">in</span> splits <span class=\"hljs-keyword\">for</span> c <span class=\"hljs-keyword\">in</span> string.ascii_lowercase <span class=\"hljs-keyword\">if</span> b]\n        inserts    = [a + c + b     <span class=\"hljs-keyword\">for</span> a, b <span class=\"hljs-keyword\">in</span> splits <span class=\"hljs-keyword\">for</span> c <span class=\"hljs-keyword\">in</span> string.ascii_lowercase]\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">set</span>(deletes + transposes + replaces + inserts)\n\n    <span class=\"hljs-comment\"># internal function: identify known edits</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">known_edits2</span>(<span class=\"hljs-params\">word,nwords</span>):</span>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">set</span>(e2 <span class=\"hljs-keyword\">for</span> e1 <span class=\"hljs-keyword\">in</span> edits1(word) <span class=\"hljs-keyword\">for</span> e2 <span class=\"hljs-keyword\">in</span> edits1(e1) <span class=\"hljs-keyword\">if</span> e2 <span class=\"hljs-keyword\">in</span> nwords)\n\n    <span class=\"hljs-comment\"># internal function: identify known words</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">known</span>(<span class=\"hljs-params\">words,nwords</span>):</span> <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">set</span>(w <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> words <span class=\"hljs-keyword\">if</span> w <span class=\"hljs-keyword\">in</span> nwords)\n\n    <span class=\"hljs-comment\"># internal function: correct spelling</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">correct</span>(<span class=\"hljs-params\">word,nwords</span>):</span>\n        candidates = known([word],nwords) <span class=\"hljs-keyword\">or</span> known(edits1(word),nwords) <span class=\"hljs-keyword\">or</span> known_edits2(word,nwords) <span class=\"hljs-keyword\">or</span> [word]\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">max</span>(candidates, key=nwords.get)\n\n    <span class=\"hljs-comment\"># expand out based on a fixed list of common contractions</span>\n    contract_dict = { <span class=\"hljs-string\">\"ain't\"</span>: <span class=\"hljs-string\">\"is not\"</span>,\n        <span class=\"hljs-string\">\"aren't\"</span>: <span class=\"hljs-string\">\"are not\"</span>,\n        <span class=\"hljs-string\">\"can't\"</span>: <span class=\"hljs-string\">\"cannot\"</span>,\n        <span class=\"hljs-string\">\"can't've\"</span>: <span class=\"hljs-string\">\"cannot have\"</span>,\n        <span class=\"hljs-string\">\"'cause\"</span>: <span class=\"hljs-string\">\"because\"</span>,\n        <span class=\"hljs-string\">\"could've\"</span>: <span class=\"hljs-string\">\"could have\"</span>,\n        <span class=\"hljs-string\">\"couldn't\"</span>: <span class=\"hljs-string\">\"could not\"</span>,\n        <span class=\"hljs-string\">\"couldn't've\"</span>: <span class=\"hljs-string\">\"could not have\"</span>,\n        <span class=\"hljs-string\">\"didn't\"</span>: <span class=\"hljs-string\">\"did not\"</span>,\n        <span class=\"hljs-string\">\"doesn't\"</span>: <span class=\"hljs-string\">\"does not\"</span>,\n        <span class=\"hljs-string\">\"don't\"</span>: <span class=\"hljs-string\">\"do not\"</span>,\n        <span class=\"hljs-string\">\"hadn't\"</span>: <span class=\"hljs-string\">\"had not\"</span>,\n        <span class=\"hljs-string\">\"hadn't've\"</span>: <span class=\"hljs-string\">\"had not have\"</span>,\n        <span class=\"hljs-string\">\"hasn't\"</span>: <span class=\"hljs-string\">\"has not\"</span>,\n        <span class=\"hljs-string\">\"haven't\"</span>: <span class=\"hljs-string\">\"have not\"</span>,\n        <span class=\"hljs-string\">\"he'd\"</span>: <span class=\"hljs-string\">\"he had\"</span>,\n        <span class=\"hljs-string\">\"he'd've\"</span>: <span class=\"hljs-string\">\"he would have\"</span>,\n        <span class=\"hljs-string\">\"he'll\"</span>: <span class=\"hljs-string\">\"he will\"</span>,\n        <span class=\"hljs-string\">\"he'll've\"</span>: <span class=\"hljs-string\">\"he will have\"</span>,\n        <span class=\"hljs-string\">\"he's\"</span>: <span class=\"hljs-string\">\"he is\"</span>,\n        <span class=\"hljs-string\">\"how'd\"</span>: <span class=\"hljs-string\">\"how did\"</span>,\n        <span class=\"hljs-string\">\"how'd'y\"</span>: <span class=\"hljs-string\">\"how do you\"</span>,\n        <span class=\"hljs-string\">\"how'll\"</span>: <span class=\"hljs-string\">\"how will\"</span>,\n        <span class=\"hljs-string\">\"how's\"</span>: <span class=\"hljs-string\">\"how is\"</span>,\n        <span class=\"hljs-string\">\"i'd\"</span>: <span class=\"hljs-string\">\"i would\"</span>,\n        <span class=\"hljs-string\">\"i'd've\"</span>: <span class=\"hljs-string\">\"i would have\"</span>,\n        <span class=\"hljs-string\">\"i'll\"</span>: <span class=\"hljs-string\">\"i will\"</span>,\n        <span class=\"hljs-string\">\"i'll've\"</span>: <span class=\"hljs-string\">\"i will have\"</span>,\n        <span class=\"hljs-string\">\"i'm\"</span>: <span class=\"hljs-string\">\"i am\"</span>,\n        <span class=\"hljs-string\">\"i've\"</span>: <span class=\"hljs-string\">\"i have\"</span>,\n        <span class=\"hljs-string\">\"isn't\"</span>: <span class=\"hljs-string\">\"is not\"</span>,\n        <span class=\"hljs-string\">\"it'd\"</span>: <span class=\"hljs-string\">\"it would\"</span>,\n        <span class=\"hljs-string\">\"it'd've\"</span>: <span class=\"hljs-string\">\"it would have\"</span>,\n        <span class=\"hljs-string\">\"it'll\"</span>: <span class=\"hljs-string\">\"it will\"</span>,\n        <span class=\"hljs-string\">\"it'll've\"</span>: <span class=\"hljs-string\">\"it will have\"</span>,\n        <span class=\"hljs-string\">\"it's\"</span>: <span class=\"hljs-string\">\"it is\"</span>,\n        <span class=\"hljs-string\">\"let's\"</span>: <span class=\"hljs-string\">\"let us\"</span>,\n        <span class=\"hljs-string\">\"ma'am\"</span>: <span class=\"hljs-string\">\"madam\"</span>,\n        <span class=\"hljs-string\">\"mayn't\"</span>: <span class=\"hljs-string\">\"may not\"</span>,\n        <span class=\"hljs-string\">\"might've\"</span>: <span class=\"hljs-string\">\"might have\"</span>,\n        <span class=\"hljs-string\">\"mightn't\"</span>: <span class=\"hljs-string\">\"might not\"</span>,\n        <span class=\"hljs-string\">\"mightn't've\"</span>: <span class=\"hljs-string\">\"might not have\"</span>,\n        <span class=\"hljs-string\">\"must've\"</span>: <span class=\"hljs-string\">\"must have\"</span>,\n        <span class=\"hljs-string\">\"mustn't\"</span>: <span class=\"hljs-string\">\"must not\"</span>,\n        <span class=\"hljs-string\">\"mustn't've\"</span>: <span class=\"hljs-string\">\"must not have\"</span>,\n        <span class=\"hljs-string\">\"needn't\"</span>: <span class=\"hljs-string\">\"need not\"</span>,\n        <span class=\"hljs-string\">\"needn't've\"</span>: <span class=\"hljs-string\">\"need not have\"</span>,\n        <span class=\"hljs-string\">\"o'clock\"</span>: <span class=\"hljs-string\">\"of the clock\"</span>,\n        <span class=\"hljs-string\">\"oughtn't\"</span>: <span class=\"hljs-string\">\"ought not\"</span>,\n        <span class=\"hljs-string\">\"oughtn't've\"</span>: <span class=\"hljs-string\">\"ought not have\"</span>,\n        <span class=\"hljs-string\">\"shan't\"</span>: <span class=\"hljs-string\">\"shall not\"</span>,\n        <span class=\"hljs-string\">\"sha'n't\"</span>: <span class=\"hljs-string\">\"shall not\"</span>,\n        <span class=\"hljs-string\">\"shan't've\"</span>: <span class=\"hljs-string\">\"shall not have\"</span>,\n        <span class=\"hljs-string\">\"she'd\"</span>: <span class=\"hljs-string\">\"she would\"</span>,\n        <span class=\"hljs-string\">\"she'd've\"</span>: <span class=\"hljs-string\">\"she would have\"</span>,\n        <span class=\"hljs-string\">\"she'll\"</span>: <span class=\"hljs-string\">\"she will\"</span>,\n        <span class=\"hljs-string\">\"she'll've\"</span>: <span class=\"hljs-string\">\"she will have\"</span>,\n        <span class=\"hljs-string\">\"she's\"</span>: <span class=\"hljs-string\">\"she is\"</span>,\n        <span class=\"hljs-string\">\"should've\"</span>: <span class=\"hljs-string\">\"should have\"</span>,\n        <span class=\"hljs-string\">\"shouldn't\"</span>: <span class=\"hljs-string\">\"should not\"</span>,\n        <span class=\"hljs-string\">\"shouldn't've\"</span>: <span class=\"hljs-string\">\"should not have\"</span>,\n        <span class=\"hljs-string\">\"so've\"</span>: <span class=\"hljs-string\">\"so have\"</span>,\n        <span class=\"hljs-string\">\"so's\"</span>: <span class=\"hljs-string\">\"so as\"</span>,\n        <span class=\"hljs-string\">\"that'd\"</span>: <span class=\"hljs-string\">\"that had\"</span>,\n        <span class=\"hljs-string\">\"that'd've\"</span>: <span class=\"hljs-string\">\"that would have\"</span>,\n        <span class=\"hljs-string\">\"that's\"</span>: <span class=\"hljs-string\">\"that is\"</span>,\n        <span class=\"hljs-string\">\"there'd\"</span>: <span class=\"hljs-string\">\"there would\"</span>,\n        <span class=\"hljs-string\">\"there'd've\"</span>: <span class=\"hljs-string\">\"there would have\"</span>,\n        <span class=\"hljs-string\">\"there's\"</span>: <span class=\"hljs-string\">\"there is\"</span>,\n        <span class=\"hljs-string\">\"they'd\"</span>: <span class=\"hljs-string\">\"they would\"</span>,\n        <span class=\"hljs-string\">\"they'd've\"</span>: <span class=\"hljs-string\">\"they would have\"</span>,\n        <span class=\"hljs-string\">\"they'll\"</span>: <span class=\"hljs-string\">\"they will\"</span>,\n        <span class=\"hljs-string\">\"they'll've\"</span>: <span class=\"hljs-string\">\"they will have\"</span>,\n        <span class=\"hljs-string\">\"they're\"</span>: <span class=\"hljs-string\">\"they are\"</span>,\n        <span class=\"hljs-string\">\"they've\"</span>: <span class=\"hljs-string\">\"they have\"</span>,\n        <span class=\"hljs-string\">\"to've\"</span>: <span class=\"hljs-string\">\"to have\"</span>,\n        <span class=\"hljs-string\">\"wasn't\"</span>: <span class=\"hljs-string\">\"was not\"</span>,\n        <span class=\"hljs-string\">\"we'd\"</span>: <span class=\"hljs-string\">\"we would\"</span>,\n        <span class=\"hljs-string\">\"we'd've\"</span>: <span class=\"hljs-string\">\"we would have\"</span>,\n        <span class=\"hljs-string\">\"we'll\"</span>: <span class=\"hljs-string\">\"we will\"</span>,\n        <span class=\"hljs-string\">\"we'll've\"</span>: <span class=\"hljs-string\">\"we will have\"</span>,\n        <span class=\"hljs-string\">\"we're\"</span>: <span class=\"hljs-string\">\"we are\"</span>,\n        <span class=\"hljs-string\">\"we've\"</span>: <span class=\"hljs-string\">\"we have\"</span>,\n        <span class=\"hljs-string\">\"weren't\"</span>: <span class=\"hljs-string\">\"were not\"</span>,\n        <span class=\"hljs-string\">\"what'll\"</span>: <span class=\"hljs-string\">\"what will\"</span>,\n        <span class=\"hljs-string\">\"what'll've\"</span>: <span class=\"hljs-string\">\"what will have\"</span>,\n        <span class=\"hljs-string\">\"what're\"</span>: <span class=\"hljs-string\">\"what are\"</span>,\n        <span class=\"hljs-string\">\"what's\"</span>: <span class=\"hljs-string\">\"what is\"</span>,\n        <span class=\"hljs-string\">\"what've\"</span>: <span class=\"hljs-string\">\"what have\"</span>,\n        <span class=\"hljs-string\">\"when's\"</span>: <span class=\"hljs-string\">\"when is\"</span>,\n        <span class=\"hljs-string\">\"when've\"</span>: <span class=\"hljs-string\">\"when have\"</span>,\n        <span class=\"hljs-string\">\"where'd\"</span>: <span class=\"hljs-string\">\"where did\"</span>,\n        <span class=\"hljs-string\">\"where's\"</span>: <span class=\"hljs-string\">\"where is\"</span>,\n        <span class=\"hljs-string\">\"where've\"</span>: <span class=\"hljs-string\">\"where have\"</span>,\n        <span class=\"hljs-string\">\"who'll\"</span>: <span class=\"hljs-string\">\"who will\"</span>,\n        <span class=\"hljs-string\">\"who'll've\"</span>: <span class=\"hljs-string\">\"who will have\"</span>,\n        <span class=\"hljs-string\">\"who's\"</span>: <span class=\"hljs-string\">\"who is\"</span>,\n        <span class=\"hljs-string\">\"who've\"</span>: <span class=\"hljs-string\">\"who have\"</span>,\n        <span class=\"hljs-string\">\"why's\"</span>: <span class=\"hljs-string\">\"why is\"</span>,\n        <span class=\"hljs-string\">\"why've\"</span>: <span class=\"hljs-string\">\"why have\"</span>,\n        <span class=\"hljs-string\">\"will've\"</span>: <span class=\"hljs-string\">\"will have\"</span>,\n        <span class=\"hljs-string\">\"won't\"</span>: <span class=\"hljs-string\">\"will not\"</span>,\n        <span class=\"hljs-string\">\"won't've\"</span>: <span class=\"hljs-string\">\"will not have\"</span>,\n        <span class=\"hljs-string\">\"would've\"</span>: <span class=\"hljs-string\">\"would have\"</span>,\n        <span class=\"hljs-string\">\"wouldn't\"</span>: <span class=\"hljs-string\">\"would not\"</span>,\n        <span class=\"hljs-string\">\"wouldn't've\"</span>: <span class=\"hljs-string\">\"would not have\"</span>,\n        <span class=\"hljs-string\">\"y'all\"</span>: <span class=\"hljs-string\">\"you all\"</span>,\n        <span class=\"hljs-string\">\"y'all'd\"</span>: <span class=\"hljs-string\">\"you all would\"</span>,\n        <span class=\"hljs-string\">\"y'all'd've\"</span>: <span class=\"hljs-string\">\"you all would have\"</span>,\n        <span class=\"hljs-string\">\"y'all're\"</span>: <span class=\"hljs-string\">\"you all are\"</span>,\n        <span class=\"hljs-string\">\"y'all've\"</span>: <span class=\"hljs-string\">\"you all have\"</span>,\n        <span class=\"hljs-string\">\"you'd\"</span>: <span class=\"hljs-string\">\"you would\"</span>,\n        <span class=\"hljs-string\">\"you'd've\"</span>: <span class=\"hljs-string\">\"you would have\"</span>,\n        <span class=\"hljs-string\">\"you'll\"</span>: <span class=\"hljs-string\">\"you will\"</span>,\n        <span class=\"hljs-string\">\"you'll've\"</span>: <span class=\"hljs-string\">\"you will have\"</span>,\n        <span class=\"hljs-string\">\"you're\"</span>: <span class=\"hljs-string\">\"you are\"</span>,\n        <span class=\"hljs-string\">\"you've\"</span>: <span class=\"hljs-string\">\"you have\"</span> }\n    contractions_re = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">'(%s)'</span> % <span class=\"hljs-string\">'|'</span>.join(<span class=\"hljs-built_in\">list</span>(contract_dict.keys())))\n\n    <span class=\"hljs-comment\"># internal function:</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">expand_contractions</span>(<span class=\"hljs-params\">text, contractions_re=contractions_re</span>):</span>\n        <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">replace</span>(<span class=\"hljs-params\">match</span>):</span>\n            <span class=\"hljs-keyword\">return</span> contract_dict[match.group(<span class=\"hljs-number\">0</span>)]\n        <span class=\"hljs-keyword\">return</span> contractions_re.sub(replace, text.lower())\n\n    <span class=\"hljs-comment\"># process all words in the text</span>\n    cleantoken = []\n    text = expand_contractions(text)\n    <div style=\"display: inline;\" id=\"tokenization_1\" class=\"highlights fea_tokenization\">token = word_tokenize(text)</div>\n    <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> token:\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">\"'\"</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> word:\n            cleantoken.append(correct(word,nwords))\n        <span class=\"hljs-keyword\">else</span>:\n            cleantoken.append(word)\n    <span class=\"hljs-keyword\">return</span> cleantoken\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">pos_to_wn</span>(<span class=\"hljs-params\">tag</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Convert NLTK default tagger output into a format that Wordnet\n    can use in order to properly lemmatize the text.\n    \"\"\"</span>\n\n    <span class=\"hljs-comment\"># create some inner functions for simplicity</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">is_noun</span>(<span class=\"hljs-params\">tag</span>):</span>\n        <span class=\"hljs-keyword\">return</span> tag <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\">'NN'</span>, <span class=\"hljs-string\">'NNS'</span>, <span class=\"hljs-string\">'NNP'</span>, <span class=\"hljs-string\">'NNPS'</span>]\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">is_verb</span>(<span class=\"hljs-params\">tag</span>):</span>\n        <span class=\"hljs-keyword\">return</span> tag <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\">'VB'</span>, <span class=\"hljs-string\">'VBD'</span>, <span class=\"hljs-string\">'VBG'</span>, <span class=\"hljs-string\">'VBN'</span>, <span class=\"hljs-string\">'VBP'</span>, <span class=\"hljs-string\">'VBZ'</span>]\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">is_adverb</span>(<span class=\"hljs-params\">tag</span>):</span>\n        <span class=\"hljs-keyword\">return</span> tag <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\">'RB'</span>, <span class=\"hljs-string\">'RBR'</span>, <span class=\"hljs-string\">'RBS'</span>]\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">is_adjective</span>(<span class=\"hljs-params\">tag</span>):</span>\n        <span class=\"hljs-keyword\">return</span> tag <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\">'JJ'</span>, <span class=\"hljs-string\">'JJR'</span>, <span class=\"hljs-string\">'JJS'</span>]\n\n    <span class=\"hljs-comment\"># check each tag against possible categories</span>\n    <span class=\"hljs-keyword\"></span><div style=\"display: inline;\" id=\"n_grams_0\" class=\"highlights fea_n_grams\"><span class=\"hljs-keyword\">if</span> is_noun(tag):\n        <span class=\"hljs-keyword\">return</span> wn.NOUN\n    <span class=\"hljs-keyword\">elif</span> is_verb(tag):\n        <span class=\"hljs-keyword\">return</span> wn.VERB\n    <span class=\"hljs-keyword\">elif</span> is_adverb(tag):\n        <span class=\"hljs-keyword\">return</span> wn.ADV\n    <span class=\"hljs-keyword\">elif</span> is_adjective(tag):\n        <span class=\"hljs-keyword\">return</span> wn.ADJ\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">return</span> wn.NOUN</div>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">Lemmatize</span>(<span class=\"hljs-params\">tokenlist</span>):</span>\n    l<div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">emmatizer = WordNetLemmatizer()</div>\n    <div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">defaultPos = nltk.pos_tag(tokenlist)</div> <span class=\"hljs-comment\"># get the POS tags from NLTK default tagger</span>\n    words_lemma = []\n    <span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> defaultPos:\n        words_lemma.append(<div style=\"display: inline;\" id=\"lemmatization_1\" class=\"highlights fea_lemmatization\">lemmatizer.lemmatize(item[<span class=\"hljs-number\">0</span>],pos_to_wn(item[<span class=\"hljs-number\">1</span>]))</div>) <span class=\"hljs-comment\"># need to convert POS tags to a format (NOUN, VERB, ADV, ADJ) that wordnet uses to lemmatize</span>\n    <span class=\"hljs-keyword\">return</span> words_lemma\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">ApplyPOSTagging</span>(<span class=\"hljs-params\">df,\n                    filename,\n                    add_stanford_tags=<span class=\"hljs-literal\">False</span>,\n                    stanford_pos_path=<span class=\"hljs-literal\">None</span>,\n                    stanford_language_path=<span class=\"hljs-literal\">None</span></span>):</span>\n\n    <span class=\"hljs-string\">\"\"\"\n    Given a dataframe of conversation turns, return a new\n    dataframe with part-of-speech tagging. Add filename\n    (given as string) as a new column in returned dataframe.\n\n    By default, return only tags from the NLTK default POS\n    tagger. Optionally, also return Stanford POS tagger\n    results by setting `add_stanford_tags=True`.\n\n    If Stanford POS tagging is desired, specify the\n    location of the Stanford POS tagger with the\n    `stanford_pos_path` argument. Also note that the\n    default language model for the Stanford tagger is\n    English (english-left3words-distsim.tagger). To change\n    language model, specify the location with the\n    `stanford_language_path` argument.\n\n    \"\"\"</span>\n\n    <span class=\"hljs-comment\"># if desired, import Stanford tagger</span>\n    <span class=\"hljs-keyword\">if</span> add_stanford_tags:\n        <span class=\"hljs-keyword\">if</span> stanford_pos_path <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span> <span class=\"hljs-keyword\">or</span> stanford_language_path <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n            <span class=\"hljs-keyword\">raise</span> ValueError(<span class=\"hljs-string\">'Error! Specify path to Stanford POS tagger and language model using the `stanford_pos_path` and `stanford_language_path` arguments'</span>)\n        <span class=\"hljs-keyword\">else</span>:\n            <div style=\"display: inline;\" id=\"tagger_0\" class=\"highlights fea_tagger\">stanford_tagger = StanfordPOSTagger(stanford_pos_path + stanford_language_path,\n                                                stanford_pos_path + <span class=\"hljs-string\">'stanford-postagger.jar'</span>)</div>\n\n    <span class=\"hljs-comment\"># add new columns to dataframe</span>\n    df[<span class=\"hljs-string\">'tagged_token'</span>] = df[<span class=\"hljs-string\">'token'</span>].apply(<div style=\"display: inline;\" id=\"Part_of_Speech_1\" class=\"highlights fea_Part_of_Speech\">nltk.pos_tag</div>)\n    df[<span class=\"hljs-string\">'tagged_lemma'</span>] = df[<span class=\"hljs-string\">'lemma'</span>].apply(nltk.pos_tag)\n\n    <span class=\"hljs-comment\"># if desired, also tag with Stanford tagger</span>\n    <span class=\"hljs-keyword\">if</span> add_stanford_tags:\n        df[<span class=\"hljs-string\">'tagged_stan_token'</span>] = df[<span class=\"hljs-string\">'token'</span>].apply(<div style=\"display: inline;\" id=\"tagger_1\" class=\"highlights fea_tagger\">stanford_tagger.tag</div>)\n        df[<span class=\"hljs-string\">'tagged_stan_lemma'</span>] = df[<span class=\"hljs-string\">'lemma'</span>].apply(stanford_tagger.tag)\n\n    df[<span class=\"hljs-string\">'file'</span>] = filename\n\n    <span class=\"hljs-comment\"># return finished dataframe</span>\n    <span class=\"hljs-keyword\">return</span> df\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">prepare_transcripts</span>(<span class=\"hljs-params\">input_files,\n                        output_file_directory,\n                        training_dictionary=<span class=\"hljs-literal\">None</span>,\n                        minwords=<span class=\"hljs-number\">2</span>,\n                        use_filler_list=<span class=\"hljs-literal\">None</span>,\n                        filler_regex_and_list=<span class=\"hljs-literal\">False</span>,\n                        add_stanford_tags=<span class=\"hljs-literal\">False</span>,\n                        stanford_pos_path=<span class=\"hljs-literal\">None</span>,\n                        stanford_language_path=<span class=\"hljs-literal\">None</span>,\n                        input_as_directory=<span class=\"hljs-literal\">True</span>,\n                        save_concatenated_dataframe=<span class=\"hljs-literal\">True</span></span>):</span>\n\n    <span class=\"hljs-string\">\"\"\"\n    Prepare transcripts for similarity analysis.\n\n    Given individual .txt files of conversations,\n    return a completely prepared dataframe of transcribed\n    conversations for later ALIGN analysis, including: text\n    cleaning, merging adjacent turns, spell-checking,\n    tokenization, lemmatization, and part-of-speech tagging.\n    The output serve as the input for later ALIGN\n    analysis.\n\n    Parameters\n    ----------\n\n    input_files : str (directory name) or list of str (file names)\n        Raw files to be cleaned. Behavior governed by `input_as_directory`\n        parameter as well.\n\n    output_file_directory : str\n        Name of directory where output for individual conversations will be\n        saved.\n\n    training_dictionary : str, optional (default: None)\n        Specify whether to train the spell-checking dictionary using a\n        provided file name (str) or the default Project\n        Gutenberg corpus [http://www.gutenberg.org] (None).\n\n    minwords : int, optional (2)\n        Specify the minimum number of words in a turn. Any turns with fewer\n        than the minimum number of words will be removed from the corpus.\n        (Note: `minwords` must be equal to or greater than `maxngram` provided\n        to `calculate_alignment()` and `calculate_baseline_alignment` in later\n        steps.)\n\n    use_filler_list : list of str, optional (default: None)\n        Specify whether words should be filtered from all conversations using a\n        list of filler words (list of str) or using regular expressions to\n        filter out common filler words (None). Behavior governed by\n        `filler_regex_and_list` parameter as well.\n\n    filler_regex_and_list : boolean, optional (default: False)\n        If providing a list to `use_filler_list` parameter, specify whether to\n        use only the provided list (False) or to use both the provided list and\n        the regular expression filter (True).\n\n    add_stanford_tags : boolean, optional (default: False)\n        Specify whether to return part-of-speech similarity scores based on\n        Stanford POS tagger in addition to the Penn POS tagger (True) or to\n        return only POS similarity scores from the Penn tagger (False). (Note:\n        Including Stanford POS tags will lead to a significant increase in\n        processing time.)\n\n    stanford_pos_path : str, optional (default: None)\n        If Stanford POS tagging is desired, specify local path to Stanford POS\n        tagger.\n\n    stanford_language_path : str, optional (default: None)\n        If Stanford POS tagging is desired, specify local path to Stanford POS\n        tagger for the desired language (str) or use the default English tagger\n        (None).\n\n    input_as_directory : boolean, optional (default: True)\n        Specify whether the value passed to `input_files` parameter should\n        be read as a directory (True) or a list of files to be processed\n        (False).\n\n    save_concatenated_dataframe : boolean, optional (default: True)\n        Specify whether to save the individual conversation output data only\n        as individual files in the `output_file_directory` (False) or to save\n        the individual files as well as a single concatenated dataframe (True).\n\n    Returns\n    -------\n\n    prepped_df : Pandas DataFrame\n        A single concatenated dataframe of all transcripts, ready for\n        processing with `calculate_alignment()` and\n        `calculate_baseline_alignment()`.\n\n    \"\"\"</span>\n\n    <span class=\"hljs-comment\"># create an internal function to train the model</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">train</span>(<span class=\"hljs-params\">features</span>):</span>\n        model = defaultdict(<span class=\"hljs-keyword\">lambda</span>: <span class=\"hljs-number\">1</span>)\n        <span class=\"hljs-keyword\">for</span> f <span class=\"hljs-keyword\">in</span> features:\n            model[f] += <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">return</span> model\n\n    <span class=\"hljs-comment\"># if no training dictionary is specified, use the Gutenberg corpus</span>\n    <span class=\"hljs-keyword\">if</span> training_dictionary <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n\n        <span class=\"hljs-comment\"># first, get the name of the package directory</span>\n        module_path = os.path.dirname(os.path.abspath(__file__))\n\n        <span class=\"hljs-comment\"># then construct the path to the text file</span>\n        training_dictionary = os.path.join(module_path, <span class=\"hljs-string\">'data/gutenberg.txt'</span>)\n\n    <span class=\"hljs-comment\"># train our spell-checking model</span>\n    nwords = train(re.findall(<span class=\"hljs-string\">'[a-z]+'</span>, (<span class=\"hljs-built_in\">open</span>(training_dictionary).read().lower())))\n\n    <span class=\"hljs-comment\"># grab the appropriate files</span>\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> input_as_directory:\n        file_list = glob.glob(input_files)\n    <span class=\"hljs-keyword\">else</span>:\n        file_list = glob.glob(input_files+<span class=\"hljs-string\">\"/*.txt\"</span>)\n\n    <span class=\"hljs-comment\"># cycle through all files</span>\n    prepped_df = pd.DataFrame()\n    <span class=\"hljs-keyword\">for</span> fileName <span class=\"hljs-keyword\">in</span> file_list:\n\n        <span class=\"hljs-comment\"># let us know which file we're processing</span>\n        print((<span class=\"hljs-string\">\"Processing: \"</span>+fileName))\n        dataframe = pd.read_csv(fileName, sep=<span class=\"hljs-string\">'\\t'</span>,encoding=<span class=\"hljs-string\">'utf-8'</span>)\n\n        <span class=\"hljs-comment\"># clean up, merge, spellcheck, tokenize, lemmatize, and POS-tag</span>\n        dataframe = InitialCleanup(dataframe,\n                                   minwords=minwords,\n                                   use_filler_list=use_filler_list,\n                                   filler_regex_and_list=filler_regex_and_list)\n        dataframe = AdjacentMerge(dataframe)\n\n        <span class=\"hljs-comment\"># tokenize and lemmatize</span>\n        dataframe[<span class=\"hljs-string\">'token'</span>] = dataframe[<span class=\"hljs-string\">'content'</span>].apply(Tokenize,\n                                     args=(nwords,))\n        dataframe[<span class=\"hljs-string\">'lemma'</span>] = dataframe[<span class=\"hljs-string\">'token'</span>].apply(Lemmatize)\n\n        <span class=\"hljs-comment\"># apply part-of-speech tagging</span>\n        dataframe = ApplyPOSTagging(dataframe,\n                                    filename=os.path.basename(fileName),\n                                    add_stanford_tags=add_stanford_tags,\n                                    stanford_pos_path=stanford_pos_path,\n                                    stanford_language_path=stanford_language_path)\n\n        <span class=\"hljs-comment\"># export the conversation's dataframe as a CSV</span>\n        conversation_file = os.path.join(output_file_directory,os.path.basename(fileName))\n        dataframe.to_csv(conversation_file, encoding=<span class=\"hljs-string\">'utf-8'</span>,index=<span class=\"hljs-literal\">False</span>,sep=<span class=\"hljs-string\">'\\t'</span>)\n        prepped_df = prepped_df.append(dataframe)\n\n    <span class=\"hljs-comment\"># save the concatenated dataframe</span>\n    <span class=\"hljs-keyword\">if</span> save_concatenated_dataframe:\n        concatenated_file = os.path.join(output_file_directory,<span class=\"hljs-string\">'../align_concatenated_dataframe.txt'</span>)\n        prepped_df.to_csv(concatenated_file,\n                    encoding=<span class=\"hljs-string\">'utf-8'</span>,index=<span class=\"hljs-literal\">False</span>, sep=<span class=\"hljs-string\">'\\t'</span>)\n\n    <span class=\"hljs-comment\"># return the dataframe</span>\n    <span class=\"hljs-keyword\">return</span> prepped_df\n    <span class=\"hljs-comment\">#https://github.com/nickduran/align-linguistic-alignment/blob/master/align/prepare_transcripts.py</span></code></pre></div>",
    "fir_8.py": "<div class=\"codeBlock hljs xml\" id=\"fir_8\"><pre id=\"fir_8_code\" ><code class=\"javascript\"># -*- coding: utf-8 -*-\n# Implementation from https://dev.to/davidisrawi/build-a-quick-summarizer-with-python-and-nltk\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\n\nfrom framework.parser.parser import Parser\n\ntext_str = '''\n<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">header</span>&gt;</span>My name is Wil Wheaton. I Live With Chronic Depression and Generalized Anxiety. I Am Not Ashamed.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">header</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Before I begin, I want to warn you that this talk touches on many triggering subjects, including self-harm and suicide. I also want you to know that Im speaking from my personal experience, and that if you or someone you know may be living with mental illness, please talk to a licensed and qualified medical professional, because I am not a doctor.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Okay, lets do this.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Hi, Im Wil Wheaton. Im 45 years-old, I have a wonderful wife, two adult children who make me proud every day, and a daughter in-law who I love like shes my own child. I work on the most popular comedy series in the world, Ive been a New York Times Number One Bestselling Audiobook narrator, I have run out of space in my office for the awards Ive received for my work, and as a white, heterosexual, cisgender man in America, I live life on the lowest difficulty setting  with the Celebrity cheat enabled.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">b</span>&gt;</span>My life is, by every objective measurement, very very good.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">b</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">b</span>&gt;</span>And in spite of all of that, I struggle every day with my self esteem, my self worth, and my value not only as an actor and writer, but as a human being.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">b</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Thats because I live with Depression and Anxiety, the tag team champions of the World Wrestling With Mental Illness Federation.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>And Im not ashamed to stand here, in front of six hundred people in this room, and millions more online, and proudly say that I live with mental illness, and thats okay. I say with because even though my mental illness tries its best, it doesnt control me, it doesnt define me, and I refuse to be stigmatized by it.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">b</span>&gt;</span>So. My name is Wil Wheaton, and I have Chronic Depression.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">b</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>It took me over thirty years to be able to say those ten words, and I suffered for most of them as a result. I suffered because though we in America have done a lot to help people who live with mental illness, we have not done nearly enough to make it okay for our fellow travelers on the wonky brain express to reach out and accept that help.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Im here today to talk with you about working to end the stigma and prejudice that surrounds mental illness in America, and as part of that, I want to share my story with you.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>When I was a little kid, probably seven or eight years old, I started having panic attacks. Back then, we didnt know thats what they were, and because they usually happened when I was asleep, the adults in my life just thought I had nightmares. Well, I did have nightmares, but they were so much worse than just bad dreams. Night after night, Id wake up in absolute terror, and night after night, Id drag my blankets off my bed, to go to sleep on the floor in my sisters bedroom, because I was so afraid to be alone.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>There were occasional stretches of relief, sometimes for months at a time, and during those months, I felt like what I considered to be a normal kid, but the panic attacks always came back, and each time they came back, they seemed worse than before.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>When I was around twelve or thirteen, my anxiety began to express itself in all sorts of delightful ways.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I worried about everything. I was tired all the time, and irritable most of the time. I had no confidence and terrible self-esteem. I felt like I couldnt trust anyone who wanted to be close to me, because I was convinced that I was stupid and worthless and the only reason anyone would want to be my friend was to take advantage of my fame.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>This is important context. When I was thirteen, I was in an internationally-beloved film called Stand by Me, and I was famous. Like, really famous, like, cant-go-to-the-mall-with-my-friends-without-getting-mobbed famous, and that meant that all of my actions were scrutinized by my parents, my peers, my fans, and the press. All the weird, anxious feelings I had all the time? Id been raised to believe that they were shameful. That they reflected poorly on my parents and my family. That they should be crammed down deep inside me, shared with nobody, and kept secret.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>My panic attacks happened daily, and not just when I was asleep. When I tried to reach out to the adults in my life for help, they didnt take me seriously. When I was on the set of a tv show or commercial, and I was having a hard time breathing because I was so anxious about making a mistake and getting fired? The directors and producers complained to my parents that I was being difficult to work with. When I was so uncomfortable with my haircut or my crooked teeth and didnt want to pose for teen magazine photos, the publicists told me that I was being ungrateful and trying to sabotage my success. When I couldnt remember my lines, because I was so anxious about things I cant even remember now, directors would accuse me of being unprofessional and unprepared. And thats when my anxiety turned into depression.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">header</span>&gt;</span>(Im going to take a moment for myself right now, and Im going to tear a hole in the fabric of spacetime and Im going to tell all those adults from the past: give this kid a break. Hes scared. Hes confused. He is doing the best he can, and if you all could stop seeing him as a way to put money into your pockets, maybe you could see that hes suffering and needs help.)<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">header</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I was miserable a lot of the time, and it didnt make any sense. I was living a childhood dream, working on Star Trek: The Next Generation, and getting paid to do what I loved. I had all the video games and board games I ever wanted, and did I mention that I was famous?<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I struggled to reconcile the facts of my life with the reality of my existence. I knew something was wrong with me, but I didnt know what. And because I didnt know what, I didnt know how to ask for help.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I wish I had known that I had a mental illness that could be treated! I wish I had known that that the way I felt wasnt normal and it wasnt necessary. I wish I had known that I didnt deserve to feel bad, all the time.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>And I didnt know those things, because Mental Illness was something my family didnt talk about, and when they did, they talked about it like it was something that happened to someone else, and that it was something they should be ashamed of, because it was a result of something they did. This prejudice existed in my family in spite of the ample incidence of mental illness that ran rampant through my DNA, featuring successful and unsuccessful suicide attempts by my relations, more than one case of bipolar disorder, clinical depression everywhere, and, because of self-medication, so much alcoholism, it was actually notable when someone didnt have a drinking problem.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Now, I dont blame my parents for how they addressed  or more accurately didnt address  my mental illness, because I genuinely believe they were blind to the symptoms I was exhibiting. They grew up and raised me in the world Ive spent the last decade of my life trying to change. They lived in a world where mental illness was equated with weakness, and shame, and as a result, I suffered until I was in my thirties.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>And its not like I never reached out for help. I did! I just didnt know what questions to ask, and the adults I was close to didnt know what answers to give.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Mom, I know youre going to read this or hear this and I know its going to make you upset. I want you to know that I love you, and I know that you did the very best you could. Im telling my story, though, so someone elses mom can see the things you didnt, through no fault of your own.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I clearly remember being twenty-two, living in my own house, waking up from a panic attack that was so terrifying just writing about it for this talk gave me so much anxiety I almost cut this section from my speech. It was the middle of the night, and I drove across town, to my parents house, to sleep on the floor of my sisters bedroom again, because at least thats where I felt safe. The next morning, I tearfully asked my mom what was wrong with me. She knew that many of my blood relatives had mental illness, but she couldnt or wouldnt connect the dots. Youre just realizing that the world is a scary place, she said.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Yeah, no kidding. The world terrifies me every night of my life and I dont know why or how to stop it.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Again, I dont blame her and neither should you. She really was doing the best that she could for me, but stigma and the shame is inspires are powerful things.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I want to be very clear on this: Mom, I know youre going to read this or hear this and I know its going to make you upset. I want you to know that I love you, and I know that you did the very best you could. Im telling my story, though, so someone elses mom can see the things you didnt, through no fault of your own.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Through my twenties, I continued to suffer, and not just from nightmares and panic attacks. I began to develop obsessive behaviors that Ive never talked about in public until right now. Heres a very incomplete list: I began to worry that the things I did would affect the world around me in totally irrational ways. I would hold my breath underneath bridges when I was driving, because if I didnt, maybe Id crash my car. I would tap the side of an airplane with my hand while I was boarding, and tell it to take care of me when I flew places for work, because I was convinced that if I didnt, the plane would crash. Every single time I said goodbye to someone I cared about, my brain would play out in vivid detail how I would remember this as the last time I saw them. Talking about those memories, even without getting into specifics, is challenging. Its painful to recall, but Im not ashamed, because all those thoughts  which I thankfully dont have any more, thanks to medical science and therapy  were not my fault any more than the allergies that clog my sinuses when the trees in my neighborhood start doin it every spring are my fault. Its just part of who I am. Its part of how my brain is wired, and because I know that, I can medically treat it, instead of being a victim of it.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>One of the primary reasons I speak out about my mental illness, is so that I can make the difference in someones life that I wish had been made in mine when I was young, because not only did I have no idea what Depression even was until I was in my twenties, once I was pretty sure that I had it, I suffered with it for another fifteen years, because I was ashamed, I was embarrassed, and I was afraid.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>So I am here today to tell anyone who can hear me: if you suspect that you have a mental illness, there is no reason to be ashamed, or embarrassed, and most importantly, you do not need to be afraid. You do not need to suffer. There is nothing noble in suffering, and there is nothing shameful or weak in asking for help. This may seem really obvious to a lot of you, but it wasnt for me, and Im a pretty smart guy, so Im going to say it anyway: There is no reason to feel embarrassed when you reach out to a professional for help, because the person you are reaching out to is someone who has literally dedicated their life to helping people like us live, instead of merely exist.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I missed out on a lot of things, during what are supposed to be the best years of my life, because I was paralyzed by What If-ing anxiety.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>That difference, between existing and living, is something I want to focus on for a minute: before I got help for my anxiety and depression, I didnt truly live my life. I wanted to go do things with my friends, but my anxiety always found a way to stop me. Traffic would just be too stressful, it would tell me. Its going to be a real hassle to get there and find parking, it would helpfully observe. And if those didnt stop me from leaving my house, there was always the old reliable: What if? Ah, What if something totally unlikely to happen actually happens? What if the plane crashes? What if I sit next to someone who freaks me out? What if they laugh at me? What if I get lost? What if I get robbed? What if I get locked out of my hotel room? What if I slip on some ice I didnt see? What if theres an earthquake? What if what if what if what if<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>When I look back on most of my life, it breaks my heart that when my brain was unloading an endless pile of what ifs on me, it never asked, What if I go do this thing that I want to do, and its  fun? What if I enjoy myself, and Im really glad I went?<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I have to tell you a painful truth: I missed out on a lot of things, during what are supposed to be the best years of my life, because I was paralyzed by What If-ing anxiety.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>All the things that people do when they are living their lives  all those experiences that make up a life, my anxiety got in between me and doing them. So I wasnt living. I was just existing.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>And through it all, I never stopped to ask myself if this was normal, or healthy, or even if it was my fault. I just knew that I was nervous about stuff, and I worried a lot. For my entire childhood, my mom told me that I was a worry wart, and my dad said I was overly dramatic about everything, and thats just the way it was.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Except it didnt have to be that way, and it took me having a full blown panic attack and a complete meltdown at Los Angeles International Airport for my wife to suggest to me that I get help.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Like I said, I had suspected for years that I was clinically depressed, but I was afraid to admit it, until the most important person in my life told me without shame or judgment that she could see that I was suffering. So I went to see a doctor, and I will never forget what he said, when I told him how afraid I was: Please let me help you.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I think it was then, at about 34 years-old, that I realized that Mental Illness is not weakness. Its just an illness. I mean, its right there in the name Mental ILLNESS so it shouldnt have been the revelation that it was, but when the part of our bodies that is responsible for how we perceive the world and ourselves is the same part of our body that is sick, it can be difficult to find objectivity or perspective.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>So I let my doctor help me. I started a low dose of an antidepressant, and I waited to see if anything was going to change.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>And boy did it.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>My wife and I were having a walk in our neighborhood and I realized that it was just a really beautiful day  it was warm with just a little bit of a breeze, the birds sounded really beautiful, the flowers smelled really great and my wifes hand felt really good in mine.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>And as we were walking I just started to cry and she asked me, whats wrong?<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I said I just realized that I dont feel bad and I just realized that Im not existing, Im living.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>At that moment, I realized that I had lived my life in a room that was so loud, all I could do every day was deal with how loud it was. But with the help of my wife, my doctor, and medical science, I found a doorway out of that room.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I had taken that walk with my wife almost every day for nearly ten years, before I ever noticed the birds or the flowers, or how loved I felt when I noticed that her hand was holding mine. Ten years  all of my twenties  that I can never get back. Ten years of suffering and feeling weak and worthless and afraid all the time, because of the stigma that surrounds mental illness.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Im not religious, but I can still say Thank God for Anne Wheaton. Thank God for her love and support. Thank God that my wife saw that I was hurting, and thank God she didnt believe the lie that Depression is weakness, or something to be ashamed of. Thank God for Anne, because if she hadnt had the strength to encourage me to seek professional help, I dont know how much longer I would have been able to even exist, to say nothing of truly living.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I started talking in public about my mental illness in 2012, and ever since then, people reach out to me online every day, and they ask me about living with depression and anxiety. They share their stories, and ask me how I get through a bad day, or a bad week.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">header</span>&gt;</span>Right now, there is a child somewhere who has the same panic attacks I had, and their parents arent getting them help, because they believe it reflects poorly on their parenting to have a child with mental illness.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">header</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Heres one of the things I tell them:<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>One of the many delightful things about having Depression and Anxiety is occasionally and unexpectedly feeling like the whole goddamn world is a heavy lead blanket, like that thing they put on your chest at the dentist when you get x-rays, and its been dropped around your entire existence without your consent.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Physically, it weighs heavier on me in some places than it does in others. I feel it tugging at the corners of my eyes, and pressing down on the center of my chest. When its really bad, it can feel like one of those dreams where you try to move, but every step and every motion feels like youre struggling to move through something heavy and viscous. Emotionally, it covers me completely, separating me from my motivation, my focus, and everything that brings me joy in my life.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>When it drops that lead apron over us, we have to remind ourselves that one of the things Depression does, to keep itself strong and in charge, is tell us lies, like: I am the worst at everything. Nobody really likes me. I dont deserve to be happy. This will never end. And so on and so on. We can know, in our rational minds, that this is a giant bunch of bullshit (and we can look at all these times in our lives when were WERE good at a thing, when we genuinely felt happy, when we felt awful but got through it, etc.) but in the moment, it can be a serious challenge to wait for Depression to lift the roadblock thats keeping us from moving those facts from our rational mind to our emotional selves.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>And thats the thing about Depression: we cant force it to go away. As Ive said, if I could just stop feeling sad I WOULD. (And, also, Depression isnt just feeling sad, right? Its a lot of things together than can manifest themselves into something that is most easily simplified into I feel sad.)<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>So another step in our self care is to be gentle with ourselves. Depression is beating up on us already, and we dont need to help it out. Give yourself permission to acknowledge that youre feeling terrible (or bad, or whatever it is you are feeling), and then do a little thing, just one single thing, that you probably dont feel like doing, and I PROMISE you it will help. Some of those things are:<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">ul</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">li</span>&gt;</span>Take a shower. <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">li</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">li</span>&gt;</span>Eat a nutritious meal. <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">li</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">li</span>&gt;</span>Take a walk outside (even if its literally to the corner and back). <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">li</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">li</span>&gt;</span>Do something  throw a ball, play tug of war, give belly rubs  with a dog. Just about any activity with my dogs, even if its just a snuggle on the couch for a few minutes, helps me. <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">li</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">li</span>&gt;</span>Do five minutes of yoga stretching. <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">li</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">li</span>&gt;</span>Listen to a guided meditation and follow along as best as you can. <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">li</span>&gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">ul</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Finally, please trust me and know that this shitty, awful, overwhelming, terrible way you feel IS NOT FOREVER. It will get better. It always gets better. You are not alone in this fight, and you are OK.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>No person anywhere, especially here in the richest country in the world, should live in the shadows or suffer alone, because they cant afford treatment. We have all the money in the world for weapons and corporate tax cuts, so I know that we can afford to prioritize not just health care in general, but mental health care, specifically.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Right now, there is a child somewhere who has the same panic attacks I had, and their parents arent getting them help, because they believe it reflects poorly on their parenting to have a child with mental illness. Right now, there is a teenager who is contemplating self harm, because they dont know how to reach out and ask for help. Right now, there are too many people struggling just to get to the end of the day, because they cant afford the help that a lot of us cant live without. But there are also people everywhere who are picking up the phone and making an appointment. There are parents who have learned that mental illness is no different than physical illness, and theyre helping their children get better. There are adults who, like me, were terrified that antidepressant medication would make them a different person, and theyre hearing the birds sing for the first time, because they have finally found their way out of the dark room.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>I spent the first thirty years of my life trapped in that dark, loud room, and I know how hopeless and suffocating it feels to be in there, so I do everything I can to help others find their way out. I do that by telling my story, so that my privilege and success does more than enrich my own life. I can live by example for someone else the way Jenny Lawson lives by example for me.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>But I want to leave you today with some suggestions for things that we can all do, even if youre not Internet Famous like I am, to help end the stigma of mental illness, so that nobody has to merely exist, when they could be living.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>We can start by demanding that our elected officials fully fund mental health programs. No person anywhere, especially here in the richest country in the world, should live in the shadows or suffer alone, because they cant afford treatment. We have all the money in the world for weapons and corporate tax cuts, so I know that we can afford to prioritize not just health care in general, but mental health care, specifically.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>And until our elected officials get their acts together, we can support organizations like NAMI, that offer low and no-cost assistance to anyone who asks for it. We can support organizations like Project UROK, that work tirelessly to end stigmatization and remind us that we are sick, not weak.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>We can remember, and we can remind each other, that there is no finish line when it comes to mental illness. Its a journey, and sometimes we can see the path were on all the way to the horizon, while other times we cant even see five feet in front of us because the fog is so thick. But the path is always there, and if we cant locate it on our own, we have loved ones and doctors and medications to help us find it again, as long as we dont give up trying to see it.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>Finally, we who live with mental illness need to talk about it, because our friends and neighbors know us and trust us. Its one thing for me to stand here and tell you that youre not alone in this fight, but its something else entirely for you to prove it. We need to share our experiences, so someone who is suffering the way I was wont feel weird or broken or ashamed or afraid to seek treatment. So that parents dont feel like they have failed or somehow screwed up when they see symptoms in their kids.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>People tell me that Im brave for speaking out the way I do, and while I appreciate that, I dont necessarily agree. Firefighters are brave. Single parents who work multiple jobs to take care of their kids are brave. The Parkland students are brave. People who reach out to get help for their mental illness are brave. Im not brave. Im just a writer and occasional actor who wants to share his privilege and good fortune with the world, who hopes to speak out about mental health so much that one day, it will be wholly unremarkable to stand up and say fifteen words:<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">p</span>&gt;</span>My name is Wil Wheaton, I live with chronic depression, and I am not ashamed.<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">p</span>&gt;</span>\n'''\n\n# All weightage for structure doc\n# Important: These scores are for the experimenting purpose only\nWEIGHT_FOR_LIST = 5\nWEIGHT_FOR_HIGHLIGHTED = 10\nWEIGHT_FOR_NUMERICAL = 5\nWEIGHT_FIRST_PARAGRAPH = 5\nWEIGHT_BASIC = 1\n\n\ndef _create_frequency_table(paragraph_list) -&gt; dict:\n    \"\"\"\n    we create a dictionary for the word frequency table.\n    For this, we should only use the words that are not part of the stopWords array.\n\n    Removing stop words and making frequency table\n    Stemmer - an algorithm to bring words to its root word.\n    :rtype: dict\n    \"\"\"\n    <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stopWords = set(stopwords.words(\"english\"))</div>\n\n    <div style=\"display: inline;\" id=\"stemming_0\" class=\"highlights fea_stemming\">ps = PorterStemmer()</div>\n\n    freqTable = dict()\n    for paragraph in paragraph_list:\n        <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">words = word_tokenize(paragraph.text)</div>\n\n        all_highlighted_sentences = [sent for sent in paragraph.get_highlighted()]\n        highlighted_words_text = \" \".join(all_highlighted_sentences)\n        highlighted_words = word_tokenize(highlighted_words_text)\n\n        for word in words:\n\n            if paragraph.is_list_set:\n                weight = WEIGHT_FOR_LIST\n            else:\n                weight = WEIGHT_BASIC\n\n            if word in highlighted_words:\n                weight += WEIGHT_FOR_HIGHLIGHTED\n\n            if word.isnumeric() and len(word) &gt;= 2:\n                weight += WEIGHT_FOR_NUMERICAL\n\n            if paragraph.is_first_paragraph:\n                weight += WEIGHT_FIRST_PARAGRAPH\n\n            word = ps.stem(word)\n            if word in stopWords:\n                continue\n\n            if word in freqTable:\n                freqTable[word] += weight\n            else:\n                freqTable[word] = weight\n\n    return freqTable\n\n\n<div style=\"display: inline;\" id=\"text_scoring_0\" class=\"highlights fea_text_scoring\">def _score_sentences(sentences, freqTable) -&gt; dict:</div>\n    \"\"\"\n    score a sentence by its words\n    Basic algorithm: adding the frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n    :rtype: dict\n    \"\"\"\n    # TODO: Can you make this multiprocess compatible in python?\n\n    sentenceValue = dict()\n\n    for sentence in sentences:\n        word_count_in_sentence = (len(word_tokenize(sentence)))\n        word_count_in_sentence_except_stop_words = 0\n        for wordValue in freqTable:\n            if wordValue in sentence.lower():\n                word_count_in_sentence_except_stop_words += 1\n                if sentence[:10] in sentenceValue:\n                    sentenceValue[sentence[:10]] += freqTable[wordValue]\n                else:\n                    sentenceValue[sentence[:10]] = freqTable[wordValue]\n\n        if sentence[:10] in sentenceValue:\n            sentenceValue[sentence[:10]] = sentenceValue[sentence[:10]] / word_count_in_sentence_except_stop_words\n\n        '''\n        Notice that a potential issue with our score algorithm is that long sentences will have an advantage over short sentences. \n        To solve this, we're dividing every sentence score by the number of words in the sentence.\n        \n        Note that here sentence[:10] is the first 10 character of any sentence, this is to save memory while saving keys of\n        the dictionary.\n        '''\n\n    return sentenceValue\n\n\ndef _find_average_score(sentenceValue) -&gt; int:\n    \"\"\"\n    Find the average score from the sentence value dictionary\n    :rtype: int\n    \"\"\"\n    sumValues = 0\n    for entry in sentenceValue:\n        sumValues += sentenceValue[entry]\n\n    average = 0\n    # Average value of a sentence from original summary_text\n    if len(sentenceValue) &gt; 0:\n        average = (sumValues / len(sentenceValue))\n\n    return average\n\n\ndef _generate_summary(sentences, sentenceValue, threshold):\n    sentence_count = 0\n    summary = ''\n\n    for sentence in sentences:\n        if sentence[:10] in sentenceValue and sentenceValue[sentence[:10]] &gt;= (threshold):\n            summary += \" \" + sentence\n            sentence_count += 1\n\n    # TODO: check if the sentences in the summarization is in the original order of occurrence.\n\n    return summary\n\n\ndef run_summarization(paragraph_list):\n    # 1 Create the word frequency table\n    freq_table = _create_frequency_table(paragraph_list)\n    # print (freq_table)\n\n    '''\n    We already have a sentence tokenizer, so we just need \n    to run the sent_tokenize() method to create the array of sentences.\n    '''\n\n    # 2 Tokenize the sentences\n    sentences = [paragraph.text for paragraph in paragraph_list]\n    # print(sentences)\n\n    # 3 Important Algorithm: score the sentences\n    sentence_scores = _score_sentences(sentences, freq_table)\n\n    # 4 Find the threshold\n    threshold = _find_average_score(sentence_scores)\n\n    # 5 Important Algorithm: Generate the summary\n    summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n\n    return summary\n\n\nif __name__ == '__main__':\n    parser = Parser()\n    parser.feed(text_str)\n    <div style=\"display: inline;\" id=\"summarizer_0\" class=\"highlights fea_summarizer\">result = run_summarization(parser.paragraphs)</div>\n    print(result)\n    #https://github.com/akashp1712/summarize-webpage/blob/master/implementation/word_frequency_summarize_parser.py</code></pre></div>",
    "fir_9.py": "<div class=\"codeBlock hljs python\" id=\"fir_9\"><pre id=\"fir_9_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> constants\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">import</span> random\n<span class=\"hljs-keyword\">from</span> sklearn.feature_extraction.text <span class=\"hljs-keyword\">import</span> TfidfVectorizer\n<span class=\"hljs-keyword\">from</span> sklearn.metrics.pairwise <span class=\"hljs-keyword\">import</span> cosine_similarity\n<span class=\"hljs-keyword\">import</span> string\n<span class=\"hljs-keyword\">import</span> warnings\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_formalities_response</span>(<span class=\"hljs-params\">formality</span>) :</span>\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">any</span>(remove_punctuation_marks(formality).lower() <span class=\"hljs-keyword\">in</span> remove_punctuation_marks(greet).lower() <span class=\"hljs-keyword\">for</span> greet <span class=\"hljs-keyword\">in</span> constants.GREETING_INPUTS) :\n        <span class=\"hljs-keyword\">return</span> random.choice(constants.GREETING_REPLIES)\n    <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">any</span>(remove_punctuation_marks(formality).lower() <span class=\"hljs-keyword\">in</span> remove_punctuation_marks(thanks).lower() <span class=\"hljs-keyword\">for</span> thanks <span class=\"hljs-keyword\">in</span> constants.THANKS_INPUTS) :\n        <span class=\"hljs-keyword\">return</span> random.choice(constants.THANKS_REPLIES)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_lemmatized_tokens</span>(<span class=\"hljs-params\">text</span>) :</span>\n    <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">normalized_tokens = nltk.word_tokenize(remove_punctuation_marks(text.lower()))</div>\n    <span class=\"hljs-keyword\">return</span> [<div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">nltk.stem.WordNetLemmatizer().lemmatize(normalized_token)</div> <span class=\"hljs-keyword\">for</span> normalized_token <span class=\"hljs-keyword\">in</span> normalized_tokens]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_query_reply</span>(<span class=\"hljs-params\">query</span>) :</span>\n    documents.append(query)\n    tfidf_results = TfidfVectorizer(tokenizer = get_lemmatized_tokens, stop_words = <span class=\"hljs-string\">'english'</span>).fit_transform(documents)\n    cosine_similarity_results = cosine_similarity(tfidf_results[-<span class=\"hljs-number\">1</span>], tfidf_results).flatten()\n    <span class=\"hljs-comment\"># The last will be 1.0 because it is the Cosine Similarity between the first document and itself</span>\n    best_index = cosine_similarity_results.argsort()[-<span class=\"hljs-number\">2</span>]\n    documents.remove(query)\n    <span class=\"hljs-keyword\">if</span> cosine_similarity_results[best_index] == <span class=\"hljs-number\">0</span> :\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\"I am sorry! I don't understand you...\"</span>\n    <span class=\"hljs-keyword\">else</span> :\n        <span class=\"hljs-keyword\">return</span> documents[best_index]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_punctuation_marks</span>(<span class=\"hljs-params\">text</span>) :</span>\n    punctuation_marks = <span class=\"hljs-built_in\">dict</span>((<span class=\"hljs-built_in\">ord</span>(punctuation_mark), <span class=\"hljs-literal\">None</span>) <span class=\"hljs-keyword\">for</span> punctuation_mark <span class=\"hljs-keyword\">in</span> string.punctuation)\n    <span class=\"hljs-keyword\">return</span> text.translate(punctuation_marks)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span> :\n    warnings.filterwarnings(<span class=\"hljs-string\">\"ignore\"</span>)\n\n    <span class=\"hljs-keyword\">try</span> :\n        nltk.data.find(<span class=\"hljs-string\">'tokenizers/punkt'</span>)\n    <span class=\"hljs-keyword\">except</span> LookupError:\n        nltk.download(<span class=\"hljs-string\">'punkt'</span>)\n\n    <span class=\"hljs-keyword\">try</span> :\n        nltk.data.find(<span class=\"hljs-string\">'corpora/wordnet'</span>)\n    <span class=\"hljs-keyword\">except</span> LookupError:\n        <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">nltk.download(<span class=\"hljs-string\">'wordnet'</span>)</div>\n\n    corpus = <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">'corpus.txt'</span>, <span class=\"hljs-string\">'r'</span> , errors = <span class=\"hljs-string\">'ignore'</span>).read().lower()\n    <div style=\"display: inline;\" id=\"tokenization_1\" class=\"highlights fea_tokenization\">documents = nltk.sent_tokenize(corpus)</div>\n\n    <div style=\"display: inline;\" id=\"chatbot_0\" class=\"highlights fea_chatbot\">print(<span class=\"hljs-string\">'RyuzakiBot: My name is RyuzakiBot. I will answer your queries about World Wide Web. If you want to exit just type: Bye!'</span>)\n    end_chat = <span class=\"hljs-literal\">False</span>\n    <span class=\"hljs-keyword\">while</span> end_chat == <span class=\"hljs-literal\">False</span> :\n        input_text = <span class=\"hljs-built_in\">input</span>()\n        <span class=\"hljs-keyword\">if</span> remove_punctuation_marks(input_text).lower() != <span class=\"hljs-string\">'bye'</span> :\n            formality_reply = get_formalities_response(input_text)\n            <span class=\"hljs-keyword\">if</span>  formality_reply :\n                print(<span class=\"hljs-string\">'RyuzakiBot: '</span> + formality_reply)\n            <span class=\"hljs-keyword\">else</span> :\n                print(<span class=\"hljs-string\">'RyuzakiBot: '</span> + get_query_reply(input_text))\n        <span class=\"hljs-keyword\">else</span> :\n            print(<span class=\"hljs-string\">'RyuzakiBot: Bye! Take care '</span> + random.choice(constants.CANDIES))\n            end_chat = <span class=\"hljs-literal\">True</span></div><span class=\"hljs-literal\"></span>\n            <span class=\"hljs-comment\">#https://github.com/LuciaLlavero/ryuzaki_bot/blob/master/ryuzaki_bot_desktop.py</span></code></pre></div>",
    "fir_10.py": "<div class=\"codeBlock hljs python\" id=\"fir_10\"><pre id=\"fir_10_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># coding: utf-8</span>\n\n<span class=\"hljs-keyword\">import</span> constants\n<span class=\"hljs-keyword\">from</span> flask <span class=\"hljs-keyword\">import</span> Flask, jsonify, request\n<span class=\"hljs-keyword\">from</span> flask_cors <span class=\"hljs-keyword\">import</span> CORS\n<span class=\"hljs-keyword\">from</span> flask_restful <span class=\"hljs-keyword\">import</span> Resource, Api\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">import</span> random\n<span class=\"hljs-keyword\">from</span> sklearn.feature_extraction.text <span class=\"hljs-keyword\">import</span> TfidfVectorizer\n<span class=\"hljs-keyword\">from</span> sklearn.metrics.pairwise <span class=\"hljs-keyword\">import</span> cosine_similarity\n<span class=\"hljs-keyword\">import</span> string\n<span class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\">import</span> warnings\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_formalities_reply</span>(<span class=\"hljs-params\">formality</span>) :</span>\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">any</span>(remove_punctuation_marks(formality).lower() <span class=\"hljs-keyword\">in</span> remove_punctuation_marks(greet).lower() <span class=\"hljs-keyword\">for</span> greet <span class=\"hljs-keyword\">in</span> constants.GREETING_INPUTS) :\n        <span class=\"hljs-keyword\">return</span> random.choice(constants.GREETING_REPLIES)\n    <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">any</span>(remove_punctuation_marks(formality).lower() <span class=\"hljs-keyword\">in</span> remove_punctuation_marks(thanks).lower() <span class=\"hljs-keyword\">for</span> thanks <span class=\"hljs-keyword\">in</span> constants.THANKS_INPUTS) :\n        <span class=\"hljs-keyword\">return</span> random.choice(constants.THANKS_REPLIES)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_lemmatized_tokens</span>(<span class=\"hljs-params\">text</span>):</span>\n    <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">normalized_tokens = nltk.word_tokenize(remove_punctuation_marks(text.lower()))</div>\n    <span class=\"hljs-keyword\">return</span> [<div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">nltk.stem.WordNetLemmatizer().lemmatize(normalized_token)</div> <span class=\"hljs-keyword\">for</span> normalized_token <span class=\"hljs-keyword\">in</span> normalized_tokens]\n\ncorpus = <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">'corpus.txt'</span>, <span class=\"hljs-string\">'r'</span> , errors = <span class=\"hljs-string\">'ignore'</span>).read().lower()\ndocuments = nltk.sent_tokenize(corpus)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_query_reply</span>(<span class=\"hljs-params\">query</span>) :</span>    \n    documents.append(query)\n    tfidf_results = TfidfVectorizer(tokenizer = get_lemmatized_tokens, stop_words = <span class=\"hljs-string\">'english'</span>).fit_transform(documents)\n    cosine_similarity_results = cosine_similarity(tfidf_results[-<span class=\"hljs-number\">1</span>], tfidf_results).flatten()\n    <span class=\"hljs-comment\"># The last will be 1.0 because it is the Cosine Similarity between the first document and itself</span>\n    best_index = cosine_similarity_results.argsort()[-<span class=\"hljs-number\">2</span>]\n    documents.remove(query)\n    <span class=\"hljs-keyword\">if</span> cosine_similarity_results[best_index] == <span class=\"hljs-number\">0</span> :\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\"I am sorry! I don't understand you...\"</span>\n    <span class=\"hljs-keyword\">else</span> :\n        <span class=\"hljs-keyword\">return</span> documents[best_index]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_punctuation_marks</span>(<span class=\"hljs-params\">text</span>) :</span>\n    punctuation_marks = <span class=\"hljs-built_in\">dict</span>((<span class=\"hljs-built_in\">ord</span>(punctuation_mark), <span class=\"hljs-literal\">None</span>) <span class=\"hljs-keyword\">for</span> punctuation_mark <span class=\"hljs-keyword\">in</span> string.punctuation)\n    <span class=\"hljs-keyword\">return</span> text.translate(punctuation_marks)\n\napp = Flask(__name__)\ncors = CORS(app)\napi = Api(app)\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Reply</span>(<span class=\"hljs-params\">Resource</span>) :</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get</span>(<span class=\"hljs-params\">self</span>) :</span>\n        <span class=\"hljs-keyword\">if</span> request.args.get(<span class=\"hljs-string\">'q'</span>) :\n            formality_reply = get_formalities_reply(request.args.get(<span class=\"hljs-string\">'q'</span>))\n            <span class=\"hljs-keyword\">if</span>  formality_reply :\n                <span class=\"hljs-keyword\">return</span> jsonify({<span class=\"hljs-string\">'reply'</span>: formality_reply + <span class=\"hljs-string\">' '</span> + random.choice(constants.SWEETS)})\n            <span class=\"hljs-keyword\">else</span> :\n                <span class=\"hljs-keyword\">return</span> jsonify({<span class=\"hljs-string\">'reply'</span>: get_query_reply(request.args.get(<span class=\"hljs-string\">'q'</span>))})\n        <span class=\"hljs-keyword\">else</span> :\n            <span class=\"hljs-keyword\">return</span> jsonify({<span class=\"hljs-string\">'error'</span>: <span class=\"hljs-string\">'query is empty'</span>})\n\napi.add_resource(Reply, <span class=\"hljs-string\">'/reply.json'</span>)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span> :\n\n    app.run()\n    <span class=\"hljs-comment\">#https://github.com/LuciaLlavero/ryuzaki_bot/blob/master/ryuzaki_bot.py</span></code></pre></div>",
    "fir_11.py": "<div class=\"codeBlock hljs python\" id=\"fir_11\"><pre id=\"fir_11_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">from</span> newspaper <span class=\"hljs-keyword\">import</span> Article\n<span class=\"hljs-keyword\">from</span> geograpy.labels <span class=\"hljs-keyword\">import</span> Labels\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Extractor</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-string\">'''\n    Extract geo context for text or from url\n    '''</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, text=<span class=\"hljs-literal\">None</span>, url=<span class=\"hljs-literal\">None</span>, debug=<span class=\"hljs-literal\">False</span></span>):</span>\n        <span class=\"hljs-string\">'''\n        Constructor\n        Args:\n\n            text(string): the text to analyze\n            url(string): the url to read the text to analyze from\n            debug(boolean): if True show debug information\n        '''</span>\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> text <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> url:\n            <span class=\"hljs-keyword\">raise</span> Exception(<span class=\"hljs-string\">'text or url is required'</span>)\n        self.debug=debug\n        self.text = text\n        self.url = url\n        self.places = []\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">set_text</span>(<span class=\"hljs-params\">self</span>):</span>\n        <span class=\"hljs-string\">'''\n        Setter for text\n        '''</span>\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> self.text <span class=\"hljs-keyword\">and</span> self.url:\n            a = Article(self.url)\n            a.download()\n            a.parse()\n            self.text = a.text\n            \n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">split</span>(<span class=\"hljs-params\">self,delimiter=<span class=\"hljs-string\">r\",\"</span></span>):</span>\n        <span class=\"hljs-string\">'''\n        simpler regular expression splitter with not entity check\n        \n        hat tip: https://stackoverflow.com/a/1059601/1497139\n        '''</span>\n        self.set_text()\n        self.places=re.split(delimiter,self.text)\n            \n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">find_geoEntities</span>(<span class=\"hljs-params\">self</span>):</span>\n        <span class=\"hljs-string\">'''\n        Find geographic entities\n        \n        Returns:\n            list: \n                List of places\n        '''</span>\n        self.find_entities(Labels.geo)\n        <span class=\"hljs-keyword\">return</span> self.places\n        \n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">find_entities</span>(<span class=\"hljs-params\">self,labels=Labels.default</span>):</span>\n        <span class=\"hljs-string\">'''\n        Find entities with the given labels set self.places and returns it\n        Args:\n            labels: \n                Labels: The labels to filter\n        Returns:\n            list: \n                List of places\n        '''</span>\n        self.set_text()\n\n        <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">text = nltk.word_tokenize(self.text)</div>\n        nes = nltk.ne_chunk(<div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">nltk.pos_tag(text)</div>)\n\n        <span class=\"hljs-keyword\">for</span> ne <span class=\"hljs-keyword\">in</span> nes:\n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">type</span>(ne) <span class=\"hljs-keyword\">is</span> nltk.tree.Tree:\n                nelabel=ne.label()\n                <span class=\"hljs-keyword\">if</span> (nelabel <span class=\"hljs-keyword\">in</span> labels):\n                    leaves=ne.leaves()\n                    <span class=\"hljs-keyword\">if</span> self.debug:\n                        print(leaves)\n                    self.places.append(<span class=\"hljs-string\">u' '</span>.join([i[<span class=\"hljs-number\">0</span>] <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> leaves]))\n        <span class=\"hljs-keyword\">return</span> self.places\n        <span class=\"hljs-comment\">#https://github.com/somnathrakshit/geograpy3/blob/master/geograpy/extraction.py</span></code></pre></div>",
    "fir_12.py": "<div class=\"codeBlock hljs python\" id=\"fir_12\"><pre id=\"fir_12_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> sys,re,collections,nltk\n<span class=\"hljs-keyword\">from</span> nltk.stem.wordnet <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize\n\n<span class=\"hljs-comment\"># patterns that used to find or/and replace particular chars or words</span>\n<span class=\"hljs-comment\"># to find chars that are not a letter, a blank or a quotation</span>\npat_letter = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r'[^a-zA-Z \\']+'</span>)\n<span class=\"hljs-comment\"># to find the 's following the pronouns. re.I is refers to ignore case</span>\npat_is = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"(it|he|she|that|this|there|here)(\\'s)\"</span>, re.I)\n<span class=\"hljs-comment\"># to find the 's following the letters</span>\npat_s = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"(?&lt;=[a-zA-Z])\\'s\"</span>)\n<span class=\"hljs-comment\"># to find the ' following the words ending by s</span>\npat_s2 = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"(?&lt;=s)\\'s?\"</span>)\n<span class=\"hljs-comment\"># to find the abbreviation of not</span>\npat_not = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"(?&lt;=[a-zA-Z])n\\'t\"</span>)\n<span class=\"hljs-comment\"># to find the abbreviation of would</span>\npat_would = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"(?&lt;=[a-zA-Z])\\'d\"</span>)\n<span class=\"hljs-comment\"># to find the abbreviation of will</span>\npat_will = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"(?&lt;=[a-zA-Z])\\'ll\"</span>)\n<span class=\"hljs-comment\"># to find the abbreviation of am</span>\npat_am = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"(?&lt;=[I|i])\\'m\"</span>)\n<span class=\"hljs-comment\"># to find the abbreviation of are</span>\npat_are = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"(?&lt;=[a-zA-Z])\\'re\"</span>)\n<span class=\"hljs-comment\"># to find the abbreviation of have</span>\npat_ve = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"(?&lt;=[a-zA-Z])\\'ve\"</span>)\n\n\nlmtzr = WordNetLemmatizer()\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_words</span>(<span class=\"hljs-params\">file</span>):</span>  \n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span> (file) <span class=\"hljs-keyword\">as</span> f:  \n        words_box=[]\n        pat = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r'[^a-zA-Z \\']+'</span>)\n        <span class=\"hljs-keyword\">for</span> line <span class=\"hljs-keyword\">in</span> f:                           \n            <span class=\"hljs-comment\">#if re.match(r'[a-zA-Z]*',line): </span>\n            <span class=\"hljs-comment\">#    words_box.extend(line.strip().strip('\\'\\\"\\.,').lower().split())</span>\n            <span class=\"hljs-comment\"># words_box.extend(pat.sub(' ', line).strip().lower().split())</span>\n            words_box.extend(merge(replace_abbreviations(line).split()))\n    <span class=\"hljs-keyword\">return</span> collections.Counter(words_box)  \n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">merge</span>(<span class=\"hljs-params\">words</span>):</span>\n    new_words = []\n    <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> words:\n        <span class=\"hljs-keyword\">if</span> word:\n            tag = <div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">nltk.pos_tag</div>(<div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">word_tokenize(word)</div>) <span class=\"hljs-comment\"># tag is like [('bigger', 'JJR')]</span>\n            pos = get_wordnet_pos(tag[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">1</span>])\n            <span class=\"hljs-keyword\">if</span> pos:\n                <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">lemmatized_word = lmtzr.lemmatize(word, pos)</div>\n                new_words.append(lemmatized_word)\n            <span class=\"hljs-keyword\">else</span>:\n                new_words.append(word)\n    <span class=\"hljs-keyword\">return</span> new_words\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_wordnet_pos</span>(<span class=\"hljs-params\">treebank_tag</span>):</span>\n    <span class=\"hljs-keyword\"></span><div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\"><span class=\"hljs-keyword\">if</span> treebank_tag.startswith(<span class=\"hljs-string\">'J'</span>):\n        <span class=\"hljs-keyword\">return</span> nltk.corpus.wordnet.ADJ\n    <span class=\"hljs-keyword\">elif</span> treebank_tag.startswith(<span class=\"hljs-string\">'V'</span>):\n        <span class=\"hljs-keyword\">return</span> nltk.corpus.wordnet.VERB\n    <span class=\"hljs-keyword\">elif</span> treebank_tag.startswith(<span class=\"hljs-string\">'N'</span>):\n        <span class=\"hljs-keyword\">return</span> nltk.corpus.wordnet.NOUN\n    <span class=\"hljs-keyword\">elif</span> treebank_tag.startswith(<span class=\"hljs-string\">'R'</span>):\n        <span class=\"hljs-keyword\">return</span> nltk.corpus.wordnet.ADV</div>\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">''</span>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">replace_abbreviations</span>(<span class=\"hljs-params\">text</span>):</span>\n    new_text = text\n    new_text = pat_letter.sub(<span class=\"hljs-string\">' '</span>, text).strip().lower()\n    new_text = pat_is.sub(<span class=\"hljs-string\">r\"\\1 is\"</span>, new_text)\n    new_text = pat_s.sub(<span class=\"hljs-string\">\"\"</span>, new_text)\n    new_text = pat_s2.sub(<span class=\"hljs-string\">\"\"</span>, new_text)\n    new_text = pat_not.sub(<span class=\"hljs-string\">\" not\"</span>, new_text)\n    new_text = pat_would.sub(<span class=\"hljs-string\">\" would\"</span>, new_text)\n    new_text = pat_will.sub(<span class=\"hljs-string\">\" will\"</span>, new_text)\n    new_text = pat_am.sub(<span class=\"hljs-string\">\" am\"</span>, new_text)\n    new_text = pat_are.sub(<span class=\"hljs-string\">\" are\"</span>, new_text)\n    new_text = pat_ve.sub(<span class=\"hljs-string\">\" have\"</span>, new_text)\n    new_text = new_text.replace(<span class=\"hljs-string\">'\\''</span>, <span class=\"hljs-string\">' '</span>)\n    <span class=\"hljs-keyword\">return</span> new_text\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">append_ext</span>(<span class=\"hljs-params\">words</span>):</span>\n    new_words = []\n    <span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> words:\n        word, count = item\n        tag = nltk.pos_tag(word_tokenize(word))[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">1</span>] <span class=\"hljs-comment\"># tag is like [('bigger', 'JJR')]</span>\n        new_words.append((word, count, tag))\n    <span class=\"hljs-keyword\">return</span> new_words\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">write_to_file</span>(<span class=\"hljs-params\">words, file=<span class=\"hljs-string\">'results.txt'</span></span>):</span>\n    f = <span class=\"hljs-built_in\">open</span>(file, <span class=\"hljs-string\">'w'</span>)\n    <span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> words:\n        <span class=\"hljs-keyword\">for</span> field <span class=\"hljs-keyword\">in</span> item:\n            f.write(<span class=\"hljs-built_in\">str</span>(field)+<span class=\"hljs-string\">','</span>)\n        f.write(<span class=\"hljs-string\">'\\n'</span>)\n\n\n<span class=\"hljs-keyword\">if</span> __name__==<span class=\"hljs-string\">'__main__'</span>:\n    book = sys.argv[<span class=\"hljs-number\">1</span>]\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"counting...\"</span>\n    words = get_words(book)\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"writing file...\"</span>\n    write_to_file(append_ext(words.most_common()))\n    <span class=\"hljs-comment\">#https://github.com/rocketk/wordcounter/blob/master/wordcounter/word_counter.py</span></code></pre></div>",
    "fir_13.py": "<div class=\"codeBlock hljs python\" id=\"fir_13\"><pre id=\"fir_13_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># -*- coding: utf-8 -*-</span>\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> ast\n<span class=\"hljs-keyword\">import</span> argparse\n<span class=\"hljs-keyword\">import</span> argcomplete\n<span class=\"hljs-keyword\">import</span> multiprocessing\n<span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> partial\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> TweetTokenizer\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n<span class=\"hljs-keyword\">import</span> gensim\n<span class=\"hljs-keyword\">from</span> gensim <span class=\"hljs-keyword\">import</span> utils, corpora, models\n<span class=\"hljs-keyword\">import</span> io\n\n<div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">ignore_words = <span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">'english'</span>))</div>\n\n<span class=\"hljs-string\">''' from the model that was created, you can calculate the topic probability distribution of unseen documents.\n    this is a command line interface using Gensim for preprocessing unseen\n    documents and calculating topic probability distributions over a given topology from an LDA model '''</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">write_topn_words</span>(<span class=\"hljs-params\">output_dir, lda</span>):</span>\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(output_dir + <span class=\"hljs-string\">'topn_words.json'</span>):\n        print(<span class=\"hljs-string\">'Writing topn words for LDA model'</span>)\n        reg_ex = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">'(?&lt;![\\s/])/[^\\s/]+(?![\\S/])'</span>)\n        topn_words = {<span class=\"hljs-string\">'Topic '</span> + <span class=\"hljs-built_in\">str</span>(i + <span class=\"hljs-number\">1</span>): [reg_ex.sub(<span class=\"hljs-string\">''</span>, word) <span class=\"hljs-keyword\">for</span> word, prob <span class=\"hljs-keyword\">in</span> lda.show_topic(i, topn=<span class=\"hljs-number\">20</span>)] <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, lda.num_topics)}\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(output_dir + <span class=\"hljs-string\">'topn_words.json'</span>, <span class=\"hljs-string\">'w'</span>) <span class=\"hljs-keyword\">as</span> outfile:\n            json.dump(topn_words, outfile, sort_keys=<span class=\"hljs-literal\">True</span>, indent=<span class=\"hljs-number\">4</span>)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">preprocess_tweet</span>(<span class=\"hljs-params\">document, lemma</span>):</span>\n    <span class=\"hljs-keyword\">with</span> io.<span class=\"hljs-built_in\">open</span>(document, <span class=\"hljs-string\">'r'</span>, encoding=<span class=\"hljs-string\">\"utf-8\"</span>) <span class=\"hljs-keyword\">as</span> infile:\n        text = <span class=\"hljs-string\">' '</span>.join(line.rstrip(<span class=\"hljs-string\">'\\n'</span>) <span class=\"hljs-keyword\">for</span> line <span class=\"hljs-keyword\">in</span> infile)\n    <span class=\"hljs-comment\"># convert string into unicode</span>\n    text = gensim.utils.any2unicode(text)\n    <span class=\"hljs-comment\"># remove URL's</span>\n    text = re.sub(<span class=\"hljs-string\">r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*'</span>, <span class=\"hljs-string\">''</span>, text)\n    <span class=\"hljs-comment\"># remove symbols excluding the @, # and \\s symbol</span>\n    text = re.sub(<span class=\"hljs-string\">r'[^\\w@#\\s]'</span>, <span class=\"hljs-string\">''</span>, text)\n    <span class=\"hljs-keyword\">if</span> lemma:\n        <span class=\"hljs-keyword\">return</span> utils.lemmatize(text, stopwords=ignore_words, min_length=<span class=\"hljs-number\">3</span>)\n    <span class=\"hljs-comment\"># tokenize words using NLTK Twitter Tokenizer</span>\n    <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">tknzr = TweetTokenizer()\n    text = tknzr.tokenize(text)</div>\n    <span class=\"hljs-comment\"># lowercase, remove words less than len 2 &amp; remove numbers in tokenized list</span>\n    <span class=\"hljs-keyword\">return</span> [word.lower() <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> text <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(word) &gt; <span class=\"hljs-number\">2</span> <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> word.isdigit() <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> word <span class=\"hljs-keyword\">in</span> ignore_words]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_document_vectors</span>(<span class=\"hljs-params\">user_id, **kwargs</span>):</span>\n    print(<span class=\"hljs-string\">'Getting document vectors for: '</span> + user_id)\n    <span class=\"hljs-keyword\">if</span> os.path.exists(kwargs[<span class=\"hljs-string\">'tweets_dir'</span>] + user_id):\n        tweetpath = kwargs[<span class=\"hljs-string\">'tweets_dir'</span>] + user_id\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">return</span>\n\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> user_id <span class=\"hljs-keyword\">in</span> kwargs[<span class=\"hljs-string\">'document_vectors'</span>]:\n        document = preprocess_tweet(tweetpath, kwargs[<span class=\"hljs-string\">'lemma'</span>])\n        <span class=\"hljs-comment\"># if after preprocessing, the list is empty, then skip that user</span>\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> document:\n            <span class=\"hljs-keyword\">return</span>\n        <span class=\"hljs-comment\"># create bag of words from input document</span>\n        doc_bow = kwargs[<span class=\"hljs-string\">'dictionary'</span>].doc2bow(document)\n        <span class=\"hljs-comment\"># queries the document against the LDA model and associates the data with probabalistic topics</span>\n        doc_lda = get_doc_topics(kwargs[<span class=\"hljs-string\">'lda_model'</span>], doc_bow)\n        dense_vec = gensim.matutils.sparse2full(doc_lda, kwargs[<span class=\"hljs-string\">'lda_model'</span>].num_topics)\n        <span class=\"hljs-comment\"># build dictionary of user document vectors &lt;k, v&gt;(user_id, vec)</span>\n        <span class=\"hljs-keyword\">return</span> (user_id, dense_vec.tolist())\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">return</span> (user_id, kwargs[<span class=\"hljs-string\">'document_vectors'</span>][user_id])\n\n<span class=\"hljs-comment\"># http://stackoverflow.com/questions/17310933/document-topical-distribution-in-gensim-lda</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_doc_topics</span>(<span class=\"hljs-params\">lda, bow</span>):</span>\n    gamma, _ = lda.inference([bow])\n    topic_dist = gamma[<span class=\"hljs-number\">0</span>] / <span class=\"hljs-built_in\">sum</span>(gamma[<span class=\"hljs-number\">0</span>])\n    <span class=\"hljs-keyword\">return</span> [(topic_id, topic_value) <span class=\"hljs-keyword\">for</span> topic_id, topic_value <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(topic_dist)]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">community_document_vectors</span>(<span class=\"hljs-params\">doc_vecs, community</span>):</span>\n    comm_doc_vecs = {}\n    <span class=\"hljs-keyword\">for</span> user <span class=\"hljs-keyword\">in</span> ast.literal_eval(community):\n        <span class=\"hljs-keyword\">try</span>:\n            comm_doc_vecs[<span class=\"hljs-built_in\">str</span>(user)] = doc_vecs[<span class=\"hljs-built_in\">str</span>(user)]\n        <span class=\"hljs-keyword\">except</span>:\n            <span class=\"hljs-keyword\">pass</span>\n    <span class=\"hljs-keyword\">return</span> comm_doc_vecs\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">read_json</span>(<span class=\"hljs-params\">file_name</span>):</span>\n    <span class=\"hljs-keyword\">try</span>:\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(file_name, <span class=\"hljs-string\">'r'</span>) <span class=\"hljs-keyword\">as</span> comm_doc_vecs_file:\n            <span class=\"hljs-keyword\">return</span> json.load(comm_doc_vecs_file)\n    <span class=\"hljs-keyword\">except</span>:\n        <span class=\"hljs-keyword\">return</span> {}\n \n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">main</span>():</span>\n    <span class=\"hljs-comment\"># this program uses an LDA model to vectorize 'documents' and outputs a json file containing {user: [topic probability distribution vector]} results</span>\n    <span class=\"hljs-comment\"># it also creates the directories for the communities generated from the topology file, putting each community document vectors json file in corresponding directory</span>\n    parser = argparse.ArgumentParser(description=<span class=\"hljs-string\">'Create a corpus from a collection of tweets and/or build an LDA model'</span>)\n    parser.add_argument(<span class=\"hljs-string\">'-t'</span>, <span class=\"hljs-string\">'--topology_file'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'top_file'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location of topology file'</span>)\n    parser.add_argument(<span class=\"hljs-string\">'-p'</span>, <span class=\"hljs-string\">'--dir_prefix'</span>, choices=[<span class=\"hljs-string\">'clique'</span>, <span class=\"hljs-string\">'community'</span>], required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'dir_prefix'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Select whether the topology contains cliques or communities'</span>)\n    parser.add_argument(<span class=\"hljs-string\">'-w'</span>, <span class=\"hljs-string\">'--working_dir'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'working_dir'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Name of the directory you want to direct output to'</span>)\n    parser.add_argument(<span class=\"hljs-string\">'-l'</span>, <span class=\"hljs-string\">'--lda_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'lda_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location of the saved LDA model'</span>)\n    parser.add_argument(<span class=\"hljs-string\">'-d'</span>, <span class=\"hljs-string\">'--dict_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'dict_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location of dictionary for the model'</span>)\n    parser.add_argument(<span class=\"hljs-string\">'-u'</span>, <span class=\"hljs-string\">'--unseen_docs'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'unseen_docs'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Directory containing unseen documents'</span>)\n    parser.add_argument(<span class=\"hljs-string\">'-m'</span>, <span class=\"hljs-string\">'--lemma'</span>, action=<span class=\"hljs-string\">'store_true'</span>, dest=<span class=\"hljs-string\">'lemma'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Use this option to lemmatize words'</span>)\n    argcomplete.autocomplete(parser)\n    args = parser.parse_args()\n\n    output_dir = os.path.join(args.working_dir, <span class=\"hljs-string\">''</span>)\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(os.path.dirname(output_dir)):\n        os.makedirs(os.path.dirname(output_dir), <span class=\"hljs-number\">0o755</span>)\n\n    <span class=\"hljs-comment\"># load dictionary</span>\n    model_dict = corpora.Dictionary.load(args.dict_loc)\n    <span class=\"hljs-comment\"># load trained model from file</span>\n    lda = models.LdaModel.load(args.lda_loc)\n    write_topn_words(output_dir, lda)\n\n    <span class=\"hljs-comment\"># create a set of all users from topology file</span>\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(args.top_file, <span class=\"hljs-string\">'r'</span>) <span class=\"hljs-keyword\">as</span> inp_file:\n        users = <span class=\"hljs-built_in\">set</span>(<span class=\"hljs-built_in\">str</span>(user) <span class=\"hljs-keyword\">for</span> community <span class=\"hljs-keyword\">in</span> inp_file <span class=\"hljs-keyword\">for</span> user <span class=\"hljs-keyword\">in</span> ast.literal_eval(community))\n\n    <span class=\"hljs-comment\"># opens up a 'job in progress' if ran this program and stopped it</span>\n    <span class=\"hljs-keyword\">try</span>:\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(output_dir + <span class=\"hljs-string\">'document_vectors.json'</span>, <span class=\"hljs-string\">'r'</span>) <span class=\"hljs-keyword\">as</span> all_community_file:\n            document_vectors = json.load(all_community_file)\n    <span class=\"hljs-keyword\">except</span>:\n        document_vectors = {}\n\n    <span class=\"hljs-comment\"># use multiprocessing to query document vectors</span>\n    pool = multiprocessing.Pool(<span class=\"hljs-built_in\">max</span>(<span class=\"hljs-number\">1</span>, multiprocessing.cpu_count() - <span class=\"hljs-number\">1</span>))\n    func = partial(get_document_vectors,\n                   tweets_dir=args.unseen_docs,\n                   document_vectors=document_vectors,\n                   dictionary=model_dict,\n                   lda_model=lda,\n                   lemma=args.lemma)\n    doc_vecs = pool.<span class=\"hljs-built_in\">map</span>(func, users)\n    doc_vecs = [item <span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> doc_vecs <span class=\"hljs-keyword\">if</span> item <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>]\n    pool.close()\n    pool.join()\n    doc_vecs = <span class=\"hljs-built_in\">dict</span>(doc_vecs) <span class=\"hljs-comment\"># {user: [topic probability distribution vector]}</span>\n\n    document_vectors.update(doc_vecs)\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(output_dir + <span class=\"hljs-string\">'document_vectors.json'</span>, <span class=\"hljs-string\">'w'</span>) <span class=\"hljs-keyword\">as</span> document_vectors_file:\n        json.dump(document_vectors, document_vectors_file, sort_keys=<span class=\"hljs-literal\">True</span>, indent=<span class=\"hljs-number\">4</span>)\n\n    print(<span class=\"hljs-string\">'Building directories'</span>)\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(args.top_file, <span class=\"hljs-string\">'r'</span>) <span class=\"hljs-keyword\">as</span> topology_file:\n        <span class=\"hljs-keyword\">for</span> i, community <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(topology_file):\n            community_dir = os.path.join(output_dir, args.dir_prefix + <span class=\"hljs-string\">'_'</span> + <span class=\"hljs-built_in\">str</span>(i) + <span class=\"hljs-string\">'/'</span>)\n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> os.path.exists(os.path.dirname(community_dir)):\n                os.makedirs(os.path.dirname(community_dir), <span class=\"hljs-number\">0o755</span>)\n            comm_doc_vecs = community_document_vectors(doc_vecs, community)\n            <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(community_dir + <span class=\"hljs-string\">'community_doc_vecs.json'</span>, <span class=\"hljs-string\">'w'</span>) <span class=\"hljs-keyword\">as</span> comm_docs_file:\n                json.dump(comm_doc_vecs, comm_docs_file, sort_keys=<span class=\"hljs-literal\">True</span>, indent=<span class=\"hljs-number\">4</span>)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    sys.exit(main())\n    <span class=\"hljs-comment\">#https://github.com/kethort/TwitterLDATopicModeling/blob/master/src/tweets_on_LDA.py</span></code></pre></div>",
    "fir_14.py": "<div class=\"codeBlock hljs python\" id=\"fir_14\"><pre id=\"fir_14_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> logging\n<span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\">import</span> bz2\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> itertools\n<span class=\"hljs-keyword\">import</span> tarfile\n<span class=\"hljs-keyword\">import</span> multiprocessing\n<span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> partial\n<span class=\"hljs-keyword\">import</span> gensim\n<span class=\"hljs-keyword\">from</span> gensim.corpora <span class=\"hljs-keyword\">import</span> MmCorpus, Dictionary, WikiCorpus\n<span class=\"hljs-keyword\">from</span> gensim <span class=\"hljs-keyword\">import</span> models, utils\n<span class=\"hljs-keyword\">import</span> pyLDAvis\n<span class=\"hljs-keyword\">from</span> pyLDAvis <span class=\"hljs-keyword\">import</span> gensim <span class=\"hljs-keyword\">as</span> gensim_vis\n<span class=\"hljs-keyword\">import</span> argparse\n<span class=\"hljs-keyword\">import</span> argcomplete\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> TweetTokenizer\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n<span class=\"hljs-keyword\">from</span> nltk.stem <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\n\n<span class=\"hljs-string\">''' a command-line utility for the Gensim library that creates LDA model either from a folder of texts \n    or a wikipedia dump. '''</span>\n\nDEFAULT_DICT_SIZE = <span class=\"hljs-number\">100000</span>\n<div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">ignore_words = <span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">'english'</span>))</div>\n\nlogging.basicConfig(<span class=\"hljs-built_in\">format</span>=<span class=\"hljs-string\">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)\n\n<span class=\"hljs-comment\"># an 'override' of the Gensim WikiCorpus tokenizer function</span>\n<span class=\"hljs-comment\"># compares against nltk stopword list to omit useless words</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">wiki_tokenizer</span>(<span class=\"hljs-params\">content, token_min_len=<span class=\"hljs-number\">3</span>, token_max_len=<span class=\"hljs-number\">15</span>, lower=<span class=\"hljs-literal\">True</span></span>):</span>\n    <span class=\"hljs-keyword\">return</span> [\n        utils.to_unicode(token) <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> utils.simple_preprocess(content, deacc=<span class=\"hljs-literal\">True</span>, min_len=<span class=\"hljs-number\">3</span>) \n        <span class=\"hljs-keyword\">if</span> token_min_len &lt;= <span class=\"hljs-built_in\">len</span>(token) &lt;= token_max_len <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> token.startswith(<span class=\"hljs-string\">'_'</span>) <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> token.isdigit()\n        <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> token <span class=\"hljs-keyword\">in</span> ignore_words\n    ]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">preprocess_text</span>(<span class=\"hljs-params\">lemma, document</span>):</span>\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(document, <span class=\"hljs-string\">'r'</span>) <span class=\"hljs-keyword\">as</span> infile:\n        <span class=\"hljs-comment\"># transform document into one string</span>\n        text = <span class=\"hljs-string\">' '</span>.join(line.rstrip(<span class=\"hljs-string\">'\\n'</span>) <span class=\"hljs-keyword\">for</span> line <span class=\"hljs-keyword\">in</span> infile)\n    <span class=\"hljs-comment\"># convert string into unicode</span>\n    text = gensim.utils.any2unicode(text)\n\n    <span class=\"hljs-comment\"># remove URL's</span>\n    text = re.sub(<span class=\"hljs-string\">r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*'</span>, <span class=\"hljs-string\">''</span>, text)\n\n    <span class=\"hljs-comment\"># remove symbols excluding the @, # and \\s symbol</span>\n    text = re.sub(<span class=\"hljs-string\">r'[^\\w@#\\s]'</span>, <span class=\"hljs-string\">''</span>, text)\n    \n    <span class=\"hljs-comment\"># use the built-in Gensim lemmatize engine </span>\n    <span class=\"hljs-keyword\">if</span> lemma:\n        <span class=\"hljs-keyword\">return</span> utils.lemmatize(text, stopwords=ignore_words, min_length=<span class=\"hljs-number\">3</span>)\n\n    <span class=\"hljs-comment\"># tokenize words using NLTK Twitter Tokenizer</span>\n    <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">tknzr = TweetTokenizer()\n    text = tknzr.tokenize(text)</div>\n\n    <span class=\"hljs-comment\"># lowercase, remove words less than len 2 &amp; remove numbers in tokenized list</span>\n    <span class=\"hljs-keyword\">return</span> [word.lower() <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> text <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(word) &gt; <span class=\"hljs-number\">2</span> <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> word.isdigit() <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> word <span class=\"hljs-keyword\">in</span> ignore_words]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">filenames_to_generator</span>(<span class=\"hljs-params\">directory</span>):</span>\n    <span class=\"hljs-keyword\">for</span> filename <span class=\"hljs-keyword\">in</span> os.listdir(directory):\n        <span class=\"hljs-keyword\">yield</span> directory + <span class=\"hljs-built_in\">str</span>(filename)\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">DocCorpus</span>(<span class=\"hljs-params\">gensim.corpora.TextCorpus</span>):</span>\n    <span class=\"hljs-comment\"># overrides the get_texts function of Gensim TextCorpus in order to use </span>\n    <span class=\"hljs-comment\"># directory of texts as corpus, where each text file is a document</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, docs_loc, lemmatize, dictionary=<span class=\"hljs-literal\">None</span>, metadata=<span class=\"hljs-literal\">None</span></span>):</span>\n        self.docs_loc = docs_loc\n        <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">self.lemmatize = lemmatize</div>\n        self.metadata = metadata\n        <span class=\"hljs-keyword\">if</span> dictionary <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n            self.dictionary = Dictionary(self.get_texts())\n        <span class=\"hljs-keyword\">else</span>:\n            self.dictionary = dictionary\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_texts</span>(<span class=\"hljs-params\">self</span>):</span>\n        pool = multiprocessing.Pool(<span class=\"hljs-built_in\">max</span>(<span class=\"hljs-number\">1</span>, multiprocessing.cpu_count() - <span class=\"hljs-number\">1</span>))\n        func = partial(preprocess_text, self.lemmatize)\n        <span class=\"hljs-keyword\">for</span> tokens <span class=\"hljs-keyword\">in</span> pool.<span class=\"hljs-built_in\">map</span>(func, filenames_to_generator(self.docs_loc)):\n            <span class=\"hljs-keyword\">yield</span> tokens\n        pool.terminate()\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">build_LDA_model</span>(<span class=\"hljs-params\">corp_loc, dict_loc, num_topics, num_pass, lda_loc</span>):</span>\n    corpus = MmCorpus(corp_loc) \n    dictionary = Dictionary.load(dict_loc)\n\n    lda = gensim.models.LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=<span class=\"hljs-built_in\">int</span>(num_topics), alpha=<span class=\"hljs-string\">'asymmetric'</span>, passes=<span class=\"hljs-built_in\">int</span>(num_pass))\n    lda.save(lda_loc + <span class=\"hljs-string\">'.model'</span>)\n\n    build_pyLDAvis_output(corp_loc, dict_loc, lda_loc)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">build_pyLDAvis_output</span>(<span class=\"hljs-params\">corp_loc, dict_loc, lda_loc</span>):</span>\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-string\">'.model'</span> <span class=\"hljs-keyword\">in</span> lda_loc:\n        lda_loc += <span class=\"hljs-string\">'.model'</span>\n    \n    corpus = MmCorpus(corp_loc)\n    dictionary = Dictionary.load(dict_loc)\n    lda = models.LdaModel.load(lda_loc)\n\n    vis_data = gensim_vis.prepare(lda, corpus, dictionary, sort_topics=<span class=\"hljs-literal\">False</span>) \n    pyLDAvis.save_html(vis_data, lda_loc.split(<span class=\"hljs-string\">'.model'</span>)[<span class=\"hljs-number\">0</span>] + <span class=\"hljs-string\">'.html'</span>)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">main</span>():</span>\n    <span class=\"hljs-comment\"># a command line interface for running Gensim operations</span>\n    <span class=\"hljs-comment\"># can create a corpus from a directory of texts or from a wikipedia dump</span>\n    <span class=\"hljs-comment\"># options for lemmatize words, build model and/or pyLDAvis graph output</span>\n    parser = argparse.ArgumentParser(description=<span class=\"hljs-string\">'Create a corpus from a collection of tweets and/or build an LDA model'</span>)\n    subparsers = parser.add_subparsers(dest=<span class=\"hljs-string\">'mode'</span>)\n    \n    text_corpus_parser = subparsers.add_parser(<span class=\"hljs-string\">'text'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Build corpus from directory of text files'</span>)\n    text_corpus_parser.add_argument(<span class=\"hljs-string\">'-d'</span>, <span class=\"hljs-string\">'--docs_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'docs_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Directory where tweet documents stored'</span>)\n    text_corpus_parser.add_argument(<span class=\"hljs-string\">'-c'</span>, <span class=\"hljs-string\">'--corp_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'corp_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location and name to save corpus'</span>)\n    text_corpus_parser.add_argument(<span class=\"hljs-string\">'-m'</span>, <span class=\"hljs-string\">'--lemma'</span>, action=<span class=\"hljs-string\">'store_true'</span>, dest=<span class=\"hljs-string\">'lemma'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Use this option to lemmatize words'</span>)\n\n    wiki_corpus_parser = subparsers.add_parser(<span class=\"hljs-string\">'wiki'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Build corpus from compressed Wikipedia articles'</span>)\n    wiki_corpus_parser.add_argument(<span class=\"hljs-string\">'-w'</span>, <span class=\"hljs-string\">'--wiki_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'wiki_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location of compressed Wikipedia dump'</span>)\n    wiki_corpus_parser.add_argument(<span class=\"hljs-string\">'-c'</span>, <span class=\"hljs-string\">'--corp_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'corp_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location and name to save corpus'</span>)\n    wiki_corpus_parser.add_argument(<span class=\"hljs-string\">'-m'</span>, <span class=\"hljs-string\">'--lemma'</span>, action=<span class=\"hljs-string\">'store_true'</span>, dest=<span class=\"hljs-string\">'lemma'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Use this option to lemmatize words'</span>)\n\n    lda_model_parser = subparsers.add_parser(<span class=\"hljs-string\">'lda'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Create LDA model from saved corpus'</span>)\n    lda_model_parser.add_argument(<span class=\"hljs-string\">'-c'</span>, <span class=\"hljs-string\">'--corp_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'corp_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location of corpus'</span>)\n    lda_model_parser.add_argument(<span class=\"hljs-string\">'-d'</span>, <span class=\"hljs-string\">'--dict_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'dict_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location of dictionary'</span>)\n    lda_model_parser.add_argument(<span class=\"hljs-string\">'-n'</span>, <span class=\"hljs-string\">'--num_topics'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'num_topics'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Number of topics to assign to LDA model'</span>)\n    lda_model_parser.add_argument(<span class=\"hljs-string\">'-p'</span>, <span class=\"hljs-string\">'--num_pass'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'num_pass'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Number of passes through corpus when training the LDA model'</span>)\n    lda_model_parser.add_argument(<span class=\"hljs-string\">'-l'</span>, <span class=\"hljs-string\">'--lda_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'lda_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location and name to save LDA model'</span>)\n\n    lda_vis_parser = subparsers.add_parser(<span class=\"hljs-string\">'ldavis'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Create visualization of LDA model'</span>)\n    lda_vis_parser.add_argument(<span class=\"hljs-string\">'-c'</span>, <span class=\"hljs-string\">'--corp_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'corp_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location of corpus'</span>)\n    lda_vis_parser.add_argument(<span class=\"hljs-string\">'-d'</span>, <span class=\"hljs-string\">'--dict_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'dict_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location of dictionary'</span>)\n    lda_vis_parser.add_argument(<span class=\"hljs-string\">'-l'</span>, <span class=\"hljs-string\">'--lda_loc'</span>, required=<span class=\"hljs-literal\">True</span>, action=<span class=\"hljs-string\">'store'</span>, dest=<span class=\"hljs-string\">'lda_loc'</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Location of LDA model'</span>)\n\n    argcomplete.autocomplete(parser)\n    args = parser.parse_args()\n\n    <span class=\"hljs-keyword\">if</span> args.mode == <span class=\"hljs-string\">'text'</span>:\n        doc_corpus = DocCorpus(args.docs_loc, args.lemma)\n\n        doc_corpus.dictionary.filter_extremes(no_below=<span class=\"hljs-number\">1</span>, no_above=<span class=\"hljs-number\">0.5</span>, keep_n=DEFAULT_DICT_SIZE)\n\n        MmCorpus.serialize(args.corp_loc + <span class=\"hljs-string\">'.mm'</span>, doc_corpus)\n        doc_corpus.dictionary.save(args.corp_loc + <span class=\"hljs-string\">'.dict'</span>)\n\n    <span class=\"hljs-keyword\">if</span> args.mode == <span class=\"hljs-string\">'wiki'</span>:\n        wiki_corpus = WikiCorpus(args.wiki_loc, lemmatize=args.lemma, tokenizer_func=wiki_tokenizer, article_min_tokens=<span class=\"hljs-number\">100</span>, token_min_len=<span class=\"hljs-number\">3</span>, token_max_len=<span class=\"hljs-number\">15</span>)\n\n        wiki_corpus.dictionary.filter_extremes(no_below=<span class=\"hljs-number\">5</span>, no_above=<span class=\"hljs-number\">0.5</span>, keep_n=DEFAULT_DICT_SIZE)\n\n        MmCorpus.serialize(args.corp_loc + <span class=\"hljs-string\">'.mm'</span>, wiki_corpus)\n        wiki_corpus.dictionary.save(args.corp_loc + <span class=\"hljs-string\">'.dict'</span>)\n\n    <span class=\"hljs-keyword\">if</span> args.mode == <span class=\"hljs-string\">'lda'</span>:\n        build_LDA_model(args.corp_loc, args.dict_loc, args.num_topics, args.num_pass, args.lda_loc)\n\n    <span class=\"hljs-keyword\">if</span> args.mode == <span class=\"hljs-string\">'ldavis'</span>:\n        build_pyLDAvis_output(args.corp_loc, args.dict_loc, args.lda_loc)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    sys.exit(main())\n    <span class=\"hljs-comment\">#https://github.com/kethort/TwitterLDATopicModeling/blob/master/src/create_LDA_model.py</span></code></pre></div>",
    "fir_18.py": "<div class=\"codeBlock hljs python\" id=\"fir_18\"><pre id=\"fir_18_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> math\n<span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> pickle\n<span class=\"hljs-keyword\">import</span> string\n\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize\n<span class=\"hljs-keyword\">from</span> nltk.tokenize.treebank <span class=\"hljs-keyword\">import</span> TreebankWordDetokenizer\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">TrueCaser</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, dist_file_path=<span class=\"hljs-literal\">None</span></span>):</span>\n        <span class=\"hljs-string\">\"\"\" Initialize module with default data/english.dist file \"\"\"</span>\n        <span class=\"hljs-keyword\">if</span> dist_file_path <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n            dist_file_path = os.path.join(\n                os.path.dirname(os.path.abspath(__file__)),\n                <span class=\"hljs-string\">\"data/english.dist\"</span>)\n\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(dist_file_path, <span class=\"hljs-string\">\"rb\"</span>) <span class=\"hljs-keyword\">as</span> distributions_file:\n            pickle_dict = pickle.load(distributions_file)\n            self.uni_dist = pickle_dict[<span class=\"hljs-string\">\"uni_dist\"</span>]\n            self.backward_bi_dist = pickle_dict[<span class=\"hljs-string\">\"backward_bi_dist\"</span>]\n            self.forward_bi_dist = pickle_dict[<span class=\"hljs-string\">\"forward_bi_dist\"</span>]\n            self.trigram_dist = pickle_dict[<span class=\"hljs-string\">\"trigram_dist\"</span>]\n            self.word_casing_lookup = pickle_dict[<span class=\"hljs-string\">\"word_casing_lookup\"</span>]\n        <div style=\"display: inline;\" id=\"tokenization_1\" class=\"highlights fea_tokenization\">self.detknzr = TreebankWordDetokenizer()</div>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_score</span>(<span class=\"hljs-params\">self, prev_token, possible_token, next_token</span>):</span>\n        pseudo_count = <span class=\"hljs-number\">5.0</span>\n\n        <span class=\"hljs-comment\"># Get Unigram Score</span>\n        numerator = self.uni_dist[possible_token] + pseudo_count\n        denominator = <span class=\"hljs-number\">0</span>\n        <span class=\"hljs-keyword\">for</span> alternativeToken <span class=\"hljs-keyword\">in</span> self.word_casing_lookup[\n                possible_token.lower()]:\n            denominator += self.uni_dist[alternativeToken] + pseudo_count\n\n        unigram_score = numerator / denominator\n\n        <span class=\"hljs-comment\"># Get Backward Score</span>\n        bigram_backward_score = <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">if</span> prev_token <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>:\n            numerator = (\n                self.backward_bi_dist[prev_token + <span class=\"hljs-string\">\"_\"</span> + possible_token] +\n                pseudo_count)\n            denominator = <span class=\"hljs-number\">0</span>\n            <span class=\"hljs-keyword\">for</span> alternativeToken <span class=\"hljs-keyword\">in</span> self.word_casing_lookup[\n                    possible_token.lower()]:\n                denominator += (self.backward_bi_dist[prev_token + <span class=\"hljs-string\">\"_\"</span> +\n                                                      alternativeToken] +\n                                pseudo_count)\n\n            bigram_backward_score = numerator / denominator\n\n        <span class=\"hljs-comment\"># Get Forward Score</span>\n        bigram_forward_score = <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">if</span> next_token <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>:\n            next_token = next_token.lower()  <span class=\"hljs-comment\"># Ensure it is lower case</span>\n            numerator = (\n                self.forward_bi_dist[possible_token + <span class=\"hljs-string\">\"_\"</span> + next_token] +\n                pseudo_count)\n            denominator = <span class=\"hljs-number\">0</span>\n            <span class=\"hljs-keyword\">for</span> alternativeToken <span class=\"hljs-keyword\">in</span> self.word_casing_lookup[\n                    possible_token.lower()]:\n                denominator += (\n                    self.forward_bi_dist[alternativeToken + <span class=\"hljs-string\">\"_\"</span> + next_token] +\n                    pseudo_count)\n\n            bigram_forward_score = numerator / denominator\n\n        <span class=\"hljs-comment\"># Get Trigram Score</span>\n        trigram_score = <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">if</span> prev_token <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span> <span class=\"hljs-keyword\">and</span> next_token <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>:\n            next_token = next_token.lower()  <span class=\"hljs-comment\"># Ensure it is lower case</span>\n            numerator = (self.trigram_dist[prev_token + <span class=\"hljs-string\">\"_\"</span> + possible_token +\n                                           <span class=\"hljs-string\">\"_\"</span> + next_token] + pseudo_count)\n            denominator = <span class=\"hljs-number\">0</span>\n            <span class=\"hljs-keyword\">for</span> alternativeToken <span class=\"hljs-keyword\">in</span> self.word_casing_lookup[\n                    possible_token.lower()]:\n                denominator += (\n                    self.trigram_dist[prev_token + <span class=\"hljs-string\">\"_\"</span> + alternativeToken +\n                                      <span class=\"hljs-string\">\"_\"</span> + next_token] + pseudo_count)\n\n            trigram_score = numerator / denominator\n\n        result = (math.log(unigram_score) + math.log(bigram_backward_score) +\n                  math.log(bigram_forward_score) + math.log(trigram_score))\n\n        <span class=\"hljs-keyword\">return</span> result\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">first_token_case</span>(<span class=\"hljs-params\">self, raw</span>):</span>\n        <span class=\"hljs-keyword\">return</span> raw.capitalize()\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_true_case</span>(<span class=\"hljs-params\">self, sentence, out_of_vocabulary_token_option=<span class=\"hljs-string\">\"title\"</span></span>):</span>\n        <span class=\"hljs-string\">\"\"\" Wrapper function for handling untokenized input.\n        \n        @param sentence: a sentence string to be tokenized\n        @param outOfVocabularyTokenOption:\n            title: Returns out of vocabulary (OOV) tokens in 'title' format\n            lower: Returns OOV tokens in lower case\n            as-is: Returns OOV tokens as is\n    \n        Returns (str): detokenized, truecased version of input sentence \n        \"\"\"</span>\n        <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">tokens = word_tokenize(sentence)</div>\n        tokens_true_case = self.get_true_case_from_tokens(tokens, out_of_vocabulary_token_option)\n        <span class=\"hljs-keyword\">return</span> self.detknzr.detokenize(tokens_true_case)\n        \n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_true_case_from_tokens</span>(<span class=\"hljs-params\">self, tokens, out_of_vocabulary_token_option=<span class=\"hljs-string\">\"title\"</span></span>):</span>\n        <span class=\"hljs-string\">\"\"\" Returns the true case for the passed tokens.\n    \n        @param tokens: List of tokens in a single sentence\n        @param pretokenised: set to true if input is alreay tokenised (e.g. string with whitespace between tokens)\n        @param outOfVocabularyTokenOption:\n            title: Returns out of vocabulary (OOV) tokens in 'title' format\n            lower: Returns OOV tokens in lower case\n            as-is: Returns OOV tokens as is\n        \n        Returns (list[str]): truecased version of input list\n        of tokens \n        \"\"\"</span>\n        tokens_true_case = []\n        <span class=\"hljs-keyword\">for</span> token_idx, token <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(tokens):\n\n            <span class=\"hljs-keyword\">if</span> token <span class=\"hljs-keyword\">in</span> string.punctuation <span class=\"hljs-keyword\">or</span> token.isdigit():\n                tokens_true_case.append(token)\n            <span class=\"hljs-keyword\">else</span>:\n                token = token.lower()\n                <span class=\"hljs-keyword\">if</span> token <span class=\"hljs-keyword\">in</span> self.word_casing_lookup:\n                    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(self.word_casing_lookup[token]) == <span class=\"hljs-number\">1</span>:\n                        tokens_true_case.append(\n                            <span class=\"hljs-built_in\">list</span>(self.word_casing_lookup[token])[<span class=\"hljs-number\">0</span>])\n                    <span class=\"hljs-keyword\">else</span>:\n                        prev_token = (tokens_true_case[token_idx - <span class=\"hljs-number\">1</span>]\n                                      <span class=\"hljs-keyword\">if</span> token_idx &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>)\n                        next_token = (tokens[token_idx + <span class=\"hljs-number\">1</span>]\n                                      <span class=\"hljs-keyword\">if</span> token_idx &lt; <span class=\"hljs-built_in\">len</span>(tokens) - <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>)\n\n                        best_token = <span class=\"hljs-literal\">None</span>\n                        highest_score = <span class=\"hljs-built_in\">float</span>(<span class=\"hljs-string\">\"-inf\"</span>)\n\n                        <span class=\"hljs-keyword\">for</span> possible_token <span class=\"hljs-keyword\">in</span> self.word_casing_lookup[token]:\n                            score = self.get_score(prev_token, possible_token,\n                                                   next_token)\n\n                            <span class=\"hljs-keyword\">if</span> score &gt; highest_score:\n                                best_token = possible_token\n                                highest_score = score\n\n                        tokens_true_case.append(best_token)\n\n                    <span class=\"hljs-keyword\">if</span> token_idx == <span class=\"hljs-number\">0</span>:\n                        tokens_true_case[<span class=\"hljs-number\">0</span>] = self.first_token_case(\n                            tokens_true_case[<span class=\"hljs-number\">0</span>])\n\n                <span class=\"hljs-keyword\">else</span>:  <span class=\"hljs-comment\"># Token out of vocabulary</span>\n                    <span class=\"hljs-keyword\">if</span> out_of_vocabulary_token_option == <span class=\"hljs-string\">\"title\"</span>:\n                        tokens_true_case.append(token.title())\n                    <span class=\"hljs-keyword\">elif</span> out_of_vocabulary_token_option == <span class=\"hljs-string\">\"capitalize\"</span>:\n                        tokens_true_case.append(token.capitalize())\n                    <span class=\"hljs-keyword\">elif</span> out_of_vocabulary_token_option == <span class=\"hljs-string\">\"lower\"</span>:\n                        tokens_true_case.append(token.lower())\n                    <span class=\"hljs-keyword\">else</span>:\n                        tokens_true_case.append(token)\n\n        <span class=\"hljs-keyword\">return</span> tokens_true_case\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    dist_file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),\n                                  <span class=\"hljs-string\">\"data/english.dist\"</span>)\n\n    caser = TrueCaser(dist_file_path)\n\n    <span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n        ip = <span class=\"hljs-built_in\">input</span>(<span class=\"hljs-string\">\"Enter a sentence: \"</span>)\n        print(caser.get_true_case(ip, <span class=\"hljs-string\">\"lower\"</span>))\n        <span class=\"hljs-comment\">#https://github.com/daltonfury42/truecase/blob/master/truecase/TrueCaser.py</span></code></pre></div>",
    "fir_19.py": "<div class=\"codeBlock hljs python\" id=\"fir_19\"><pre id=\"fir_19_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">from</span> pprint <span class=\"hljs-keyword\">import</span> pprint\n\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> sent_tokenize, word_tokenize\n\n<span class=\"hljs-keyword\">from</span> nltk.cluster.util <span class=\"hljs-keyword\">import</span> cosine_distance\n\nMULTIPLE_WHITESPACE_PATTERN = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r\"\\s+\"</span>, re.UNICODE)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">normalize_whitespace</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Translates multiple whitespace into single space character.\n    If there is at least one new line character chunk is replaced\n    by single LF (Unix new line) character.\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">return</span> MULTIPLE_WHITESPACE_PATTERN.sub(_replace_whitespace, text)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_replace_whitespace</span>(<span class=\"hljs-params\">match</span>):</span>\n    text = match.group()\n\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">\"\\n\"</span> <span class=\"hljs-keyword\">in</span> text <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">\"\\r\"</span> <span class=\"hljs-keyword\">in</span> text:\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\"\\n\"</span>\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\" \"</span>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">is_blank</span>(<span class=\"hljs-params\">string</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Returns `True` if string contains only white-space characters\n    or is empty. Otherwise `False` is returned.\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">not</span> string <span class=\"hljs-keyword\">or</span> string.isspace()\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_symmetric_matrix</span>(<span class=\"hljs-params\">matrix</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Get Symmetric matrix\n    :param matrix:\n    :return: matrix\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">return</span> matrix + matrix.T - np.diag(matrix.diagonal())\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">core_cosine_similarity</span>(<span class=\"hljs-params\">vector1, vector2</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    measure cosine similarity between two vectors\n    :param vector1:\n    :param vector2:\n    :return: 0 &lt; cosine similarity value &lt; 1\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span> - <div style=\"display: inline;\" id=\"text_similarity_0\" class=\"highlights fea_text_similarity\">cosine_distance(vector1, vector2)</div>\n\n\n<span class=\"hljs-string\">'''\nNote: This is not a summarization algorithm. This Algorithm pics top sentences irrespective of the order they appeared.\n'''</span>\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">TextRank4Sentences</span>():</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span>\n        self.damping = <span class=\"hljs-number\">0.85</span>  <span class=\"hljs-comment\"># damping coefficient, usually is .85</span>\n        self.min_diff = <span class=\"hljs-number\">1e-5</span>  <span class=\"hljs-comment\"># convergence threshold</span>\n        self.steps = <span class=\"hljs-number\">100</span>  <span class=\"hljs-comment\"># iteration steps</span>\n        self.text_str = <span class=\"hljs-literal\">None</span>\n        self.sentences = <span class=\"hljs-literal\">None</span>\n        self.pr_vector = <span class=\"hljs-literal\">None</span>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_sentence_similarity</span>(<span class=\"hljs-params\">self, sent1, sent2, stopwords=<span class=\"hljs-literal\">None</span></span>):</span>\n        <span class=\"hljs-keyword\">if</span> stopwords <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n            stopwords = []\n\n        sent1 = [w.lower() <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> sent1]\n        sent2 = [w.lower() <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> sent2]\n\n        all_words = <span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">set</span>(sent1 + sent2))\n\n        vector1 = [<span class=\"hljs-number\">0</span>] * <span class=\"hljs-built_in\">len</span>(all_words)\n        vector2 = [<span class=\"hljs-number\">0</span>] * <span class=\"hljs-built_in\">len</span>(all_words)\n\n        <span class=\"hljs-comment\"># build the vector for the first sentence</span>\n        <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> sent1:\n            <span class=\"hljs-keyword\">if</span> w <span class=\"hljs-keyword\">in</span> stopwords:\n                <span class=\"hljs-keyword\">continue</span>\n            vector1[all_words.index(w)] += <span class=\"hljs-number\">1</span>\n\n        <span class=\"hljs-comment\"># build the vector for the second sentence</span>\n        <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> sent2:\n            <span class=\"hljs-keyword\">if</span> w <span class=\"hljs-keyword\">in</span> stopwords:\n                <span class=\"hljs-keyword\">continue</span>\n            vector2[all_words.index(w)] += <span class=\"hljs-number\">1</span>\n\n        <span class=\"hljs-keyword\">return</span> core_cosine_similarity(vector1, vector2)\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_build_similarity_matrix</span>(<span class=\"hljs-params\">self, sentences, stopwords=<span class=\"hljs-literal\">None</span></span>):</span>\n        <span class=\"hljs-comment\"># create an empty similarity matrix</span>\n        sm = np.zeros([<span class=\"hljs-built_in\">len</span>(sentences), <span class=\"hljs-built_in\">len</span>(sentences)])\n\n        <span class=\"hljs-keyword\">for</span> idx1 <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(sentences)):\n            <span class=\"hljs-keyword\">for</span> idx2 <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(sentences)):\n                <span class=\"hljs-keyword\">if</span> idx1 == idx2:\n                    <span class=\"hljs-keyword\">continue</span>\n\n                sm[idx1][idx2] = self._sentence_similarity(sentences[idx1], sentences[idx2], stopwords=stopwords)\n\n        <span class=\"hljs-comment\"># Get Symmeric matrix</span>\n        sm = get_symmetric_matrix(sm)\n\n        <span class=\"hljs-comment\"># Normalize matrix by column</span>\n        norm = np.<span class=\"hljs-built_in\">sum</span>(sm, axis=<span class=\"hljs-number\">0</span>)\n        sm_norm = np.divide(sm, norm, where=norm != <span class=\"hljs-number\">0</span>)  <span class=\"hljs-comment\"># this is to ignore the 0 element in norm</span>\n\n        <span class=\"hljs-keyword\">return</span> sm_norm\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_run_page_rank</span>(<span class=\"hljs-params\">self, similarity_matrix</span>):</span>\n\n        pr_vector = np.array([<span class=\"hljs-number\">1</span>] * <span class=\"hljs-built_in\">len</span>(similarity_matrix))\n\n        <span class=\"hljs-comment\"># Iteration</span>\n        previous_pr = <span class=\"hljs-number\">0</span>\n        <span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(self.steps):\n            pr_vector = (<span class=\"hljs-number\">1</span> - self.damping) + self.damping * np.matmul(similarity_matrix, pr_vector)\n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">abs</span>(previous_pr - <span class=\"hljs-built_in\">sum</span>(pr_vector)) &lt; self.min_diff:\n                <span class=\"hljs-keyword\">break</span>\n            <span class=\"hljs-keyword\">else</span>:\n                previous_pr = <span class=\"hljs-built_in\">sum</span>(pr_vector)\n\n        <span class=\"hljs-keyword\">return</span> pr_vector\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_get_sentence</span>(<span class=\"hljs-params\">self, index</span>):</span>\n\n        <span class=\"hljs-keyword\">try</span>:\n            <span class=\"hljs-keyword\">return</span> self.sentences[index]\n        <span class=\"hljs-keyword\">except</span> IndexError:\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\"\"</span>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_top_sentences</span>(<span class=\"hljs-params\">self, number=<span class=\"hljs-number\">5</span></span>):</span>\n\n        top_sentences = {}\n\n        <span class=\"hljs-keyword\">if</span> self.pr_vector <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span>:\n\n            sorted_pr = np.argsort(self.pr_vector)\n            sorted_pr = <span class=\"hljs-built_in\">list</span>(sorted_pr)\n            sorted_pr.reverse()\n\n            index = <span class=\"hljs-number\">0</span>\n            <span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(number):\n                <span class=\"hljs-built_in\">print</span> (<span class=\"hljs-built_in\">str</span>(sorted_pr[index]) + <span class=\"hljs-string\">\" : \"</span> + <span class=\"hljs-built_in\">str</span>(self.pr_vector[sorted_pr[index]]))\n                sent = self.sentences[sorted_pr[index]]\n                sent = normalize_whitespace(sent)\n                top_sentences[sent] = self.pr_vector[sorted_pr[index]]\n                index += <span class=\"hljs-number\">1</span>\n\n        <span class=\"hljs-keyword\">return</span> top_sentences\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">analyze</span>(<span class=\"hljs-params\">self, text, stop_words=<span class=\"hljs-literal\">None</span></span>):</span>\n        self.text_str = text\n        <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">self.sentences = sent_tokenize(self.text_str)</div>\n\n        tokenized_sentences = [word_tokenize(sent) <span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> self.sentences]\n\n        similarity_matrix = self._build_similarity_matrix(tokenized_sentences, stop_words)\n\n        self.pr_vector = self._run_page_rank(similarity_matrix)\n        print(self.pr_vector)\n\n\ntext_str = <span class=\"hljs-string\">'''\n    Those Who Are Resilient Stay In The Game Longer\n    On the mountains of truth you can never climb in vain: either you will reach a point higher up today, or you will be training your powers so that you will be able to climb higher tomorrow.Friedrich Nietzsche\n    Challenges and setbacks are not meant to defeat you, but promote you. However, I realise after many years of defeats, it can crush your spirit and it is easier to give up than risk further setbacks and disappointments. Have you experienced this before? To be honest, I dont have the answers. I cant tell you what the right course of action is; only you will know. However, its important not to be discouraged by failure when pursuing a goal or a dream, since failure itself means different things to different people. To a person with a Fixed Mindset failure is a blow to their self-esteem, yet to a person with a Growth Mindset, its an opportunity to improve and find new ways to overcome their obstacles. Same failure, yet different responses. Who is right and who is wrong? Neither. Each person has a different mindset that decides their outcome. Those who are resilient stay in the game longer and draw on their inner means to succeed.\n    '''</span>\n\ntr4sh = TextRank4Sentences()\ntr4sh.analyze(text_str)\npprint(tr4sh.get_top_sentences(<span class=\"hljs-number\">5</span>), width=<span class=\"hljs-number\">1</span>, depth=<span class=\"hljs-number\">2</span>)\n<span class=\"hljs-comment\">#https://github.com/akashp1712/nlp-akash/blob/master/text-summarization/text_rank_sentences.py</span></code></pre></div>",
    "fir_20.py": "<div class=\"codeBlock hljs python\" id=\"fir_20\"><pre id=\"fir_20_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> math\n\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> sent_tokenize, word_tokenize, PorterStemmer\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n\ntext_str = <span class=\"hljs-string\">'''\nThose Who Are Resilient Stay In The Game Longer\nOn the mountains of truth you can never climb in vain: either you will reach a point higher up today, or you will be training your powers so that you will be able to climb higher tomorrow.Friedrich Nietzsche\nChallenges and setbacks are not meant to defeat you, but promote you. However, I realise after many years of defeats, it can crush your spirit and it is easier to give up than risk further setbacks and disappointments. Have you experienced this before? To be honest, I dont have the answers. I cant tell you what the right course of action is; only you will know. However, its important not to be discouraged by failure when pursuing a goal or a dream, since failure itself means different things to different people. To a person with a Fixed Mindset failure is a blow to their self-esteem, yet to a person with a Growth Mindset, its an opportunity to improve and find new ways to overcome their obstacles. Same failure, yet different responses. Who is right and who is wrong? Neither. Each person has a different mindset that decides their outcome. Those who are resilient stay in the game longer and draw on their inner means to succeed.\n\nIve coached mummy and mom clients who gave up after many years toiling away at their respective goal or dream. It was at that point their biggest breakthrough came. Perhaps all those years of perseverance finally paid off. It was the 19th Centurys minister Henry Ward Beecher who once said: Ones best success comes after their greatest disappointments. No one knows what the future holds, so your only guide is whether you can endure repeated defeats and disappointments and still pursue your dream. Consider the advice from the American academic and psychologist Angela Duckworth who writes in Grit: The Power of Passion and Perseverance: Many of us, it seems, quit what we start far too early and far too often. Even more than the effort a gritty person puts in on a single day, what matters is that they wake up the next day, and the next, ready to get on that treadmill and keep going.\n\nI know one thing for certain: dont settle for less than what youre capable of, but strive for something bigger. Some of you reading this might identify with this message because it resonates with you on a deeper level. For others, at the end of their tether the message might be nothing more than a trivial pep talk. What I wish to convey irrespective of where you are in your journey is: NEVER settle for less. If you settle for less, you will receive less than you deserve and convince yourself you are justified to receive it.\n\n\nTwo people on a precipice over Yosemite Valley by Nathan Shipps on Unsplash\nDevelop A Powerful Vision Of What You Want\nYour problem is to bridge the gap which exists between where you are now and the goal you intend to reach.Earl Nightingale\nI recall a passage my father often used growing up in 1990s: Dont tell me your problems unless youve spent weeks trying to solve them yourself. That advice has echoed in my mind for decades and became my motivator. Dont leave it to other people or outside circumstances to motivate you because you will be let down every time. It must come from within you. Gnaw away at your problems until you solve them or find a solution. Problems are not stop signs, they are advising you that more work is required to overcome them. Most times, problems help you gain a skill or develop the resources to succeed later. So embrace your challenges and develop the grit to push past them instead of retreat in resignation. Where are you settling in your life right now? Could you be you playing for bigger stakes than you are? Are you willing to play bigger even if it means repeated failures and setbacks? You should ask yourself these questions to decide whether youre willing to put yourself on the line or settle for less. And thats fine if youre content to receive less, as long as youre not regretful later.\n\nIf you have not achieved the success you deserve and are considering giving up, will you regret it in a few years or decades from now? Only you can answer that, but you should carve out time to discover your motivation for pursuing your goals. Its a fact, if you dont know what you want youll get what life hands you and it may not be in your best interest, affirms author Larry Weidel: Winners know that if you dont figure out what you want, youll get whatever life hands you. The key is to develop a powerful vision of what you want and hold that image in your mind. Nurture it daily and give it life by taking purposeful action towards it.\n\nVision + desire + dedication + patience + daily action leads to astonishing success. Are you willing to commit to this way of life or jump ship at the first sign of failure? Im amused when I read questions written by millennials on Quora who ask how they can become rich and famous or the next Elon Musk. Success is a fickle and long game with highs and lows. Similarly, there are no assurances even if youre an overnight sensation, to sustain it for long, particularly if you dont have the mental and emotional means to endure it. This means you must rely on the one true constant in your favour: your personal development. The more you grow, the more you gain in terms of financial resources, status, successsimple. If you leave it to outside conditions to dictate your circumstances, you are rolling the dice on your future.\n\nSo become intentional on what you want out of life. Commit to it. Nurture your dreams. Focus on your development and if you want to give up, know whats involved before you take the plunge. Because I assure you, someone out there right now is working harder than you, reading more books, sleeping less and sacrificing all they have to realise their dreams and it may contest with yours. Dont leave your dreams to chance.\n'''</span>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_create_frequency_table</span>(<span class=\"hljs-params\">text_string</span>) -&gt; dict:</span>\n    <span class=\"hljs-string\">\"\"\"\n    we create a dictionary for the word frequency table.\n    For this, we should only use the words that are not part of the stopWords array.\n\n    Removing stop words and making frequency table\n    Stemmer - an algorithm to bring words to its root word.\n    :rtype: dict\n    \"\"\"</span>\n    <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stopWords = <span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">\"english\"</span>))</div>\n    <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">words = word_tokenize(text_string)</div>\n    <div style=\"display: inline;\" id=\"stemming_0\" class=\"highlights fea_stemming\">ps = PorterStemmer()</div>\n\n    freqTable = <span class=\"hljs-built_in\">dict</span>()\n    <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> words:\n        word = ps.stem(word)\n        <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> stopWords:\n            <span class=\"hljs-keyword\">continue</span>\n        <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> freqTable:\n            freqTable[word] += <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">else</span>:\n            freqTable[word] = <span class=\"hljs-number\">1</span>\n\n    <span class=\"hljs-keyword\">return</span> freqTable\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_create_frequency_matrix</span>(<span class=\"hljs-params\">sentences</span>):</span>\n    frequency_matrix = {}\n    <div style=\"display: inline;\" id=\"nlp_datasets_1\" class=\"highlights fea_nlp_datasets\">stopWords = <span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">\"english\"</span>))</div>\n    <div style=\"display: inline;\" id=\"stemming_1\" class=\"highlights fea_stemming\">ps = PorterStemmer()</div>\n\n    <span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> sentences:\n        freq_table = {}\n        <div style=\"display: inline;\" id=\"tokenization_1\" class=\"highlights fea_tokenization\">words = word_tokenize(sent)</div>\n        <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> words:\n            word = word.lower()\n            word = ps.stem(word)\n            <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> stopWords:\n                <span class=\"hljs-keyword\">continue</span>\n\n            <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> freq_table:\n                freq_table[word] += <span class=\"hljs-number\">1</span>\n            <span class=\"hljs-keyword\">else</span>:\n                freq_table[word] = <span class=\"hljs-number\">1</span>\n\n        frequency_matrix[sent[:<span class=\"hljs-number\">15</span>]] = freq_table\n\n    <span class=\"hljs-keyword\">return</span> frequency_matrix\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_create_tf_matrix</span>(<span class=\"hljs-params\">freq_matrix</span>):</span>\n    tf_matrix = {}\n\n    <span class=\"hljs-keyword\">for</span> sent, f_table <span class=\"hljs-keyword\">in</span> freq_matrix.items():\n        tf_table = {}\n\n        count_words_in_sentence = <span class=\"hljs-built_in\">len</span>(f_table)\n        <span class=\"hljs-keyword\">for</span> word, count <span class=\"hljs-keyword\">in</span> f_table.items():\n            tf_table[word] = count / count_words_in_sentence\n\n        tf_matrix[sent] = tf_table\n\n    <span class=\"hljs-keyword\">return</span> tf_matrix\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_create_documents_per_words</span>(<span class=\"hljs-params\">freq_matrix</span>):</span>\n    word_per_doc_table = {}\n\n    <span class=\"hljs-keyword\">for</span> sent, f_table <span class=\"hljs-keyword\">in</span> freq_matrix.items():\n        <span class=\"hljs-keyword\">for</span> word, count <span class=\"hljs-keyword\">in</span> f_table.items():\n            <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> word_per_doc_table:\n                word_per_doc_table[word] += <span class=\"hljs-number\">1</span>\n            <span class=\"hljs-keyword\">else</span>:\n                word_per_doc_table[word] = <span class=\"hljs-number\">1</span>\n\n    <span class=\"hljs-keyword\">return</span> word_per_doc_table\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_create_idf_matrix</span>(<span class=\"hljs-params\">freq_matrix, count_doc_per_words, total_documents</span>):</span>\n    idf_matrix = {}\n\n    <span class=\"hljs-keyword\">for</span> sent, f_table <span class=\"hljs-keyword\">in</span> freq_matrix.items():\n        idf_table = {}\n\n        <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> f_table.keys():\n            idf_table[word] = math.log10(total_documents / <span class=\"hljs-built_in\">float</span>(count_doc_per_words[word]))\n\n        idf_matrix[sent] = idf_table\n\n    <span class=\"hljs-keyword\">return</span> idf_matrix\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_create_tf_idf_matrix</span>(<span class=\"hljs-params\">tf_matrix, idf_matrix</span>):</span>\n    tf_idf_matrix = {}\n\n    <span class=\"hljs-keyword\">for</span> (sent1, f_table1), (sent2, f_table2) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(tf_matrix.items(), idf_matrix.items()):\n\n        tf_idf_table = {}\n\n        <span class=\"hljs-keyword\">for</span> (word1, value1), (word2, value2) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(f_table1.items(),\n                                                    f_table2.items()):  <span class=\"hljs-comment\"># here, keys are the same in both the table</span>\n            tf_idf_table[word1] = <span class=\"hljs-built_in\">float</span>(value1 * value2)\n\n        tf_idf_matrix[sent1] = tf_idf_table\n\n    <span class=\"hljs-keyword\">return</span> tf_idf_matrix\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\"></span><div style=\"display: inline;\" id=\"text_scoring_0\" class=\"highlights fea_text_scoring\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_score_sentences</span>(<span class=\"hljs-params\">tf_idf_matrix</span>) -&gt; dict:</div></span>\n    <span class=\"hljs-string\">\"\"\"\n    score a sentence by its word's TF\n    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n    :rtype: dict\n    \"\"\"</span>\n\n    sentenceValue = {}\n\n    <span class=\"hljs-keyword\">for</span> sent, f_table <span class=\"hljs-keyword\">in</span> tf_idf_matrix.items():\n        total_score_per_sentence = <span class=\"hljs-number\">0</span>\n\n        count_words_in_sentence = <span class=\"hljs-built_in\">len</span>(f_table)\n        <span class=\"hljs-keyword\">for</span> word, score <span class=\"hljs-keyword\">in</span> f_table.items():\n            total_score_per_sentence += score\n\n        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n\n    <span class=\"hljs-keyword\">return</span> sentenceValue\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_find_average_score</span>(<span class=\"hljs-params\">sentenceValue</span>) -&gt; int:</span>\n    <span class=\"hljs-string\">\"\"\"\n    Find the average score from the sentence value dictionary\n    :rtype: int\n    \"\"\"</span>\n    sumValues = <span class=\"hljs-number\">0</span>\n    <span class=\"hljs-keyword\">for</span> entry <span class=\"hljs-keyword\">in</span> sentenceValue:\n        sumValues += sentenceValue[entry]\n\n    <span class=\"hljs-comment\"># Average value of a sentence from original summary_text</span>\n    average = (sumValues / <span class=\"hljs-built_in\">len</span>(sentenceValue))\n\n    <span class=\"hljs-keyword\">return</span> average\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_generate_summary</span>(<span class=\"hljs-params\">sentences, sentenceValue, threshold</span>):</span>\n    sentence_count = <span class=\"hljs-number\">0</span>\n    summary = <span class=\"hljs-string\">''</span>\n\n    <span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sentences:\n        <span class=\"hljs-keyword\">if</span> sentence[:<span class=\"hljs-number\">15</span>] <span class=\"hljs-keyword\">in</span> sentenceValue <span class=\"hljs-keyword\">and</span> sentenceValue[sentence[:<span class=\"hljs-number\">15</span>]] &gt;= (threshold):\n            summary += <span class=\"hljs-string\">\" \"</span> + sentence\n            sentence_count += <span class=\"hljs-number\">1</span>\n\n    <span class=\"hljs-keyword\">return</span> summary\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">run_summarization</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    :param text: Plain summary_text of long article\n    :return: summarized summary_text\n    \"\"\"</span>\n\n    <span class=\"hljs-string\">'''\n    We already have a sentence tokenizer, so we just need \n    to run the sent_tokenize() method to create the array of sentences.\n    '''</span>\n    <span class=\"hljs-comment\"># 1 Sentence Tokenize</span>\n    sentences = sent_tokenize(text)\n    total_documents = <span class=\"hljs-built_in\">len</span>(sentences)\n    <span class=\"hljs-comment\">#print(sentences)</span>\n\n    <span class=\"hljs-comment\"># 2 Create the Frequency matrix of the words in each sentence.</span>\n    freq_matrix = _create_frequency_matrix(sentences)\n    <span class=\"hljs-comment\">#print(freq_matrix)</span>\n\n    <span class=\"hljs-string\">'''\n    Term frequency (TF) is how often a word appears in a document, divided by how many words are there in a document.\n    '''</span>\n    <span class=\"hljs-comment\"># 3 Calculate TermFrequency and generate a matrix</span>\n    tf_matrix = _create_tf_matrix(freq_matrix)\n    <span class=\"hljs-comment\">#print(tf_matrix)</span>\n\n    <span class=\"hljs-comment\"># 4 creating table for documents per words</span>\n    count_doc_per_words = _create_documents_per_words(freq_matrix)\n    <span class=\"hljs-comment\">#print(count_doc_per_words)</span>\n\n    <span class=\"hljs-string\">'''\n    Inverse document frequency (IDF) is how unique or rare a word is.\n    '''</span>\n    <span class=\"hljs-comment\"># 5 Calculate IDF and generate a matrix</span>\n    idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n    <span class=\"hljs-comment\">#print(idf_matrix)</span>\n\n    <span class=\"hljs-comment\"># 6 Calculate TF-IDF and generate a matrix</span>\n    tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n    <span class=\"hljs-comment\">#print(tf_idf_matrix)</span>\n\n    <span class=\"hljs-comment\"># 7 Important Algorithm: score the sentences</span>\n    sentence_scores = _score_sentences(tf_idf_matrix)\n    <span class=\"hljs-comment\">#print(sentence_scores)</span>\n\n    <span class=\"hljs-comment\"># 8 Find the threshold</span>\n    threshold = _find_average_score(sentence_scores)\n    <span class=\"hljs-comment\">#print(threshold)</span>\n\n    <span class=\"hljs-comment\"># 9 Important Algorithm: Generate the summary</span>\n    summary = _generate_summary(sentences, sentence_scores, <span class=\"hljs-number\">1.3</span> * threshold)\n    <span class=\"hljs-keyword\">return</span> summary\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    result = run_summarization(text_str)\n    print(result)\n    <span class=\"hljs-comment\">#https://github.com/akashp1712/nlp-akash/blob/master/text-summarization/TF_IDF_Summarization.py</span></code></pre></div>",
    "fir_21.py": "<div class=\"codeBlock hljs python\" id=\"fir_21\"><pre id=\"fir_21_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># Implementation from https://dev.to/davidisrawi/build-a-quick-summarizer-with-python-and-nltk</span>\n\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n<span class=\"hljs-keyword\">from</span> nltk.stem <span class=\"hljs-keyword\">import</span> PorterStemmer\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize, sent_tokenize\n\ntext_str = <span class=\"hljs-string\">'''\nThose Who Are Resilient Stay In The Game Longer\nOn the mountains of truth you can never climb in vain: either you will reach a point higher up today, or you will be training your powers so that you will be able to climb higher tomorrow.Friedrich Nietzsche\nChallenges and setbacks are not meant to defeat you, but promote you. However, I realise after many years of defeats, it can crush your spirit and it is easier to give up than risk further setbacks and disappointments. Have you experienced this before? To be honest, I dont have the answers. I cant tell you what the right course of action is; only you will know. However, its important not to be discouraged by failure when pursuing a goal or a dream, since failure itself means different things to different people. To a person with a Fixed Mindset failure is a blow to their self-esteem, yet to a person with a Growth Mindset, its an opportunity to improve and find new ways to overcome their obstacles. Same failure, yet different responses. Who is right and who is wrong? Neither. Each person has a different mindset that decides their outcome. Those who are resilient stay in the game longer and draw on their inner means to succeed.\n\nIve coached mummy and mom clients who gave up after many years toiling away at their respective goal or dream. It was at that point their biggest breakthrough came. Perhaps all those years of perseverance finally paid off. It was the 19th Centurys minister Henry Ward Beecher who once said: Ones best success comes after their greatest disappointments. No one knows what the future holds, so your only guide is whether you can endure repeated defeats and disappointments and still pursue your dream. Consider the advice from the American academic and psychologist Angela Duckworth who writes in Grit: The Power of Passion and Perseverance: Many of us, it seems, quit what we start far too early and far too often. Even more than the effort a gritty person puts in on a single day, what matters is that they wake up the next day, and the next, ready to get on that treadmill and keep going.\n\nI know one thing for certain: dont settle for less than what youre capable of, but strive for something bigger. Some of you reading this might identify with this message because it resonates with you on a deeper level. For others, at the end of their tether the message might be nothing more than a trivial pep talk. What I wish to convey irrespective of where you are in your journey is: NEVER settle for less. If you settle for less, you will receive less than you deserve and convince yourself you are justified to receive it.\n\n\nTwo people on a precipice over Yosemite Valley by Nathan Shipps on Unsplash\nDevelop A Powerful Vision Of What You Want\nYour problem is to bridge the gap which exists between where you are now and the goal you intend to reach.Earl Nightingale\nI recall a passage my father often used growing up in 1990s: Dont tell me your problems unless youve spent weeks trying to solve them yourself. That advice has echoed in my mind for decades and became my motivator. Dont leave it to other people or outside circumstances to motivate you because you will be let down every time. It must come from within you. Gnaw away at your problems until you solve them or find a solution. Problems are not stop signs, they are advising you that more work is required to overcome them. Most times, problems help you gain a skill or develop the resources to succeed later. So embrace your challenges and develop the grit to push past them instead of retreat in resignation. Where are you settling in your life right now? Could you be you playing for bigger stakes than you are? Are you willing to play bigger even if it means repeated failures and setbacks? You should ask yourself these questions to decide whether youre willing to put yourself on the line or settle for less. And thats fine if youre content to receive less, as long as youre not regretful later.\n\nIf you have not achieved the success you deserve and are considering giving up, will you regret it in a few years or decades from now? Only you can answer that, but you should carve out time to discover your motivation for pursuing your goals. Its a fact, if you dont know what you want youll get what life hands you and it may not be in your best interest, affirms author Larry Weidel: Winners know that if you dont figure out what you want, youll get whatever life hands you. The key is to develop a powerful vision of what you want and hold that image in your mind. Nurture it daily and give it life by taking purposeful action towards it.\n\nVision + desire + dedication + patience + daily action leads to astonishing success. Are you willing to commit to this way of life or jump ship at the first sign of failure? Im amused when I read questions written by millennials on Quora who ask how they can become rich and famous or the next Elon Musk. Success is a fickle and long game with highs and lows. Similarly, there are no assurances even if youre an overnight sensation, to sustain it for long, particularly if you dont have the mental and emotional means to endure it. This means you must rely on the one true constant in your favour: your personal development. The more you grow, the more you gain in terms of financial resources, status, successsimple. If you leave it to outside conditions to dictate your circumstances, you are rolling the dice on your future.\n\nSo become intentional on what you want out of life. Commit to it. Nurture your dreams. Focus on your development and if you want to give up, know whats involved before you take the plunge. Because I assure you, someone out there right now is working harder than you, reading more books, sleeping less and sacrificing all they have to realise their dreams and it may contest with yours. Dont leave your dreams to chance.\n'''</span>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_create_frequency_table</span>(<span class=\"hljs-params\">text_string</span>) -&gt; dict:</span>\n    <span class=\"hljs-string\">\"\"\"\n    we create a dictionary for the word frequency table.\n    For this, we should only use the words that are not part of the stopWords array.\n\n    Removing stop words and making frequency table\n    Stemmer - an algorithm to bring words to its root word.\n    :rtype: dict\n    \"\"\"</span>\n    <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stopWords = <span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">\"english\"</span>))</div>\n    <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">words = word_tokenize(text_string)</div>\n    <div style=\"display: inline;\" id=\"stemming_0\" class=\"highlights fea_stemming\">ps = PorterStemmer()</div>\n\n    freqTable = <span class=\"hljs-built_in\">dict</span>()\n    <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> words:\n        word = ps.stem(word)\n        <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> stopWords:\n            <span class=\"hljs-keyword\">continue</span>\n        <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> freqTable:\n            freqTable[word] += <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">else</span>:\n            freqTable[word] = <span class=\"hljs-number\">1</span>\n\n    <span class=\"hljs-keyword\">return</span> freqTable\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\"></span><div style=\"display: inline;\" id=\"text_scoring_0\" class=\"highlights fea_text_scoring\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_score_sentences</span>(<span class=\"hljs-params\">sentences, freqTable</span>) -&gt; dict:</div></span>\n    <span class=\"hljs-string\">\"\"\"\n    score a sentence by its words\n    Basic algorithm: adding the frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n    :rtype: dict\n    \"\"\"</span>\n\n    sentenceValue = <span class=\"hljs-built_in\">dict</span>()\n\n    <span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sentences:\n        word_count_in_sentence = (<span class=\"hljs-built_in\">len</span>(word_tokenize(sentence)))\n        word_count_in_sentence_except_stop_words = <span class=\"hljs-number\">0</span>\n        <span class=\"hljs-keyword\">for</span> wordValue <span class=\"hljs-keyword\">in</span> freqTable:\n            <span class=\"hljs-keyword\">if</span> wordValue <span class=\"hljs-keyword\">in</span> sentence.lower():\n                word_count_in_sentence_except_stop_words += <span class=\"hljs-number\">1</span>\n                <span class=\"hljs-keyword\">if</span> sentence[:<span class=\"hljs-number\">10</span>] <span class=\"hljs-keyword\">in</span> sentenceValue:\n                    sentenceValue[sentence[:<span class=\"hljs-number\">10</span>]] += freqTable[wordValue]\n                <span class=\"hljs-keyword\">else</span>:\n                    sentenceValue[sentence[:<span class=\"hljs-number\">10</span>]] = freqTable[wordValue]\n\n        <span class=\"hljs-keyword\">if</span> sentence[:<span class=\"hljs-number\">10</span>] <span class=\"hljs-keyword\">in</span> sentenceValue:\n            sentenceValue[sentence[:<span class=\"hljs-number\">10</span>]] = sentenceValue[sentence[:<span class=\"hljs-number\">10</span>]] / word_count_in_sentence_except_stop_words\n\n        <span class=\"hljs-string\">'''\n        Notice that a potential issue with our score algorithm is that long sentences will have an advantage over short sentences. \n        To solve this, we're dividing every sentence score by the number of words in the sentence.\n        \n        Note that here sentence[:10] is the first 10 character of any sentence, this is to save memory while saving keys of\n        the dictionary.\n        '''</span>\n\n    <span class=\"hljs-keyword\">return</span> sentenceValue\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_find_average_score</span>(<span class=\"hljs-params\">sentenceValue</span>) -&gt; int:</span>\n    <span class=\"hljs-string\">\"\"\"\n    Find the average score from the sentence value dictionary\n    :rtype: int\n    \"\"\"</span>\n    sumValues = <span class=\"hljs-number\">0</span>\n    <span class=\"hljs-keyword\">for</span> entry <span class=\"hljs-keyword\">in</span> sentenceValue:\n        sumValues += sentenceValue[entry]\n\n    <span class=\"hljs-comment\"># Average value of a sentence from original text</span>\n    average = (sumValues / <span class=\"hljs-built_in\">len</span>(sentenceValue))\n\n    <span class=\"hljs-keyword\">return</span> average\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\"></span><div style=\"display: inline;\" id=\"summarizer_0\" class=\"highlights fea_summarizer\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_generate_summary</span>(<span class=\"hljs-params\">sentences, sentenceValue, threshold</span>):</div></span>\n    sentence_count = <span class=\"hljs-number\">0</span>\n    summary = <span class=\"hljs-string\">''</span>\n\n    <span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sentences:\n        <span class=\"hljs-keyword\">if</span> sentence[:<span class=\"hljs-number\">10</span>] <span class=\"hljs-keyword\">in</span> sentenceValue <span class=\"hljs-keyword\">and</span> sentenceValue[sentence[:<span class=\"hljs-number\">10</span>]] &gt;= (threshold):\n            summary += <span class=\"hljs-string\">\" \"</span> + sentence\n            sentence_count += <span class=\"hljs-number\">1</span>\n\n    <span class=\"hljs-keyword\">return</span> summary\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">run_summarization</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-comment\"># 1 Create the word frequency table</span>\n    freq_table = _create_frequency_table(text)\n\n    <span class=\"hljs-string\">'''\n    We already have a sentence tokenizer, so we just need \n    to run the sent_tokenize() method to create the array of sentences.\n    '''</span>\n\n    <span class=\"hljs-comment\"># 2 Tokenize the sentences</span>\n    sentences = sent_tokenize(text)\n\n    <span class=\"hljs-comment\"># 3 Important Algorithm: score the sentences</span>\n    sentence_scores = _score_sentences(sentences, freq_table)\n\n    <span class=\"hljs-comment\"># 4 Find the threshold</span>\n    threshold = _find_average_score(sentence_scores)\n\n    <span class=\"hljs-comment\"># 5 Important Algorithm: Generate the summary</span>\n    summary = _generate_summary(sentences, sentence_scores, <span class=\"hljs-number\">1.3</span> * threshold)\n\n    <span class=\"hljs-keyword\">return</span> summary\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    result = run_summarization(text_str)\n    print(result)\n    <span class=\"hljs-comment\">#https://github.com/akashp1712/nlp-akash/blob/master/text-summarization/Word_Frequency_Summarization.py</span></code></pre></div>",
    "fir_25.py": "<div class=\"codeBlock hljs python\" id=\"fir_25\"><pre id=\"fir_25_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> io\n<span class=\"hljs-keyword\">import</span> random\n<span class=\"hljs-keyword\">import</span> string <span class=\"hljs-comment\"># to process standard python strings</span>\n<span class=\"hljs-keyword\">import</span> warnings\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">from</span> sklearn.feature_extraction.text <span class=\"hljs-keyword\">import</span> TfidfVectorizer\n<span class=\"hljs-keyword\">from</span> sklearn.metrics.pairwise <span class=\"hljs-keyword\">import</span> cosine_similarity\n<span class=\"hljs-keyword\">import</span> warnings\nwarnings.filterwarnings(<span class=\"hljs-string\">'ignore'</span>)\n\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">from</span> nltk.stem <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\nnltk.download(<span class=\"hljs-string\">'popular'</span>, quiet=<span class=\"hljs-literal\">True</span>) <span class=\"hljs-comment\"># for downloading packages</span>\n\nf=<span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">'chatbot.txt'</span>,<span class=\"hljs-string\">'r'</span>,errors = <span class=\"hljs-string\">'ignore'</span>)\nraw=f.read()\nraw = raw.lower()<span class=\"hljs-comment\"># converts to lowercase</span>\n\n<div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">sent_tokens = nltk.sent_tokenize(raw)<span class=\"hljs-comment\"># converts to list of sentences </span>\nword_tokens = nltk.word_tokenize(raw)</div><span class=\"hljs-comment\"># converts to list of words</span>\n\n<div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">lemmer = nltk.stem.WordNetLemmatizer()</div>\n<span class=\"hljs-comment\">#WordNet is a semantically-oriented dictionary of English included in NLTK.</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">LemTokens</span>(<span class=\"hljs-params\">tokens</span>):</span>\n    <span class=\"hljs-keyword\">return</span> [lemmer.lemmatize(token) <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> tokens]\nremove_punct_dict = <span class=\"hljs-built_in\">dict</span>((<span class=\"hljs-built_in\">ord</span>(punct), <span class=\"hljs-literal\">None</span>) <span class=\"hljs-keyword\">for</span> punct <span class=\"hljs-keyword\">in</span> string.punctuation)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">LemNormalize</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-keyword\">return</span> LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n\nGREETING_INPUTS = (<span class=\"hljs-string\">\"hello\"</span>, <span class=\"hljs-string\">\"hi\"</span>, <span class=\"hljs-string\">\"greetings\"</span>, <span class=\"hljs-string\">\"sup\"</span>, <span class=\"hljs-string\">\"what's up\"</span>,<span class=\"hljs-string\">\"hey\"</span>,)\nGREETING_RESPONSES = [<span class=\"hljs-string\">\"hi\"</span>, <span class=\"hljs-string\">\"hey\"</span>, <span class=\"hljs-string\">\"*nods*\"</span>, <span class=\"hljs-string\">\"hi there\"</span>, <span class=\"hljs-string\">\"hello\"</span>, <span class=\"hljs-string\">\"I am glad! You are talking to me\"</span>]\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">greeting</span>(<span class=\"hljs-params\">sentence</span>):</span>\n \n    <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> sentence.split():\n        <span class=\"hljs-keyword\">if</span> word.lower() <span class=\"hljs-keyword\">in</span> GREETING_INPUTS:\n            <span class=\"hljs-keyword\">return</span> random.choice(GREETING_RESPONSES)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">response</span>(<span class=\"hljs-params\">user_response</span>):</span>\n    robo_response=<span class=\"hljs-string\">''</span>\n    sent_tokens.append(user_response)\n    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=<span class=\"hljs-string\">'english'</span>)\n    tfidf = TfidfVec.fit_transform(sent_tokens)\n    vals = cosine_similarity(tfidf[-<span class=\"hljs-number\">1</span>], tfidf)\n    idx=vals.argsort()[<span class=\"hljs-number\">0</span>][-<span class=\"hljs-number\">2</span>]\n    flat = vals.flatten()\n    flat.sort()\n    req_tfidf = flat[-<span class=\"hljs-number\">2</span>]\n    <span class=\"hljs-keyword\">if</span>(req_tfidf==<span class=\"hljs-number\">0</span>):\n        robo_response=robo_response+<span class=\"hljs-string\">\"I am sorry! I don't understand you\"</span>\n        <span class=\"hljs-keyword\">return</span> robo_response\n    <span class=\"hljs-keyword\">else</span>:\n        robo_response = robo_response+sent_tokens[idx]\n        <span class=\"hljs-keyword\">return</span> robo_response\n\nflag=<span class=\"hljs-literal\">True</span>\nprint(<span class=\"hljs-string\">\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\"</span>)\n<span class=\"hljs-keyword\">while</span>(flag==<span class=\"hljs-literal\">True</span>):\n    user_response = <span class=\"hljs-built_in\">input</span>()\n    user_response=user_response.lower()\n    <span class=\"hljs-keyword\">if</span>(user_response!=<span class=\"hljs-string\">'bye'</span>):\n        <span class=\"hljs-keyword\">if</span>(user_response==<span class=\"hljs-string\">'thanks'</span> <span class=\"hljs-keyword\">or</span> user_response==<span class=\"hljs-string\">'thank you'</span> ):\n            flag=<span class=\"hljs-literal\">False</span>\n            print(<span class=\"hljs-string\">\"ROBO: You are welcome..\"</span>)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-keyword\">if</span>(greeting(user_response)!=<span class=\"hljs-literal\">None</span>):\n                print(<span class=\"hljs-string\">\"ROBO: \"</span>+greeting(user_response))\n            <span class=\"hljs-keyword\">else</span>:\n                print(<span class=\"hljs-string\">\"ROBO: \"</span>,end=<span class=\"hljs-string\">\"\"</span>)\n                print(response(user_response))\n                sent_tokens.remove(user_response)\n    <span class=\"hljs-keyword\">else</span>:\n        flag=<span class=\"hljs-literal\">False</span>\n        print(<span class=\"hljs-string\">\"ROBO: Bye! take care..\"</span>)</code></pre></div>",
    "fir_29.py": "<div class=\"codeBlock hljs python\" id=\"fir_29\"><pre id=\"fir_29_code\" ><code class=\"javascript\"><span class=\"hljs-string\">''' Text Keyword Match'''</span>\n<span class=\"hljs-comment\">#--------------------------------</span>\n<span class=\"hljs-comment\"># Date : 19-06-2020</span>\n<span class=\"hljs-comment\"># Project : Text Keyword Match</span>\n<span class=\"hljs-comment\"># Category : NLP/NLTK sentence Scoring</span>\n<span class=\"hljs-comment\"># Company : weblineindia</span>\n<span class=\"hljs-comment\"># Department : AI/ML</span>\n<span class=\"hljs-comment\">#--------------------------------</span>\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> sent_tokenize\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize\n<span class=\"hljs-keyword\">from</span> nltk.stem <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\n<span class=\"hljs-keyword\">from</span> nltk.translate.bleu_score <span class=\"hljs-keyword\">import</span> sentence_bleu\n\n<div style=\"display: inline;\" id=\"lemmatization_1\" class=\"highlights fea_lemmatization\">lemmatizer = WordNetLemmatizer()</div>\n<div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stop_words = <span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">'english'</span>))</div>\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">scoreText</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    A class used to score sentences based on the input keyword\n    \"\"\"</span>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span>\n\n        self.sentences = []\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">cleanText</span>(<span class=\"hljs-params\">self,sentences</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Eliminates the duplicates and cleans the text\n        \"\"\"</span>\n        <span class=\"hljs-keyword\">try</span>:\n            sentences = <span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">set</span>(sentences))\n            mainBody = []\n            <span class=\"hljs-keyword\">for</span> i, text <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(sentences):\n                text = re.sub(<span class=\"hljs-string\">\"[-()\\\"#/@&amp;&amp;^*();:&lt;&gt;{}`+=~|!?,]\"</span>, <span class=\"hljs-string\">\"\"</span>, text)\n                mainBody.append(text)\n            <span class=\"hljs-keyword\">return</span> mainBody\n        <span class=\"hljs-keyword\">except</span>:\n            print(<span class=\"hljs-string\">\"Error occured in text clean\"</span>)\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">preProcessText</span>(<span class=\"hljs-params\">self,sentences</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Tokenization of sentence and lemmatization of words\n        \"\"\"</span>\n        <span class=\"hljs-keyword\">try</span>:\n            <span class=\"hljs-comment\"># Tokenize words in a sentence</span>\n            <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">word_tokens = word_tokenize(sentences)</div>\n            <span class=\"hljs-comment\"># Lemmatization of words</span>\n            wordlist = [<div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">lemmatizer.lemmatize(w)</div> <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> word_tokens <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> w <span class=\"hljs-keyword\">in</span> stop_words]\n\n            <span class=\"hljs-keyword\">return</span> wordlist\n        <span class=\"hljs-keyword\">except</span>:\n            print(<span class=\"hljs-string\">\"Error occured in text preprocessing\"</span>)\n\n    <span class=\"hljs-comment\"># similarity of subject</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">scoreText</span>(<span class=\"hljs-params\">self,keyword,sentences</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Compares sentences with keyword with bleu scoring technique\n        \"\"\"</span>\n        <span class=\"hljs-keyword\">try</span>:\n            <span class=\"hljs-comment\"># Remove symbols from text</span>\n            sentences = self.cleanText(sentences)\n            \n            <span class=\"hljs-comment\"># Tokenization and Lennatization of the keyword</span>\n            keywordList = self.preProcessText(keyword)\n\n            scoredSentencesList = []\n            <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(sentences)):\n               \n                <span class=\"hljs-comment\"># Tokenization and Lennatization of the sentences</span>\n                wordlist = self.preProcessText(sentences[i])\n\n                <span class=\"hljs-comment\">#list of keyword taken as reference</span>\n                reference = [keywordList]\n                <span class=\"hljs-comment\">#sentence bleu calculates the score based on 1-gram,2-gram,3-gram-4-gram,</span>\n                <span class=\"hljs-comment\">#and a cumulative of the above is taken as score of the sentence.</span>\n                <div style=\"display: inline;\" id=\"text_scoring_0\" class=\"highlights fea_text_scoring\">bleu_score_1 = sentence_bleu(reference, wordlist, weights=(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>))\n                bleu_score_2 = sentence_bleu(reference, wordlist, weights=(<span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>))\n                bleu_score_3 = sentence_bleu(reference, wordlist, weights=(<span class=\"hljs-number\">0.33</span>, <span class=\"hljs-number\">0.33</span>, <span class=\"hljs-number\">0.34</span>, <span class=\"hljs-number\">0</span>))\n                bleu_score_4 = sentence_bleu(reference, wordlist, weights=(<span class=\"hljs-number\">0.25</span>, <span class=\"hljs-number\">0.25</span>, <span class=\"hljs-number\">0.25</span>, <span class=\"hljs-number\">0.25</span>))\n                bleu_score = ( <span class=\"hljs-number\">4</span>*bleu_score_4 + <span class=\"hljs-number\">3</span>*bleu_score_3 + <span class=\"hljs-number\">2</span>*bleu_score_2 + bleu_score_1 )/<span class=\"hljs-number\">10</span></div><span class=\"hljs-number\"></span>\n\n                <span class=\"hljs-comment\">#append the score with sentence to the list</span>\n                scList = [bleu_score,sentences[i]]\n                scoredSentencesList.append(scList)\n            <span class=\"hljs-keyword\">return</span> scoredSentencesList\n\n\n        <span class=\"hljs-keyword\">except</span>:\n            print(<span class=\"hljs-string\">\"Error occured in score text\"</span>)\n\n   \n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">sortText</span>(<span class=\"hljs-params\">self,scoredText</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Returns 3 top scored list of sentences\n        \"\"\"</span>\n        <span class=\"hljs-keyword\">try</span>:\n            scoredTexts = <span class=\"hljs-built_in\">sorted</span>(scoredText, key = <span class=\"hljs-keyword\">lambda</span> x: x[<span class=\"hljs-number\">0</span>],reverse=<span class=\"hljs-literal\">True</span>)\n            scoredTexts = [v[<span class=\"hljs-number\">1</span>] <span class=\"hljs-keyword\">for</span> i,v <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(scoredTexts) <span class=\"hljs-keyword\">if</span> i &lt; <span class=\"hljs-number\">3</span>]\n            <span class=\"hljs-keyword\">return</span> scoredTexts\n        <span class=\"hljs-keyword\">except</span>:\n            print(<span class=\"hljs-string\">\"Error occured in sorting text\"</span>)\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">sentenceMatch</span>(<span class=\"hljs-params\">self,keyword,paragraph</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Converts paragraph into list and calls scoreText and sortText functions,\n        and returns the most matching sentences with the keywords.\n        \"\"\"</span>\n        <span class=\"hljs-keyword\">try</span>:\n            sentencesList = sent_tokenize(paragraph)\n            scoredSentence = self.scoreText(keyword,sentencesList)\n            sortedSentence = self.sortText(scoredSentence)\n            <span class=\"hljs-keyword\">return</span> sortedSentence\n        <span class=\"hljs-keyword\">except</span>:\n            print(<span class=\"hljs-string\">\"Error occured in sentence match\"</span>)\n        <span class=\"hljs-comment\">#https://github.com/weblineindia/AIML-NLP-Text-Scoring/blob/master/scoring.py</span></code></pre></div>",
    "fir_30.py": "<div class=\"codeBlock hljs python\" id=\"fir_30\"><pre id=\"fir_30_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># MIT License</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># Copyright (c) 2021 Greg James</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># Permission is hereby granted, free of charge, to any person obtaining a copy</span>\n<span class=\"hljs-comment\"># of this software and associated documentation files (the \"Software\"), to deal</span>\n<span class=\"hljs-comment\"># in the Software without restriction, including without limitation the rights</span>\n<span class=\"hljs-comment\"># to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span>\n<span class=\"hljs-comment\"># copies of the Software, and to permit persons to whom the Software is</span>\n<span class=\"hljs-comment\"># furnished to do so, subject to the following conditions:</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># The above copyright notice and this permission notice shall be included in all</span>\n<span class=\"hljs-comment\"># copies or substantial portions of the Software.</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>\n<span class=\"hljs-comment\"># IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>\n<span class=\"hljs-comment\"># FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span>\n<span class=\"hljs-comment\"># AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>\n<span class=\"hljs-comment\"># LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span>\n<span class=\"hljs-comment\"># OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span>\n<span class=\"hljs-comment\"># SOFTWARE.</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># RESOURCES USED:</span>\n<span class=\"hljs-comment\"># https://towardsdatascience.com/text-normalization-for-natural-language-processing-nlp-70a314bfa646</span>\n<span class=\"hljs-comment\"># https://stackoverflow.com/questions/8376691/how-to-remove-hashtag-user-link-of-a-tweet-using-regular-expression</span>\n<span class=\"hljs-comment\"># https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python</span>\n<span class=\"hljs-comment\"># https://stats.stackexchange.com/questions/70801/how-to-normalize-data-to-0-1-range</span>\n<span class=\"hljs-comment\"># https://stackoverflow.com/questions/48966176/tweepy-truncated-tweets-when-using-tweet-mode-extended</span>\n<span class=\"hljs-comment\"># https://stackoverflow.com/questions/4270301/matplotlib-multiple-datasets-on-the-same-scatter-plot</span>\n<span class=\"hljs-comment\"># https://docs.tweepy.org/en/latest/streaming_how_to.html</span>\n<span class=\"hljs-comment\"># https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk</span>\n<span class=\"hljs-comment\"># http://www.nltk.org/howto/twitter.html</span>\n<span class=\"hljs-comment\"># https://docs.python.org/3/library/datetime.html#timedelta-objects</span>\n<span class=\"hljs-comment\"># https://pandas.pydata.org/pandas-docs/stable/reference/index.html</span>\n<span class=\"hljs-comment\"># https://learn.sparkfun.com/tutorials/graph-sensor-data-with-python-and-matplotlib/update-a-graph-in-real-time</span>\n<span class=\"hljs-comment\"># https://www.r-bloggers.com/2018/07/how-to-get-live-stock-prices-with-python/</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># LIBRARIES USED:</span>\n<span class=\"hljs-comment\"># https://github.com/tweepy/tweepy</span>\n<span class=\"hljs-comment\"># https://www.nltk.org/</span>\n<span class=\"hljs-comment\"># https://matplotlib.org/stable/index.html</span>\n<span class=\"hljs-comment\"># https://pypi.org/project/yahoo-fin/</span>\n<span class=\"hljs-comment\"># https://pandas.pydata.org/</span>\n\n<span class=\"hljs-keyword\">import</span> tweepy\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize\n<span class=\"hljs-keyword\">from</span> nltk.stem.wordnet <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\n<span class=\"hljs-keyword\">from</span> nltk.tag <span class=\"hljs-keyword\">import</span> pos_tag\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> twitter_samples\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> classify\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> NaiveBayesClassifier\n<span class=\"hljs-keyword\">from</span> collections <span class=\"hljs-keyword\">import</span> Counter\n<span class=\"hljs-keyword\">import</span> datetime <span class=\"hljs-keyword\">as</span> dt\n<span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> thr\n<span class=\"hljs-keyword\">import</span> matplotlib.animation <span class=\"hljs-keyword\">as</span> animation\n<span class=\"hljs-keyword\">import</span> random\n<span class=\"hljs-keyword\">import</span> pandas_datareader.data <span class=\"hljs-keyword\">as</span> web\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">from</span> yahoo_fin <span class=\"hljs-keyword\">import</span> stock_info <span class=\"hljs-keyword\">as</span> si\n\n<span class=\"hljs-comment\">#twitter auth info MODIFY THIS WITH YOUR TOKENS</span>\nauth = tweepy.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_token_secret)\n\n<span class=\"hljs-comment\">#tweepy api object</span>\napi = tweepy.API(auth)\n\n<span class=\"hljs-comment\">#Load the positive and negative datasets from nltk</span>\npositive_tweets = twitter_samples.strings(<span class=\"hljs-string\">'positive_tweets.json'</span>)\nnegative_tweets = twitter_samples.strings(<span class=\"hljs-string\">'negative_tweets.json'</span>)\n\n<span class=\"hljs-comment\">#contractions dictionary for replacing them in tweets</span>\ncontractions_dict = { \n<span class=\"hljs-string\">\"ain't\"</span>: <span class=\"hljs-string\">\"am not / are not / is not / has not / have not\"</span>,\n<span class=\"hljs-string\">\"aren't\"</span>: <span class=\"hljs-string\">\"are not / am not\"</span>,\n<span class=\"hljs-string\">\"can't\"</span>: <span class=\"hljs-string\">\"cannot\"</span>,\n<span class=\"hljs-string\">\"can't've\"</span>: <span class=\"hljs-string\">\"cannot have\"</span>,\n<span class=\"hljs-string\">\"'cause\"</span>: <span class=\"hljs-string\">\"because\"</span>,\n<span class=\"hljs-string\">\"could've\"</span>: <span class=\"hljs-string\">\"could have\"</span>,\n<span class=\"hljs-string\">\"couldn't\"</span>: <span class=\"hljs-string\">\"could not\"</span>,\n<span class=\"hljs-string\">\"couldn't've\"</span>: <span class=\"hljs-string\">\"could not have\"</span>,\n<span class=\"hljs-string\">\"didn't\"</span>: <span class=\"hljs-string\">\"did not\"</span>,\n<span class=\"hljs-string\">\"doesn't\"</span>: <span class=\"hljs-string\">\"does not\"</span>,\n<span class=\"hljs-string\">\"don't\"</span>: <span class=\"hljs-string\">\"do not\"</span>,\n<span class=\"hljs-string\">\"hadn't\"</span>: <span class=\"hljs-string\">\"had not\"</span>,\n<span class=\"hljs-string\">\"hadn't've\"</span>: <span class=\"hljs-string\">\"had not have\"</span>,\n<span class=\"hljs-string\">\"hasn't\"</span>: <span class=\"hljs-string\">\"has not\"</span>,\n<span class=\"hljs-string\">\"haven't\"</span>: <span class=\"hljs-string\">\"have not\"</span>,\n<span class=\"hljs-string\">\"he'd\"</span>: <span class=\"hljs-string\">\"he had / he would\"</span>,\n<span class=\"hljs-string\">\"he'd've\"</span>: <span class=\"hljs-string\">\"he would have\"</span>,\n<span class=\"hljs-string\">\"he'll\"</span>: <span class=\"hljs-string\">\"he shall / he will\"</span>,\n<span class=\"hljs-string\">\"he'll've\"</span>: <span class=\"hljs-string\">\"he shall have / he will have\"</span>,\n<span class=\"hljs-string\">\"he's\"</span>: <span class=\"hljs-string\">\"he has / he is\"</span>,\n<span class=\"hljs-string\">\"how'd\"</span>: <span class=\"hljs-string\">\"how did\"</span>,\n<span class=\"hljs-string\">\"how'd'y\"</span>: <span class=\"hljs-string\">\"how do you\"</span>,\n<span class=\"hljs-string\">\"how'll\"</span>: <span class=\"hljs-string\">\"how will\"</span>,\n<span class=\"hljs-string\">\"how's\"</span>: <span class=\"hljs-string\">\"how has / how is / how does\"</span>,\n<span class=\"hljs-string\">\"I'd\"</span>: <span class=\"hljs-string\">\"I had / I would\"</span>,\n<span class=\"hljs-string\">\"I'd've\"</span>: <span class=\"hljs-string\">\"I would have\"</span>,\n<span class=\"hljs-string\">\"I'll\"</span>: <span class=\"hljs-string\">\"I shall / I will\"</span>,\n<span class=\"hljs-string\">\"I'll've\"</span>: <span class=\"hljs-string\">\"I shall have / I will have\"</span>,\n<span class=\"hljs-string\">\"I'm\"</span>: <span class=\"hljs-string\">\"I am\"</span>,\n<span class=\"hljs-string\">\"I've\"</span>: <span class=\"hljs-string\">\"I have\"</span>,\n<span class=\"hljs-string\">\"isn't\"</span>: <span class=\"hljs-string\">\"is not\"</span>,\n<span class=\"hljs-string\">\"it'd\"</span>: <span class=\"hljs-string\">\"it had / it would\"</span>,\n<span class=\"hljs-string\">\"it'd've\"</span>: <span class=\"hljs-string\">\"it would have\"</span>,\n<span class=\"hljs-string\">\"it'll\"</span>: <span class=\"hljs-string\">\"it shall / it will\"</span>,\n<span class=\"hljs-string\">\"it'll've\"</span>: <span class=\"hljs-string\">\"it shall have / it will have\"</span>,\n<span class=\"hljs-string\">\"it's\"</span>: <span class=\"hljs-string\">\"it has / it is\"</span>,\n<span class=\"hljs-string\">\"let's\"</span>: <span class=\"hljs-string\">\"let us\"</span>,\n<span class=\"hljs-string\">\"ma'am\"</span>: <span class=\"hljs-string\">\"madam\"</span>,\n<span class=\"hljs-string\">\"mayn't\"</span>: <span class=\"hljs-string\">\"may not\"</span>,\n<span class=\"hljs-string\">\"might've\"</span>: <span class=\"hljs-string\">\"might have\"</span>,\n<span class=\"hljs-string\">\"mightn't\"</span>: <span class=\"hljs-string\">\"might not\"</span>,\n<span class=\"hljs-string\">\"mightn't've\"</span>: <span class=\"hljs-string\">\"might not have\"</span>,\n<span class=\"hljs-string\">\"must've\"</span>: <span class=\"hljs-string\">\"must have\"</span>,\n<span class=\"hljs-string\">\"mustn't\"</span>: <span class=\"hljs-string\">\"must not\"</span>,\n<span class=\"hljs-string\">\"mustn't've\"</span>: <span class=\"hljs-string\">\"must not have\"</span>,\n<span class=\"hljs-string\">\"needn't\"</span>: <span class=\"hljs-string\">\"need not\"</span>,\n<span class=\"hljs-string\">\"needn't've\"</span>: <span class=\"hljs-string\">\"need not have\"</span>,\n<span class=\"hljs-string\">\"o'clock\"</span>: <span class=\"hljs-string\">\"of the clock\"</span>,\n<span class=\"hljs-string\">\"oughtn't\"</span>: <span class=\"hljs-string\">\"ought not\"</span>,\n<span class=\"hljs-string\">\"oughtn't've\"</span>: <span class=\"hljs-string\">\"ought not have\"</span>,\n<span class=\"hljs-string\">\"shan't\"</span>: <span class=\"hljs-string\">\"shall not\"</span>,\n<span class=\"hljs-string\">\"sha'n't\"</span>: <span class=\"hljs-string\">\"shall not\"</span>,\n<span class=\"hljs-string\">\"shan't've\"</span>: <span class=\"hljs-string\">\"shall not have\"</span>,\n<span class=\"hljs-string\">\"she'd\"</span>: <span class=\"hljs-string\">\"she had / she would\"</span>,\n<span class=\"hljs-string\">\"she'd've\"</span>: <span class=\"hljs-string\">\"she would have\"</span>,\n<span class=\"hljs-string\">\"she'll\"</span>: <span class=\"hljs-string\">\"she shall / she will\"</span>,\n<span class=\"hljs-string\">\"she'll've\"</span>: <span class=\"hljs-string\">\"she shall have / she will have\"</span>,\n<span class=\"hljs-string\">\"she's\"</span>: <span class=\"hljs-string\">\"she has / she is\"</span>,\n<span class=\"hljs-string\">\"should've\"</span>: <span class=\"hljs-string\">\"should have\"</span>,\n<span class=\"hljs-string\">\"shouldn't\"</span>: <span class=\"hljs-string\">\"should not\"</span>,\n<span class=\"hljs-string\">\"shouldn't've\"</span>: <span class=\"hljs-string\">\"should not have\"</span>,\n<span class=\"hljs-string\">\"so've\"</span>: <span class=\"hljs-string\">\"so have\"</span>,\n<span class=\"hljs-string\">\"so's\"</span>: <span class=\"hljs-string\">\"so as / so is\"</span>,\n<span class=\"hljs-string\">\"that'd\"</span>: <span class=\"hljs-string\">\"that would / that had\"</span>,\n<span class=\"hljs-string\">\"that'd've\"</span>: <span class=\"hljs-string\">\"that would have\"</span>,\n<span class=\"hljs-string\">\"that's\"</span>: <span class=\"hljs-string\">\"that has / that is\"</span>,\n<span class=\"hljs-string\">\"there'd\"</span>: <span class=\"hljs-string\">\"there had / there would\"</span>,\n<span class=\"hljs-string\">\"there'd've\"</span>: <span class=\"hljs-string\">\"there would have\"</span>,\n<span class=\"hljs-string\">\"there's\"</span>: <span class=\"hljs-string\">\"there has / there is\"</span>,\n<span class=\"hljs-string\">\"they'd\"</span>: <span class=\"hljs-string\">\"they had / they would\"</span>,\n<span class=\"hljs-string\">\"they'd've\"</span>: <span class=\"hljs-string\">\"they would have\"</span>,\n<span class=\"hljs-string\">\"they'll\"</span>: <span class=\"hljs-string\">\"they shall / they will\"</span>,\n<span class=\"hljs-string\">\"they'll've\"</span>: <span class=\"hljs-string\">\"they shall have / they will have\"</span>,\n<span class=\"hljs-string\">\"they're\"</span>: <span class=\"hljs-string\">\"they are\"</span>,\n<span class=\"hljs-string\">\"they've\"</span>: <span class=\"hljs-string\">\"they have\"</span>,\n<span class=\"hljs-string\">\"to've\"</span>: <span class=\"hljs-string\">\"to have\"</span>,\n<span class=\"hljs-string\">\"wasn't\"</span>: <span class=\"hljs-string\">\"was not\"</span>,\n<span class=\"hljs-string\">\"we'd\"</span>: <span class=\"hljs-string\">\"we had / we would\"</span>,\n<span class=\"hljs-string\">\"we'd've\"</span>: <span class=\"hljs-string\">\"we would have\"</span>,\n<span class=\"hljs-string\">\"we'll\"</span>: <span class=\"hljs-string\">\"we will\"</span>,\n<span class=\"hljs-string\">\"we'll've\"</span>: <span class=\"hljs-string\">\"we will have\"</span>,\n<span class=\"hljs-string\">\"we're\"</span>: <span class=\"hljs-string\">\"we are\"</span>,\n<span class=\"hljs-string\">\"we've\"</span>: <span class=\"hljs-string\">\"we have\"</span>,\n<span class=\"hljs-string\">\"weren't\"</span>: <span class=\"hljs-string\">\"were not\"</span>,\n<span class=\"hljs-string\">\"what'll\"</span>: <span class=\"hljs-string\">\"what shall / what will\"</span>,\n<span class=\"hljs-string\">\"what'll've\"</span>: <span class=\"hljs-string\">\"what shall have / what will have\"</span>,\n<span class=\"hljs-string\">\"what're\"</span>: <span class=\"hljs-string\">\"what are\"</span>,\n<span class=\"hljs-string\">\"what's\"</span>: <span class=\"hljs-string\">\"what has / what is\"</span>,\n<span class=\"hljs-string\">\"what've\"</span>: <span class=\"hljs-string\">\"what have\"</span>,\n<span class=\"hljs-string\">\"when's\"</span>: <span class=\"hljs-string\">\"when has / when is\"</span>,\n<span class=\"hljs-string\">\"when've\"</span>: <span class=\"hljs-string\">\"when have\"</span>,\n<span class=\"hljs-string\">\"where'd\"</span>: <span class=\"hljs-string\">\"where did\"</span>,\n<span class=\"hljs-string\">\"where's\"</span>: <span class=\"hljs-string\">\"where has / where is\"</span>,\n<span class=\"hljs-string\">\"where've\"</span>: <span class=\"hljs-string\">\"where have\"</span>,\n<span class=\"hljs-string\">\"who'll\"</span>: <span class=\"hljs-string\">\"who shall / who will\"</span>,\n<span class=\"hljs-string\">\"who'll've\"</span>: <span class=\"hljs-string\">\"who shall have / who will have\"</span>,\n<span class=\"hljs-string\">\"who's\"</span>: <span class=\"hljs-string\">\"who has / who is\"</span>,\n<span class=\"hljs-string\">\"who've\"</span>: <span class=\"hljs-string\">\"who have\"</span>,\n<span class=\"hljs-string\">\"why's\"</span>: <span class=\"hljs-string\">\"why has / why is\"</span>,\n<span class=\"hljs-string\">\"why've\"</span>: <span class=\"hljs-string\">\"why have\"</span>,\n<span class=\"hljs-string\">\"will've\"</span>: <span class=\"hljs-string\">\"will have\"</span>,\n<span class=\"hljs-string\">\"won't\"</span>: <span class=\"hljs-string\">\"will not\"</span>,\n<span class=\"hljs-string\">\"won't've\"</span>: <span class=\"hljs-string\">\"will not have\"</span>,\n<span class=\"hljs-string\">\"would've\"</span>: <span class=\"hljs-string\">\"would have\"</span>,\n<span class=\"hljs-string\">\"wouldn't\"</span>: <span class=\"hljs-string\">\"would not\"</span>,\n<span class=\"hljs-string\">\"wouldn't've\"</span>: <span class=\"hljs-string\">\"would not have\"</span>,\n<span class=\"hljs-string\">\"y'all\"</span>: <span class=\"hljs-string\">\"you all\"</span>,\n<span class=\"hljs-string\">\"y'all'd\"</span>: <span class=\"hljs-string\">\"you all would\"</span>,\n<span class=\"hljs-string\">\"y'all'd've\"</span>: <span class=\"hljs-string\">\"you all would have\"</span>,\n<span class=\"hljs-string\">\"y'all're\"</span>: <span class=\"hljs-string\">\"you all are\"</span>,\n<span class=\"hljs-string\">\"y'all've\"</span>: <span class=\"hljs-string\">\"you all have\"</span>,\n<span class=\"hljs-string\">\"you'd\"</span>: <span class=\"hljs-string\">\"you had / you would\"</span>,\n<span class=\"hljs-string\">\"you'd've\"</span>: <span class=\"hljs-string\">\"you would have\"</span>,\n<span class=\"hljs-string\">\"you'll\"</span>: <span class=\"hljs-string\">\"you shall / you will\"</span>,\n<span class=\"hljs-string\">\"you'll've\"</span>: <span class=\"hljs-string\">\"you shall have / you will have\"</span>,\n<span class=\"hljs-string\">\"you're\"</span>: <span class=\"hljs-string\">\"you are\"</span>,\n<span class=\"hljs-string\">\"you've\"</span>: <span class=\"hljs-string\">\"you have\"</span>\n}\n\ncontractions_re = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">'(%s)'</span>%<span class=\"hljs-string\">'|'</span>.join(contractions_dict.keys()))\n\n<span class=\"hljs-comment\">#function to remove contractions from tweets</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">expand_contractions</span>(<span class=\"hljs-params\">s, contractions_dict=contractions_dict</span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">replace</span>(<span class=\"hljs-params\">match</span>):</span>\n        <span class=\"hljs-keyword\">return</span> contractions_dict[match.group(<span class=\"hljs-number\">0</span>)]\n    <span class=\"hljs-keyword\">return</span> contractions_re.sub(replace, s)\n\n<span class=\"hljs-comment\">#function to clean, tokenize, and lemmatize tweets</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">clean</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-comment\">#remove the contractions</span>\n    unclean = expand_contractions(text)\n\n    <span class=\"hljs-comment\">#remove http urls</span>\n    tweet = re.sub(<span class=\"hljs-string\">r\"http\\S+\"</span>, <span class=\"hljs-string\">\"\"</span>, unclean)\n    \n    <span class=\"hljs-comment\">#remove https urls</span>\n    tweet = re.sub(<span class=\"hljs-string\">r\"https\\S+\"</span>, <span class=\"hljs-string\">\"\"</span>, unclean)\n    \n    <span class=\"hljs-comment\">#remove hashtags</span>\n    tweet = re.sub(<span class=\"hljs-string\">r\"#(\\w+)\"</span>, <span class=\"hljs-string\">' '</span>, tweet, flags=re.MULTILINE)\n    \n    <span class=\"hljs-comment\">#remove @ mentions</span>\n    tweet = re.sub(<span class=\"hljs-string\">r\"@(\\w+)\"</span>, <span class=\"hljs-string\">' '</span>, tweet, flags=re.MULTILINE)\n    \n    <span class=\"hljs-comment\">#remove stock symbols from tweets</span>\n    tweet = re.sub(<span class=\"hljs-string\">r\"\\$(\\w+)\"</span>, <span class=\"hljs-string\">' '</span>, tweet, flags=re.MULTILINE)\n    \n    <span class=\"hljs-comment\">#remove digits from tweets</span>\n    tweet = re.sub(<span class=\"hljs-string\">r\"\\d\"</span>, <span class=\"hljs-string\">\"\"</span>, tweet)\n    \n    <span class=\"hljs-comment\">#remove all emojis and punctuation from tweets</span>\n    tweet = <span class=\"hljs-string\">' '</span>.join(re.sub(<span class=\"hljs-string\">\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"</span>,<span class=\"hljs-string\">\" \"</span>,tweet).split())\n    \n    <span class=\"hljs-comment\">#converts tweets to lowercase</span>\n    tweet = tweet.lower()\n    \n    <span class=\"hljs-comment\">#tokenize the normalized tweets</span>\n    <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">sent = word_tokenize(tweet)</div>\n    \n    <span class=\"hljs-comment\">#lemmatize the tokens to get the word stems</span>\n    sentence = lemmatize_sentence(sent)\n    <span class=\"hljs-keyword\">return</span> sentence\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">lemmatize_sentence</span>(<span class=\"hljs-params\">tokens</span>):</span>\n    <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">lemmatizer = WordNetLemmatizer()</div>\n    lemmatized_sentence = []\n\n    <span class=\"hljs-comment\">#Tag parts of speech</span>\n    <span class=\"hljs-keyword\">for</span> word, tag <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">pos_tag(tokens)</div>:\n        <span class=\"hljs-keyword\">if</span> tag.startswith(<span class=\"hljs-string\">'NN'</span>):\n            pos = <span class=\"hljs-string\">'n'</span>\n        <span class=\"hljs-keyword\">elif</span> tag.startswith(<span class=\"hljs-string\">'VB'</span>):\n            pos = <span class=\"hljs-string\">'v'</span>\n        <span class=\"hljs-keyword\">else</span>:\n            pos = <span class=\"hljs-string\">'a'</span>\n        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n    <span class=\"hljs-keyword\">return</span> lemmatized_sentence\n\n<span class=\"hljs-comment\">#text for positive tweets</span>\npositive_tweet_tokens = <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">twitter_samples.strings(<span class=\"hljs-string\">'positive_tweets.json'</span>)</div>\n<span class=\"hljs-comment\">#text for negative tweets</span>\nnegative_tweet_tokens = twitter_samples.strings(<span class=\"hljs-string\">'negative_tweets.json'</span>)\n\npositive_cleaned_tokens_list = []\nnegative_cleaned_tokens_list = []\n\n<span class=\"hljs-comment\">#tokens for the cleaned positive tweets</span>\n<span class=\"hljs-keyword\">for</span> tokens <span class=\"hljs-keyword\">in</span> positive_tweet_tokens:\n    positive_cleaned_tokens_list.append(clean(tokens))\n\n<span class=\"hljs-comment\">#tokens for cleaned negative tweets</span>\n<span class=\"hljs-keyword\">for</span> tokens <span class=\"hljs-keyword\">in</span> negative_tweet_tokens:\n    negative_cleaned_tokens_list.append(clean(tokens))\n\n<span class=\"hljs-comment\">#add stock specific positive tokens</span>\npositive_cleaned_tokens_list.append([<span class=\"hljs-string\">\"up\"</span>, <span class=\"hljs-string\">\"bull\"</span>, <span class=\"hljs-string\">\"bullish\"</span>, <span class=\"hljs-string\">\"high\"</span>])\n\n<span class=\"hljs-comment\">#add stock specific negative tokens</span>\nnegative_cleaned_tokens_list.append([<span class=\"hljs-string\">\"down\"</span>, <span class=\"hljs-string\">\"fall\"</span>, <span class=\"hljs-string\">\"bear\"</span>, <span class=\"hljs-string\">\"bearish\"</span>, <span class=\"hljs-string\">\"low\"</span>])\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_tweets_for_model</span>(<span class=\"hljs-params\">cleaned_tokens_list</span>):</span>\n    <span class=\"hljs-keyword\">for</span> tweet_tokens <span class=\"hljs-keyword\">in</span> cleaned_tokens_list:\n        <span class=\"hljs-keyword\">yield</span> <span class=\"hljs-built_in\">dict</span>([token, <span class=\"hljs-literal\">True</span>] <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> tweet_tokens)\n\npositive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)\nnegative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)\n\n<span class=\"hljs-comment\">#positive data set with label positive</span>\npositive_dataset = [(tweet_dict, <span class=\"hljs-string\">\"Positive\"</span>)\n                     <span class=\"hljs-keyword\">for</span> tweet_dict <span class=\"hljs-keyword\">in</span> positive_tokens_for_model]\n\n<span class=\"hljs-comment\">#negative data set with label negative</span>\nnegative_dataset = [(tweet_dict, <span class=\"hljs-string\">\"Negative\"</span>)\n                     <span class=\"hljs-keyword\">for</span> tweet_dict <span class=\"hljs-keyword\">in</span> negative_tokens_for_model]\n\n<span class=\"hljs-comment\">#combined positive and negative dataset</span>\ndataset = positive_dataset + negative_dataset\n\n<span class=\"hljs-comment\">#shuffle the dataset</span>\nrandom.shuffle(dataset)\n\n<span class=\"hljs-comment\">#train test split from the combined dataset</span>\ntrain_data = dataset[:<span class=\"hljs-number\">7000</span>]\ntest_data = dataset[<span class=\"hljs-number\">7000</span>:]\n\n<span class=\"hljs-comment\">#train the classifier on the train data</span>\n<div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">classifier = NaiveBayesClassifier.train(train_data)</div>\n\n<span class=\"hljs-comment\">#find accuracy based on the test data</span>\nprint(<span class=\"hljs-string\">\"Accuracy is:\"</span>, classify.accuracy(classifier, test_data))\n\n<span class=\"hljs-comment\">#show most informative features for the model</span>\nprint(classifier.show_most_informative_features(<span class=\"hljs-number\">10</span>))\n\nsentiments = []\n\n<span class=\"hljs-comment\"># sentiment analysis for only the top tweets for a ticker</span>\n<span class=\"hljs-comment\"># ticker: the ticker to look up</span>\n<span class=\"hljs-comment\"># mode: 'popular','recent', or 'mixed'</span>\n<span class=\"hljs-comment\"># num: the number of tweets to get</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">topOnly</span>(<span class=\"hljs-params\">ticker, mode, num</span>):</span>\n    <span class=\"hljs-comment\">#search for all the top tweets for a ticker</span>\n    public_tweets = api.search(q=<span class=\"hljs-string\">\"$\"</span>+ticker + <span class=\"hljs-string\">\" -filter:retweets\"</span>,lang=<span class=\"hljs-string\">\"en\"</span>,result_type=mode,count=num,tweet_mode=<span class=\"hljs-string\">'extended'</span>)\n    <span class=\"hljs-keyword\">for</span> tweet <span class=\"hljs-keyword\">in</span> public_tweets:\n        <span class=\"hljs-comment\">#clean the tweet</span>\n        cleaned = clean(tweet.full_text)\n        <span class=\"hljs-comment\">#find the sentiments from the model</span>\n        sentiments.append(classifier.classify(<span class=\"hljs-built_in\">dict</span>([token, <span class=\"hljs-literal\">True</span>] <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> cleaned)))\n    <span class=\"hljs-comment\">#count the number of positive tweets</span>\n    pos = sentiments.count(<span class=\"hljs-string\">\"Positive\"</span>)\n    <span class=\"hljs-comment\">#count the number of negative tweets</span>\n    neg = sentiments.count(<span class=\"hljs-string\">\"Negative\"</span>)\n    <span class=\"hljs-comment\">#find the overall score for the ticker</span>\n    score = ((pos * <span class=\"hljs-number\">1</span>) + (neg * -<span class=\"hljs-number\">1</span>))/(pos+neg)\n    print(score)\n\n<span class=\"hljs-comment\">#list to hold the dates and times</span>\nxs = []\n\n<span class=\"hljs-comment\">#hold the avg of the scores </span>\nys = []\n\n<span class=\"hljs-comment\">#array to hold normalized prices</span>\nprices = []\n\n<span class=\"hljs-comment\">#list to hold the scores</span>\nscores = []\n\n<span class=\"hljs-comment\">#live stream listening</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MyStreamListener</span>(<span class=\"hljs-params\">tweepy.StreamListener</span>):</span>\n    <span class=\"hljs-comment\">#when a new tweet is recieved</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">on_status</span>(<span class=\"hljs-params\">self, status</span>):</span>\n        <span class=\"hljs-comment\">#clean the tweet</span>\n        cleaned = clean(status.text)\n        \n        <span class=\"hljs-comment\">#calculate the sentiment for the tweet</span>\n        <span class=\"hljs-comment\">#sentiments.append(classifier.classify(dict([token, True] for token in cleaned)))</span>\n        \n        <span class=\"hljs-comment\">#calculate the score for the tweet</span>\n        <span class=\"hljs-comment\">#pos = sentiments.count(\"Positive\")</span>\n        <span class=\"hljs-comment\">#neg = sentiments.count(\"Negative\")</span>\n        <span class=\"hljs-comment\">#score = ((pos * 1) + (neg * -1))/(pos+neg)</span>\n        \n        <span class=\"hljs-comment\">#add the score to the array</span>\n        sentiment = classifier.classify(<span class=\"hljs-built_in\">dict</span>([token, <span class=\"hljs-literal\">True</span>] <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> cleaned))\n        \n        <span class=\"hljs-keyword\">if</span> sentiment == <span class=\"hljs-string\">\"Positive\"</span>:\n            scores.append(<span class=\"hljs-number\">1</span>)\n        <span class=\"hljs-keyword\">else</span>:\n            scores.append(-<span class=\"hljs-number\">1</span>)\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">on_error</span>(<span class=\"hljs-params\">self, status_code</span>):</span>\n        <span class=\"hljs-comment\">#stop the stream on error</span>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span>\n\n<span class=\"hljs-comment\"># stream data live for a ticker</span>\n<span class=\"hljs-comment\"># ticker: the ticker to stream</span>\n<span class=\"hljs-comment\"># interval: how often to update the graph (in milliseconds)</span>\n<span class=\"hljs-comment\"># numpoints: number of points to display on the graph</span>\n<span class=\"hljs-comment\"># weeksback: how far back to go for the high/low to normalize stock data</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">stream</span>(<span class=\"hljs-params\">ticker, interval, numpoints, weeksback</span>):</span>\n    <span class=\"hljs-comment\">#get 52 week high and low for normalizizing</span>\n    start = dt.datetime.now() - dt.timedelta(weeks=weeksback)\n    end = dt.datetime.now()\n    \n    df = web.DataReader(ticker, <span class=\"hljs-string\">'yahoo'</span>, start, end)\n    close_px = df[<span class=\"hljs-string\">'Adj Close'</span>]\n\n    high = close_px.<span class=\"hljs-built_in\">max</span>()\n    low = close_px.<span class=\"hljs-built_in\">min</span>()\n\n    <span class=\"hljs-comment\">#matplotlib figure</span>\n    fig = thr.figure()\n    ax = fig.add_subplot(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)\n    \n    <span class=\"hljs-comment\">#clear the arrays</span>\n    sentiments = []\n    \n    <span class=\"hljs-comment\">#start the stream</span>\n    myStreamListener = MyStreamListener()\n    myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)\n    \n    <span class=\"hljs-comment\">#filter for the specified ticker</span>\n    myStream.<span class=\"hljs-built_in\">filter</span>(track=[<span class=\"hljs-string\">\"$\"</span>+ticker], is_async=<span class=\"hljs-literal\">True</span>)\n    \n    <span class=\"hljs-comment\">#animate the graphs</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">animate</span>(<span class=\"hljs-params\">i, xs, ys, scores, prices</span>):</span>\n        <span class=\"hljs-comment\">#add the date to the array</span>\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(scores) != <span class=\"hljs-number\">0</span>:\n            xs.append(dt.datetime.now().strftime(<span class=\"hljs-string\">'%H:%M:%S.%f'</span>))\n            avgscore = <span class=\"hljs-built_in\">sum</span>(scores)/<span class=\"hljs-built_in\">len</span>(scores) \n            ys.append((avgscore-<span class=\"hljs-built_in\">min</span>(scores))/(<span class=\"hljs-built_in\">max</span>(scores)-<span class=\"hljs-built_in\">min</span>(scores)))\n            price = si.get_live_price(ticker)\n            prices.append((price-low)/(high-low))\n\n        <span class=\"hljs-comment\"># Limit x and y lists to 20 items</span>\n        xs = xs[-numpoints:]\n        ys = ys[-numpoints:]\n        prices = prices[-numpoints:]\n\n        <span class=\"hljs-comment\">#clear scores array</span>\n        <span class=\"hljs-comment\">#scores = []</span>\n\n        <span class=\"hljs-comment\"># Draw x and y lists</span>\n        ax.clear()\n        ax.plot(xs, ys, linestyle=<span class=\"hljs-string\">'--'</span>, marker=<span class=\"hljs-string\">'o'</span>, color=<span class=\"hljs-string\">'b'</span>, label=<span class=\"hljs-string\">\"sentiment\"</span>)\n        ax.plot(xs, prices, linestyle=<span class=\"hljs-string\">'--'</span>, marker=<span class=\"hljs-string\">'x'</span>, color=<span class=\"hljs-string\">'r'</span>, label=<span class=\"hljs-string\">\"price\"</span>)\n        ax.fill_between(xs, ys, prices, alpha=<span class=\"hljs-number\">0.7</span>)\n        ax.legend(<span class=\"hljs-string\">\"sentiment\"</span>,<span class=\"hljs-string\">\"price\"</span>)\n        \n        <span class=\"hljs-comment\"># Format plot</span>\n        thr.xticks(rotation=<span class=\"hljs-number\">45</span>, ha=<span class=\"hljs-string\">'right'</span>)\n        thr.subplots_adjust(bottom=<span class=\"hljs-number\">0.30</span>)\n        thr.title(ticker.upper() + <span class=\"hljs-string\">' sentiment over time'</span>)\n        thr.ylabel(<span class=\"hljs-string\">'Sentiment'</span>)\n        thr.xlabel(<span class=\"hljs-string\">'Time'</span>)\n\n    <span class=\"hljs-comment\"># Set up plot to call animate() function periodically</span>\n    ani = animation.FuncAnimation(fig, animate, fargs=(xs, ys, scores, prices), interval=interval)\n    thr.show()\n\n<span class=\"hljs-comment\">#topOnly(\"tsla\", \"popular\", 100)</span>\nstream(<span class=\"hljs-string\">\"tsla\"</span>, <span class=\"hljs-number\">60000</span>, <span class=\"hljs-number\">60</span>, <span class=\"hljs-number\">1</span>)\n<span class=\"hljs-comment\">#https://github.com/gregyjames/twitter-stock-sentiment/blob/main/main.py</span></code></pre></div>",
    "fir_24.py": "<div class=\"codeBlock hljs python\" id=\"fir_24\"><pre id=\"fir_24_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># importing libraries for persorming the sentiment analysis, cleaning data, training and saving model</span>\n<span class=\"hljs-keyword\">import</span> pickle\n<span class=\"hljs-keyword\">import</span> random\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> string\n\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> FreqDist, NaiveBayesClassifier, classify\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords, twitter_samples\n<span class=\"hljs-keyword\">from</span> nltk.stem.wordnet <span class=\"hljs-keyword\">import</span> WordNetLemmatizer\n<span class=\"hljs-keyword\">from</span> nltk.tag <span class=\"hljs-keyword\">import</span> pos_tag\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> word_tokenize\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_noise</span>(<span class=\"hljs-params\">tweet_tokens, stop_words=(<span class=\"hljs-params\"></span>)</span>):</span>\n    <span class=\"hljs-string\">'''This function removes the links or hashtags presesnt in the text and change the verbs to its first form'''</span>\n    cleaned_tokens = []\n\n    <span class=\"hljs-keyword\">for</span> token, tag <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">pos_tag(tweet_tokens)</div>:\n        token = re.sub(<span class=\"hljs-string\">'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+#]|[!*\\(\\),]|'</span>\n                       <span class=\"hljs-string\">'(?:%[0-9a-fA-F][0-9a-fA-F]))+'</span>, <span class=\"hljs-string\">''</span>, token)\n        token = re.sub(<span class=\"hljs-string\">\"(@[A-Za-z0-9_]+)\"</span>, <span class=\"hljs-string\">\"\"</span>, token)\n\n        <span class=\"hljs-keyword\">if</span> tag.startswith(<span class=\"hljs-string\">\"NN\"</span>):\n            pos = <span class=\"hljs-string\">'n'</span>\n        <span class=\"hljs-keyword\">elif</span> tag.startswith(<span class=\"hljs-string\">'VB'</span>):\n            pos = <span class=\"hljs-string\">'v'</span>\n        <span class=\"hljs-keyword\">else</span>:\n            pos = <span class=\"hljs-string\">'a'</span>\n\n        <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">lemmatizer = WordNetLemmatizer()</div>\n        <div style=\"display: inline;\" id=\"lemmatization_1\" class=\"highlights fea_lemmatization\">token = lemmatizer.lemmatize(token, pos)</div>\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(token) &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> token <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> string.punctuation <span class=\"hljs-keyword\">and</span> token.lower() <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> stop_words:\n            cleaned_tokens.append(token.lower())\n    <span class=\"hljs-keyword\">return</span> cleaned_tokens\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_all_words</span>(<span class=\"hljs-params\">cleaned_tokens_list</span>):</span>\n    <span class=\"hljs-string\">'''It acts as an generator for the tokens'''</span>\n    <span class=\"hljs-keyword\">for</span> tokens <span class=\"hljs-keyword\">in</span> cleaned_tokens_list:\n        <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> tokens:\n            <span class=\"hljs-keyword\">yield</span> token\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_tweets_for_model</span>(<span class=\"hljs-params\">cleaned_tokens_list</span>):</span>\n    <span class=\"hljs-string\">'''This function takes the cleaned token list as input and reutrn a list which is suitable to fed to the classifier'''</span>\n    <span class=\"hljs-keyword\">for</span> tweet_tokens <span class=\"hljs-keyword\">in</span> cleaned_tokens_list:\n        <span class=\"hljs-keyword\">yield</span> <span class=\"hljs-built_in\">dict</span>([token, <span class=\"hljs-literal\">True</span>] <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> tweet_tokens)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">predict_sentiment</span>(<span class=\"hljs-params\">sentence, classifier</span>):</span>\n    <span class=\"hljs-string\">'''predict_sentiment function predict the senitment of the text which was given as a argument'''</span>\n    custom_tokens = remove_noise(word_tokenize(sentence))\n    <span class=\"hljs-keyword\">return</span> classifier.classify(\n        <span class=\"hljs-built_in\">dict</span>([token, <span class=\"hljs-literal\">True</span>] <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> custom_tokens))\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">save_model</span>():</span>\n    <span class=\"hljs-string\">'''Saving the trained classifier'''</span>\n    f = <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">'my_classifier.pickle'</span>, <span class=\"hljs-string\">'wb'</span>)\n    pickle.dump(classifier, f)\n    f.close()\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n\n    <span class=\"hljs-comment\"># loading dataset for model trainig</span>\n    <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">positive_tweets = twitter_samples.strings(<span class=\"hljs-string\">'positive_tweets.json'</span>)\n    negative_tweets = twitter_samples.strings(<span class=\"hljs-string\">'negative_tweets.json'</span>)</div>\n    text = twitter_samples.strings(<span class=\"hljs-string\">'tweets.20150430-223406.json'</span>)\n    tweet_tokens = twitter_samples.tokenized(<span class=\"hljs-string\">'positive_tweets.json'</span>)[<span class=\"hljs-number\">0</span>]\n\n    <span class=\"hljs-comment\"># saving the stopwords from the nltk into a variable</span>\n    stop_words = stopwords.words(<span class=\"hljs-string\">'english'</span>)\n\n    positive_tweet_tokens = twitter_samples.tokenized(<span class=\"hljs-string\">'positive_tweets.json'</span>)\n    negative_tweet_tokens = twitter_samples.tokenized(<span class=\"hljs-string\">'negative_tweets.json'</span>)\n\n    positive_cleaned_tokens_list = []\n    negative_cleaned_tokens_list = []\n\n    <span class=\"hljs-keyword\">for</span> tokens <span class=\"hljs-keyword\">in</span> positive_tweet_tokens:\n        positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n\n    <span class=\"hljs-keyword\">for</span> tokens <span class=\"hljs-keyword\">in</span> negative_tweet_tokens:\n        negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n\n    all_pos_words = get_all_words(positive_cleaned_tokens_list)\n\n    <div style=\"display: inline;\" id=\"word_frequency_0\" class=\"highlights fea_word_frequency\">freq_dist_pos = FreqDist(all_pos_words)</div>\n    print(freq_dist_pos.most_common(<span class=\"hljs-number\">10</span>))\n\n    positive_tokens_for_model = get_tweets_for_model(\n        positive_cleaned_tokens_list)\n    negative_tokens_for_model = get_tweets_for_model(\n        negative_cleaned_tokens_list)\n\n    positive_dataset = [(tweet_dict, <span class=\"hljs-string\">\"Positive\"</span>)\n                        <span class=\"hljs-keyword\">for</span> tweet_dict <span class=\"hljs-keyword\">in</span> positive_tokens_for_model]\n\n    negative_dataset = [(tweet_dict, <span class=\"hljs-string\">\"Negative\"</span>)\n                        <span class=\"hljs-keyword\">for</span> tweet_dict <span class=\"hljs-keyword\">in</span> negative_tokens_for_model]\n\n    dataset = positive_dataset + negative_dataset\n\n    random.shuffle(dataset)\n\n    train_data = dataset[: <span class=\"hljs-number\">7000</span>]\n    test_data = dataset[<span class=\"hljs-number\">7000</span>:]\n\n    <div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">classifier = NaiveBayesClassifier.train(train_data)</div>\n\n    print(<span class=\"hljs-string\">\"Accuracy is:\"</span>, classify.accuracy(classifier, test_data))\n\n    print(classifier.show_most_informative_features(<span class=\"hljs-number\">10</span>))\n\n    custom_tweet = <span class=\"hljs-string\">\"I ordered just once from TerribleCo, they screwed up, never used the app again.\"</span>\n\n    custom_tokens = remove_noise(word_tokenize(custom_tweet))\n\n    print(custom_tweet, classifier.classify(\n        <span class=\"hljs-built_in\">dict</span>([token, <span class=\"hljs-literal\">True</span>] <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> custom_tokens)))\n        <span class=\"hljs-comment\">#https://github.com/g-paras/sentiment-analysis-api/blob/master/model_nltk.py</span></code></pre></div>",
    "fir_5.py": "<div class=\"codeBlock hljs python\" id=\"fir_5\"><pre id=\"fir_5_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">import</span> string\n\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> re\n\nMIN_YEAR = <span class=\"hljs-number\">1900</span>\nMAX_YEAR = <span class=\"hljs-number\">2100</span>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_url_patern</span>():</span>\n    <span class=\"hljs-keyword\">return</span> <div style=\"display: inline;\" id=\"regular_expression_0\" class=\"highlights fea_regular_expression\">re.<span class=\"hljs-built_in\">compile</span>(\n        <span class=\"hljs-string\">r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))'</span>\n        <span class=\"hljs-string\">r'[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})'</span>)</div>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_emojis_pattern</span>():</span>\n    <span class=\"hljs-keyword\">try</span>:\n        <span class=\"hljs-comment\"># UCS-4</span>\n        <div style=\"display: inline;\" id=\"regular_expression_1\" class=\"highlights fea_regular_expression\">emojis_pattern = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])'</span>)</div>\n    <span class=\"hljs-keyword\">except</span> re.error:\n        <span class=\"hljs-comment\"># UCS-2</span>\n        <div style=\"display: inline;\" id=\"regular_expression_2\" class=\"highlights fea_regular_expression\">emojis_pattern = re.<span class=\"hljs-built_in\">compile</span>(\n            <span class=\"hljs-string\">u'([\\u2600-\\u27BF])|([\\uD83C][\\uDF00-\\uDFFF])|([\\uD83D][\\uDC00-\\uDE4F])|([\\uD83D][\\uDE80-\\uDEFF])'</span>)</div>\n    <span class=\"hljs-keyword\">return</span> emojis_pattern\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_hashtags_pattern</span>():</span>\n    <span class=\"hljs-keyword\">return</span> <div style=\"display: inline;\" id=\"regular_expression_3\" class=\"highlights fea_regular_expression\">re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r'#\\w*'</span>)</div>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_single_letter_words_pattern</span>():</span>\n    <span class=\"hljs-keyword\">return</span> <div style=\"display: inline;\" id=\"regular_expression_4\" class=\"highlights fea_regular_expression\">re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r'(?&lt;![\\w\\-])\\w(?![\\w\\-])'</span>)</div>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_blank_spaces_pattern</span>():</span>\n    <span class=\"hljs-keyword\">return</span> re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r'\\s{2,}|\\t'</span>)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_twitter_reserved_words_pattern</span>():</span>\n    <span class=\"hljs-keyword\">return</span> re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r'(RT|rt|FAV|fav|VIA|via)'</span>)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_mentions_pattern</span>():</span>\n    <span class=\"hljs-keyword\">return</span> re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r'@\\w*'</span>)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_negations_pattern</span>():</span>\n    negations_ = {<span class=\"hljs-string\">\"isn't\"</span>: <span class=\"hljs-string\">\"is not\"</span>, <span class=\"hljs-string\">\"can't\"</span>: <span class=\"hljs-string\">\"can not\"</span>, <span class=\"hljs-string\">\"couldn't\"</span>: <span class=\"hljs-string\">\"could not\"</span>, <span class=\"hljs-string\">\"hasn't\"</span>: <span class=\"hljs-string\">\"has not\"</span>,\n                  <span class=\"hljs-string\">\"hadn't\"</span>: <span class=\"hljs-string\">\"had not\"</span>, <span class=\"hljs-string\">\"won't\"</span>: <span class=\"hljs-string\">\"will not\"</span>,\n                  <span class=\"hljs-string\">\"wouldn't\"</span>: <span class=\"hljs-string\">\"would not\"</span>, <span class=\"hljs-string\">\"aren't\"</span>: <span class=\"hljs-string\">\"are not\"</span>,\n                  <span class=\"hljs-string\">\"haven't\"</span>: <span class=\"hljs-string\">\"have not\"</span>, <span class=\"hljs-string\">\"doesn't\"</span>: <span class=\"hljs-string\">\"does not\"</span>, <span class=\"hljs-string\">\"didn't\"</span>: <span class=\"hljs-string\">\"did not\"</span>,\n                  <span class=\"hljs-string\">\"don't\"</span>: <span class=\"hljs-string\">\"do not\"</span>, <span class=\"hljs-string\">\"shouldn't\"</span>: <span class=\"hljs-string\">\"should not\"</span>, <span class=\"hljs-string\">\"wasn't\"</span>: <span class=\"hljs-string\">\"was not\"</span>, <span class=\"hljs-string\">\"weren't\"</span>: <span class=\"hljs-string\">\"were not\"</span>,\n                  <span class=\"hljs-string\">\"mightn't\"</span>: <span class=\"hljs-string\">\"might not\"</span>,\n                  <span class=\"hljs-string\">\"mustn't\"</span>: <span class=\"hljs-string\">\"must not\"</span>}\n    <span class=\"hljs-keyword\">return</span> re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r'\\b('</span> + <span class=\"hljs-string\">'|'</span>.join(negations_.keys()) + <span class=\"hljs-string\">r')\\b'</span>)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">is_year</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">len</span>(text) == <span class=\"hljs-number\">3</span> <span class=\"hljs-keyword\">or</span> <span class=\"hljs-built_in\">len</span>(text) == <span class=\"hljs-number\">4</span>) <span class=\"hljs-keyword\">and</span> (MIN_YEAR &lt; <span class=\"hljs-built_in\">len</span>(text) &lt; MAX_YEAR):\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">True</span>\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span>\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">TwitterPreprocessor</span>:</span>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, text: <span class=\"hljs-built_in\">str</span></span>):</span>\n        self.text = text\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">fully_preprocess</span>(<span class=\"hljs-params\">self</span>):</span>\n        <span class=\"hljs-keyword\">return</span> self \\\n            .remove_urls() \\\n            .remove_mentions() \\\n            .remove_hashtags() \\\n            .remove_twitter_reserved_words() \\\n            .remove_punctuation() \\\n            .remove_single_letter_words() \\\n            .remove_blank_spaces() \\\n            .remove_stopwords() \\\n            .remove_numbers()\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_urls</span>(<span class=\"hljs-params\">self</span>):</span>\n        <div style=\"display: inline;\" id=\"regular_expression_5\" class=\"highlights fea_regular_expression\">self.text = re.sub(pattern=get_url_patern(), repl=<span class=\"hljs-string\">''</span>, string=self.text)</div>\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_punctuation</span>(<span class=\"hljs-params\">self</span>):</span>\n        self.text = self.text.translate(<span class=\"hljs-built_in\">str</span>.maketrans(<span class=\"hljs-string\">''</span>, <span class=\"hljs-string\">''</span>, string.punctuation))\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_mentions</span>(<span class=\"hljs-params\">self</span>):</span>\n        self.text = re.sub(pattern=get_mentions_pattern(), repl=<span class=\"hljs-string\">''</span>, string=self.text)\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_hashtags</span>(<span class=\"hljs-params\">self</span>):</span>\n        self.text = re.sub(pattern=get_hashtags_pattern(), repl=<span class=\"hljs-string\">''</span>, string=self.text)\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_twitter_reserved_words</span>(<span class=\"hljs-params\">self</span>):</span>\n        self.text = re.sub(pattern=get_twitter_reserved_words_pattern(), repl=<span class=\"hljs-string\">''</span>, string=self.text)\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_single_letter_words</span>(<span class=\"hljs-params\">self</span>):</span>\n        self.text = re.sub(pattern=get_single_letter_words_pattern(), repl=<span class=\"hljs-string\">''</span>, string=self.text)\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_blank_spaces</span>(<span class=\"hljs-params\">self</span>):</span>\n        self.text = re.sub(pattern=get_blank_spaces_pattern(), repl=<span class=\"hljs-string\">' '</span>, string=self.text)\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_stopwords</span>(<span class=\"hljs-params\">self, extra_stopwords=<span class=\"hljs-literal\">None</span></span>):</span>\n        <span class=\"hljs-keyword\">if</span> extra_stopwords <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n            extra_stopwords = []\n        text = nltk.word_tokenize(self.text)\n        <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stop_words = <span class=\"hljs-built_in\">set</span>(stopwords.words(<span class=\"hljs-string\">'english'</span>))</div>\n\n        new_sentence = []\n        <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> text:\n            <span class=\"hljs-keyword\">if</span> w <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> stop_words <span class=\"hljs-keyword\">and</span> w <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> extra_stopwords:\n                new_sentence.append(w)\n        self.text = <span class=\"hljs-string\">' '</span>.join(new_sentence)\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">remove_numbers</span>(<span class=\"hljs-params\">self, preserve_years=<span class=\"hljs-literal\">False</span></span>):</span>\n        text_list = self.text.split(<span class=\"hljs-string\">' '</span>)\n        <span class=\"hljs-keyword\">for</span> text <span class=\"hljs-keyword\">in</span> text_list:\n            <span class=\"hljs-keyword\">if</span> text.isnumeric():\n                <span class=\"hljs-keyword\">if</span> preserve_years:\n                    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> is_year(text):\n                        text_list.remove(text)\n                <span class=\"hljs-keyword\">else</span>:\n                    text_list.remove(text)\n\n        self.text = <span class=\"hljs-string\">' '</span>.join(text_list)\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">lowercase</span>(<span class=\"hljs-params\">self</span>):</span>\n        self.text = self.text.lower()\n        <span class=\"hljs-keyword\">return</span> self\n    \n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">handle_negations</span>(<span class=\"hljs-params\">self</span>):</span>  \n        self.text = re.sub(pattern=get_negations_pattern(), repl=<span class=\"hljs-string\">''</span>, string=self.text)\n        <span class=\"hljs-keyword\">return</span> self\n        <span class=\"hljs-comment\">#https://github.com/vasisouv/tweets-preprocessor/blob/master/twitter_preprocessor.py</span></code></pre></div>",
    "fir_7.py": "<div class=\"codeBlock hljs python\" id=\"fir_7\"><pre id=\"fir_7_code\" ><code class=\"javascript\"><span class=\"hljs-comment\">#! /usr/bin/env python2</span>\n\n<span class=\"hljs-string\">\"\"\"\nFilename: characterExtraction.py\nAuthor: Emily Daniels\nDate: April 2014\nPurpose: Extracts character names from a text file and performs analysis of\ntext sentences containing the names.\n\"\"\"</span>\n\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">import</span> re\n\n<span class=\"hljs-keyword\">from</span> collections <span class=\"hljs-keyword\">import</span> defaultdict\n<span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> stopwords\n<span class=\"hljs-keyword\">from</span> pattern.en <span class=\"hljs-keyword\">import</span> parse, Sentence, mood\n<span class=\"hljs-keyword\">from</span> pattern.db <span class=\"hljs-keyword\">import</span> csv\n<span class=\"hljs-keyword\">from</span> pattern.vector <span class=\"hljs-keyword\">import</span> Document, NB\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">readText</span>():</span>\n    <span class=\"hljs-string\">\"\"\"\n    Reads the text from a text file.\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"730.txt\"</span>, <span class=\"hljs-string\">\"rb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n        text = f.read().decode(<span class=\"hljs-string\">'utf-8-sig'</span>)\n    <span class=\"hljs-keyword\">return</span> text\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">chunkSentences</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Parses text into parts of speech tagged with parts of speech labels.\n\n    Used for reference: https://gist.github.com/onyxfish/322906\n    \"\"\"</span>\n    sentences = nltk.sent_tokenize(text)\n    tokenizedSentences = [nltk.word_tokenize(sentence)\n                          <span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sentences]\n    taggedSentences = [nltk.pos_tag(sentence)\n                       <span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> tokenizedSentences]\n    <span class=\"hljs-keyword\">if</span> nltk.__version__[<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">2</span>] == <span class=\"hljs-string\">\"2.\"</span>:\n        chunkedSentences = nltk.batch_ne_chunk(taggedSentences, binary=<span class=\"hljs-literal\">True</span>)\n    <span class=\"hljs-keyword\">else</span>:\n        chunkedSentences = nltk.ne_chunk_sents(taggedSentences, binary=<span class=\"hljs-literal\">True</span>)\n    <span class=\"hljs-keyword\">return</span> chunkedSentences\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">extractEntityNames</span>(<span class=\"hljs-params\">tree, _entityNames=<span class=\"hljs-literal\">None</span></span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Creates a local list to hold nodes of tree passed through, extracting named\n    entities from the chunked sentences.\n\n    Used for reference: https://gist.github.com/onyxfish/322906\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">if</span> _entityNames <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n        _entityNames = []\n    <span class=\"hljs-keyword\">try</span>:\n        <span class=\"hljs-keyword\">if</span> nltk.__version__[<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">2</span>] == <span class=\"hljs-string\">\"2.\"</span>:\n            label = tree.node\n        <span class=\"hljs-keyword\">else</span>:\n            label = tree.label()\n    <span class=\"hljs-keyword\">except</span> AttributeError:\n        <span class=\"hljs-keyword\">pass</span>\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">if</span> label == <span class=\"hljs-string\">'NE'</span>:\n            _entityNames.append(<span class=\"hljs-string\">' '</span>.join([child[<span class=\"hljs-number\">0</span>] <span class=\"hljs-keyword\">for</span> child <span class=\"hljs-keyword\">in</span> tree]))\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-keyword\">for</span> child <span class=\"hljs-keyword\">in</span> tree:\n                extractEntityNames(child, _entityNames=_entityNames)\n    <span class=\"hljs-keyword\">return</span> _entityNames\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">buildDict</span>(<span class=\"hljs-params\">chunkedSentences, _entityNames=<span class=\"hljs-literal\">None</span></span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Uses the global entity list, creating a new dictionary with the properties\n    extended by the local list, without overwriting.\n\n    Used for reference: https://gist.github.com/onyxfish/322906\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">if</span> _entityNames <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n        _entityNames = []\n\n    <span class=\"hljs-keyword\">for</span> tree <span class=\"hljs-keyword\">in</span> chunkedSentences:\n        extractEntityNames(tree, _entityNames=_entityNames)\n\n    <span class=\"hljs-keyword\">return</span> _entityNames\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">removeStopwords</span>(<span class=\"hljs-params\">entityNames, customStopWords=<span class=\"hljs-literal\">None</span></span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Brings in stopwords and custom stopwords to filter mismatches out.\n    \"\"\"</span>\n    <span class=\"hljs-comment\"># Memoize custom stop words</span>\n    <span class=\"hljs-keyword\">if</span> customStopWords <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"customStopWords.txt\"</span>, <span class=\"hljs-string\">\"rb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n            customStopwords = f.read().split(<span class=\"hljs-string\">', '</span>)\n\n    <span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> entityNames:\n        <span class=\"hljs-keyword\">if</span> name <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stopwords.words(<span class=\"hljs-string\">'english'</span>)</div> <span class=\"hljs-keyword\">or</span> name <span class=\"hljs-keyword\">in</span> customStopwords:\n            entityNames.remove(name)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">getMajorCharacters</span>(<span class=\"hljs-params\">entityNames</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Adds names to the major character list if they appear frequently.\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">return</span> {name <span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> entityNames <span class=\"hljs-keyword\">if</span> entityNames.count(name) &gt; <span class=\"hljs-number\">10</span>}\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">splitIntoSentences</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Split sentences on .?! \"\" and not on abbreviations of titles.\n    Used for reference: http://stackoverflow.com/a/8466725\n    \"\"\"</span>\n    sentenceEnders = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r\"\"\"\n    # Split sentences on whitespace between them.\n    (?:               # Group for two positive lookbehinds.\n      (?&lt;=[.!?])      # Either an end of sentence punct,\n    | (?&lt;=[.!?]['\"])  # or end of sentence punct and quote.\n    )                 # End group of two positive lookbehinds.\n    (?&lt;!  Mr\\.   )    # Don't end sentence on \"Mr.\"\n    (?&lt;!  Mrs\\.  )    # Don't end sentence on \"Mrs.\"\n    (?&lt;!  Ms\\.   )    # Don't end sentence on \"Ms.\"\n    (?&lt;!  Jr\\.   )    # Don't end sentence on \"Jr.\"\n    (?&lt;!  Dr\\.   )    # Don't end sentence on \"Dr.\"\n    (?&lt;!  Prof\\. )    # Don't end sentence on \"Prof.\"\n    (?&lt;!  Sr\\.   )    # Don't end sentence on \"Sr.\"\n    \\s+               # Split on whitespace between sentences.\n    \"\"\"</span>, re.IGNORECASE | re.VERBOSE)\n    <span class=\"hljs-keyword\">return</span> sentenceEnders.split(text)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">compareLists</span>(<span class=\"hljs-params\">sentenceList, majorCharacters</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Compares the list of sentences with the character names and returns\n    sentences that include names.\n    \"\"\"</span>\n    characterSentences = defaultdict(<span class=\"hljs-built_in\">list</span>)\n    <span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sentenceList:\n        <span class=\"hljs-keyword\">for</span> name <span class=\"hljs-keyword\">in</span> majorCharacters:\n            <span class=\"hljs-keyword\">if</span> re.search(<span class=\"hljs-string\">r\"\\b(?=\\w)%s\\b(?!\\w)\"</span> % re.escape(name),\n                         sentence,\n                         re.IGNORECASE):\n                characterSentences[name].append(sentence)\n    <span class=\"hljs-keyword\">return</span> characterSentences\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">extractMood</span>(<span class=\"hljs-params\">characterSentences</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Analyzes the sentence using grammatical mood module from pattern.\n    \"\"\"</span>\n    characterMoods = defaultdict(<span class=\"hljs-built_in\">list</span>)\n    <span class=\"hljs-keyword\">for</span> key, value <span class=\"hljs-keyword\">in</span> characterSentences.iteritems():\n        <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> value:\n            characterMoods[key].append(mood(Sentence(parse(<span class=\"hljs-built_in\">str</span>(x),\n                                                           lemmata=<span class=\"hljs-literal\">True</span>))))\n    <span class=\"hljs-keyword\">return</span> characterMoods\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">extractSentiment</span>(<span class=\"hljs-params\">characterSentences</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Trains a Naive Bayes classifier object with the reviews.csv file, analyzes\n    the sentence, and returns the tone.\n    \"\"\"</span>\n    nb = NB()\n    characterTones = defaultdict(<span class=\"hljs-built_in\">list</span>)\n    <span class=\"hljs-keyword\">for</span> review, rating <span class=\"hljs-keyword\">in</span> csv(<span class=\"hljs-string\">\"reviews.csv\"</span>):\n        nb.train(Document(review, <span class=\"hljs-built_in\">type</span>=<span class=\"hljs-built_in\">int</span>(rating), stopwords=<span class=\"hljs-literal\">True</span>))\n    <span class=\"hljs-keyword\">for</span> key, value <span class=\"hljs-keyword\">in</span> characterSentences.iteritems():\n        <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> value:\n            characterTones[key].append(nb.classify(<span class=\"hljs-built_in\">str</span>(x)))\n    <span class=\"hljs-keyword\">return</span> characterTones\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">writeAnalysis</span>(<span class=\"hljs-params\">sentenceAnalysis</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Writes the sentence analysis to a text file in the same directory.\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"sentenceAnalysis.txt\"</span>, <span class=\"hljs-string\">\"wb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n        <span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> sentenceAnalysis.items():\n            f.write(<span class=\"hljs-string\">\"%s:%s\\n\"</span> % item)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">writeToJSON</span>(<span class=\"hljs-params\">sentenceAnalysis</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Writes the sentence analysis to a JSON file in the same directory.\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"sentenceAnalysis.json\"</span>, <span class=\"hljs-string\">\"wb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n        json.dump(sentenceAnalysis, f)\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    text = readText()\n\n    chunkedSentences = chunkSentences(text)\n    entityNames = buildDict(chunkedSentences)\n    removeStopwords(entityNames)\n    majorCharacters = getMajorCharacters(entityNames)\n    \n    sentenceList = splitIntoSentences(text)\n    characterSentences = compareLists(sentenceList, majorCharacters)\n    characterMoods = extractMood(characterSentences)\n    characterTones = extractSentiment(characterSentences)\n\n    <span class=\"hljs-comment\"># Merges sentences, moods and tones together into one dictionary on each</span>\n    <span class=\"hljs-comment\"># character.</span>\n    sentenceAnalysis = defaultdict(<span class=\"hljs-built_in\">list</span>,\n                                   [(k, [characterSentences[k],\n                                         characterTones[k],\n                                         characterMoods[k]])\n                                    <span class=\"hljs-keyword\">for</span> k <span class=\"hljs-keyword\">in</span> characterSentences])\n    \n    writeAnalysis(sentenceAnalysis)\n    writeToJSON(sentenceAnalysis)\n    <span class=\"hljs-comment\">#https://github.com/emdaniels/character-extraction/blob/master/characterExtraction.py</span></code></pre></div>",
    "fir_28.py": "<div class=\"codeBlock hljs python\" id=\"fir_28\"><pre id=\"fir_28_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> subjectivity\n<span class=\"hljs-keyword\">from</span> nltk.classify <span class=\"hljs-keyword\">import</span> NaiveBayesClassifier\n<span class=\"hljs-keyword\">from</span> nltk.sentiment <span class=\"hljs-keyword\">import</span> SentimentAnalyzer <span class=\"hljs-comment\"># SentimentAnalyzer is a tool to implement and facilitate Sentiment Analysis.</span>\n<span class=\"hljs-keyword\">from</span> nltk.sentiment.util <span class=\"hljs-keyword\">import</span> (mark_negation, extract_unigram_feats) <span class=\"hljs-comment\"># mark_negation(): Append _NEG suffix to words that appear in the scope between a negation and a punctuation mark. extract_unigram_feats(): Populate a dictionary of unigram features, reflecting the presence/absence in the document of each of the tokens in unigrams.</span>\n\nn_instances = <span class=\"hljs-number\">100</span>\nobj_docs = [(sent, <span class=\"hljs-string\">'obj'</span>) <span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">subjectivity.sents(categories=<span class=\"hljs-string\">'obj'</span>)[:n_instances]]</div>\nsubj_docs = [(sent, <span class=\"hljs-string\">'subj'</span>) <span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> subjectivity.sents(categories=<span class=\"hljs-string\">'subj'</span>)[:n_instances]]\ntrain_obj_docs = obj_docs[:<span class=\"hljs-number\">80</span>]\ntest_obj_docs = obj_docs[<span class=\"hljs-number\">80</span>:<span class=\"hljs-number\">100</span>]\ntrain_subj_docs = subj_docs[:<span class=\"hljs-number\">80</span>]\ntest_subj_docs = subj_docs[<span class=\"hljs-number\">80</span>:<span class=\"hljs-number\">100</span>]\n\ntraining_docs = train_obj_docs + train_subj_docs\ntesting_docs = test_obj_docs + test_subj_docs\n\n<div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\">sentim_analyzer = SentimentAnalyzer()</div>\nall_words_neg = sentim_analyzer.all_words([mark_negation(doc) <span class=\"hljs-keyword\">for</span> doc <span class=\"hljs-keyword\">in</span> training_docs])\n\nunigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=<span class=\"hljs-number\">4</span>)\n\nsentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)\n\ntraining_set = sentim_analyzer.apply_features(training_docs)\ntest_set = sentim_analyzer.apply_features(testing_docs)\n\n<div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">trainer = NaiveBayesClassifier.train\nclassifier = sentim_analyzer.train(trainer, training_set)</div>\n\n<span class=\"hljs-keyword\">for</span> key,value <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">sorted</span>(sentim_analyzer.evaluate(test_set).items()):\n    print(<span class=\"hljs-string\">'{0}: {1}'</span>.<span class=\"hljs-built_in\">format</span>(key, value))\n\n<span class=\"hljs-keyword\">from</span> nltk.sentiment.vader <span class=\"hljs-keyword\">import</span> SentimentIntensityAnalyzer\n\nsentences = [\n    <span class=\"hljs-string\">\"You are a piece of shit, and I will step on you.\"</span>,\n    <span class=\"hljs-string\">\"THIS SUX!!!\"</span>,\n    <span class=\"hljs-string\">\"This kinda sux...\"</span>,\n    <span class=\"hljs-string\">\"You're good, man\"</span>,\n    <span class=\"hljs-string\">\"HAHAHA YOU ARE THE BEST!!!!! VERY FUNNY!!!\"</span>\n            ]\n\n\n<div style=\"display: inline;\" id=\"sentiment_analysis_1\" class=\"highlights fea_sentiment_analysis\">sid = SentimentIntensityAnalyzer()</div>\n\n<span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sentences:\n    print(<span class=\"hljs-string\">'\\n'</span> + sentence)\n    ss = sid.polarity_scores(sentence)\n    <span class=\"hljs-keyword\">for</span> k <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">sorted</span>(ss):\n        print(<span class=\"hljs-string\">'{0}: {1}, '</span>.<span class=\"hljs-built_in\">format</span>(k, ss[k]), end=<span class=\"hljs-string\">''</span>)</code></pre></div>",
    "fir_22.py": "<div class=\"codeBlock hljs python\" id=\"fir_22\"><pre id=\"fir_22_code\" ><code class=\"javascript\">\n<span class=\"hljs-comment\"># coding=utf-8</span>\n<span class=\"hljs-keyword\">import</span> utils\n<span class=\"hljs-keyword\">import</span> nltk\n\ndata = utils.getTrainData()\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_words_in_tweets</span>(<span class=\"hljs-params\">tweets</span>):</span>\n    all_words = []\n    <span class=\"hljs-keyword\">for</span> (words, sentiment) <span class=\"hljs-keyword\">in</span> tweets:\n      all_words.extend(words)\n    <span class=\"hljs-keyword\">return</span> all_words\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_word_features</span>(<span class=\"hljs-params\">wordlist</span>):</span>\n    <div style=\"display: inline;\" id=\"word_frequency_0\" class=\"highlights fea_word_frequency\">wordlist = nltk.FreqDist(wordlist)</div>\n    word_features = wordlist.keys()\n    <span class=\"hljs-keyword\">return</span> word_features\n\nword_features = get_word_features(get_words_in_tweets(data))\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">extract_features</span>(<span class=\"hljs-params\">document</span>):</span>\n    document_words = <span class=\"hljs-built_in\">set</span>(document)\n    features = {}\n    <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> word_features:\n        features[word.decode(<span class=\"hljs-string\">\"utf8\"</span>)] = (word <span class=\"hljs-keyword\">in</span> document_words)\n    <span class=\"hljs-keyword\">return</span> features\n\nallsetlength = <span class=\"hljs-built_in\">len</span>(data)\n<div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">training_set = nltk.classify.apply_features(extract_features, data[:allsetlength/<span class=\"hljs-number\">10</span>*<span class=\"hljs-number\">8</span>])</div>\ntest_set = data[allsetlength/<span class=\"hljs-number\">10</span>*<span class=\"hljs-number\">8</span>:]\n<div style=\"display: inline;\" id=\"classification_1\" class=\"highlights fea_classification\">classifier = nltk.NaiveBayesClassifier.train(training_set)</div>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">classify</span>(<span class=\"hljs-params\">tweet</span>):</span>\n\t<span class=\"hljs-built_in\">print</span> classifier.classify(extract_features(tweet.split()))\n\nclassify(<span class=\"hljs-string\">\"Bugn ok gzel bir gn\"</span>)\n<span class=\"hljs-comment\">#https://github.com/mertkahyaoglu/twitter-sentiment-analysis/blob/master/classify.py</span></code></pre></div>",
    "fir_27.py": "<div class=\"codeBlock hljs python\" id=\"fir_27\"><pre id=\"fir_27_code\" ><code class=\"javascript\"><span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> brown\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> FreqDist\n\n<div style=\"display: inline;\" id=\"word_frequency_0\" class=\"highlights fea_word_frequency\">suffix_fdist = FreqDist()</div>\n<span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> brown.words():\n    word = word.lower()\n    suffix_fdist[word[-<span class=\"hljs-number\">1</span>:]] += <span class=\"hljs-number\">1</span>\n    suffix_fdist[word[-<span class=\"hljs-number\">2</span>:]] += <span class=\"hljs-number\">1</span>\n    suffix_fdist[word[-<span class=\"hljs-number\">3</span>:]] += <span class=\"hljs-number\">1</span>\ncommon_suffixes = [suffix <span class=\"hljs-keyword\">for</span> (suffix, count) <span class=\"hljs-keyword\">in</span> suffix_fdist.most_common(<span class=\"hljs-number\">100</span>)]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">pos_features</span>(<span class=\"hljs-params\">word</span>):</span>\n    features = {}\n    <span class=\"hljs-keyword\">for</span> suffix <span class=\"hljs-keyword\">in</span> common_suffixes:\n        features[<span class=\"hljs-string\">'endswith({})'</span>.<span class=\"hljs-built_in\">format</span>(suffix)] = word.lower().endswith(suffix)\n    <span class=\"hljs-keyword\">return</span> features\n\n<div style=\"display: inline;\" id=\"tagger_0\" class=\"highlights fea_tagger\">tagged_words = brown.tagged_words(categories=<span class=\"hljs-string\">'news'</span>)</div>\nfeaturesets = [(pos_features(n), g) <span class=\"hljs-keyword\">for</span> (n,g) <span class=\"hljs-keyword\">in</span> tagged_words]\n\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> DecisionTreeClassifier\n<span class=\"hljs-keyword\">from</span> nltk.classify <span class=\"hljs-keyword\">import</span> accuracy\n\ncutoff = <span class=\"hljs-built_in\">int</span>(<span class=\"hljs-built_in\">len</span>(featuresets) * <span class=\"hljs-number\">0.1</span>)\ntrain_set, test_set = featuresets[cutoff:], featuresets[:cutoff]\n\n<div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">classifier = DecisionTreeClassifier.train(train_set)</div> <span class=\"hljs-comment\"># NLTK is a teaching toolkit which is not really optimized for speed. Therefore, this may take forever. For speed, use scikit-learn for the classifiers.</span>\n\naccuracy(classifier, test_set)\n\nclassifier.classify(pos_features(<span class=\"hljs-string\">'cats'</span>))\n\nclassifier.pseudocode(depth=<span class=\"hljs-number\">4</span>)</code></pre></div>",
    "fir_26.py": "<div class=\"codeBlock hljs python\" id=\"fir_26\"><pre id=\"fir_26_code\" ><code class=\"javascript\">s = <span class=\"hljs-string\">\"Le temps est un grand matre, dit-on, le malheur est qu'il tue ses lves.\"</span>\ns = s.lower()\n<span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> RegexpTokenizer\ntokenizer = RegexpTokenizer(<span class=\"hljs-string\">\"[a-zA-Z'`]+\"</span>)\ns_tokenized = tokenizer.tokenize(s)\n\n<span class=\"hljs-keyword\">from</span> nltk.util <span class=\"hljs-keyword\">import</span> ngrams\ngenerated_4grams = []\n\n<span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> s_tokenized:\n    generated_4grams.append(<span class=\"hljs-built_in\">list</span>(<div style=\"display: inline;\" id=\"n_grams_0\" class=\"highlights fea_n_grams\">ngrams(word, <span class=\"hljs-number\">4</span>, pad_left=<span class=\"hljs-literal\">True</span>, pad_right=<span class=\"hljs-literal\">True</span>, left_pad_symbol=<span class=\"hljs-string\">'_'</span>, right_pad_symbol=<span class=\"hljs-string\">'_'</span>)</div>)) <span class=\"hljs-comment\"># n = 4.</span>\n\ngenerated_4grams = [word <span class=\"hljs-keyword\">for</span> sublist <span class=\"hljs-keyword\">in</span> generated_4grams <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> sublist]\n\nng_list_4grams = generated_4grams\n<span class=\"hljs-keyword\">for</span> idx, val <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(generated_4grams):\n    ng_list_4grams[idx] = <span class=\"hljs-string\">''</span>.join(val)\n\nfreq_4grams = {}\n\n<span class=\"hljs-keyword\">for</span> ngram <span class=\"hljs-keyword\">in</span> ng_list_4grams:\n    <span class=\"hljs-keyword\">if</span> ngram <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> freq_4grams:\n        freq_4grams.update({ngram: <span class=\"hljs-number\">1</span>})\n    <span class=\"hljs-keyword\">else</span>:\n        ngram_occurrences = freq_4grams[ngram]\n        freq_4grams.update({ngram: ngram_occurrences + <span class=\"hljs-number\">1</span>})\n        \n<span class=\"hljs-keyword\">from</span> operator <span class=\"hljs-keyword\">import</span> itemgetter <span class=\"hljs-comment\"># The operator module exports a set of efficient functions corresponding to the intrinsic operators of Python. For example, operator.add(x, y) is equivalent to the expression x + y.</span>\n\nfreq_4grams_sorted = <span class=\"hljs-built_in\">sorted</span>(freq_4grams.items(), key=itemgetter(<span class=\"hljs-number\">1</span>), reverse=<span class=\"hljs-literal\">True</span>)[<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">300</span>] <span class=\"hljs-comment\"># We only keep the 300 most popular n-grams. This was suggested in the original paper written about n-grams.</span>\n\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> everygrams\n\ns_clean = <span class=\"hljs-string\">' '</span>.join(s_tokenized) <span class=\"hljs-comment\"># For the code below we need the raw sentence as opposed to the tokens.</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">ngram_extractor</span>(<span class=\"hljs-params\">sent</span>):</span>\n    <span class=\"hljs-keyword\">return</span> [<span class=\"hljs-string\">''</span>.join(ng) <span class=\"hljs-keyword\">for</span> ng <span class=\"hljs-keyword\">in</span> everygrams(sent.replace(<span class=\"hljs-string\">' '</span>, <span class=\"hljs-string\">'_ _'</span>), <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">4</span>) \n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">' '</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> ng <span class=\"hljs-keyword\">and</span> <span class=\"hljs-string\">'\\n'</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> ng <span class=\"hljs-keyword\">and</span> ng != (<span class=\"hljs-string\">'_'</span>,)]\n\nngram_extractor(s_clean)</code></pre></div>",
    "fir_15.py": "<div class=\"codeBlock hljs python\" id=\"fir_15\"><pre id=\"fir_15_code\" ><code class=\"javascript\"><span class=\"hljs-comment\"># -*- coding: utf-8 -*-</span>\n<span class=\"hljs-comment\"># Maximum Entropy Part-of-Speech Tagger for NLTK (Natural Language Toolkit)</span>\n<span class=\"hljs-comment\"># Author: Arne Neumann</span>\n<span class=\"hljs-comment\"># Licence: GPL 3</span>\n\n<span class=\"hljs-comment\">#__docformat__ = 'epytext en'</span>\n\n<span class=\"hljs-string\">\"\"\"\nA I{part-of-speech tagger} that uses NLTK's build-in L{Maximum Entropy\nmodels&lt;nltk.MaxentClassifier&gt;} to find the most likely I{part-of-speech\ntag} (POS) for each word in a given sequence.\n\nThe tagger will be trained on a corpus of tagged sentences. For every word\nin the corpus, a C{tuple} consisting of a C{dictionary} of features from\nthe word's context (e.g. preceding/succeeding words and tags, word\nprefixes/suffixes etc.) and the word's tag will be generated.\nThe maximum entropy classifier will learn a model from these tuples that\nwill be used by the tagger to find the most likely POS-tag for any given\nword, even unseen ones.\n\nThe tagger and the featuresets chosen for training are implemented as described\nin Ratnaparkhi, Adwait (1996). A Maximum Entropy Model for Part-Of-Speech\nTagging. In Proceedings of the ARPA Human Language Technology Workshop. Pages\n250-255.\n\nUsage notes:\n============\n\nPlease install the MEGAM package (http://hal3.name/megam),\notherwise training will take forever.\n\nTo use the demo, please install either 'brown' or 'treebank' with::\n\n    import nltk\n    nltk.download()\n\nin the Python interpreter. Proper usage of demo() and all other functions and\nmethods is described below.\n\"\"\"</span>\n\n<span class=\"hljs-keyword\">import</span> time\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">from</span> collections <span class=\"hljs-keyword\">import</span> defaultdict\n\n<span class=\"hljs-keyword\">from</span> nltk <span class=\"hljs-keyword\">import</span> TaggerI, FreqDist, untag, config_megam\n<span class=\"hljs-keyword\">from</span> nltk.classify.maxent <span class=\"hljs-keyword\">import</span> MaxentClassifier\n                  \n\nPATH_TO_MEGAM_EXECUTABLE = <span class=\"hljs-string\">\"/usr/bin/megam\"</span>\nconfig_megam(PATH_TO_MEGAM_EXECUTABLE)\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MaxentPosTagger</span>(<span class=\"hljs-params\">TaggerI</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    MaxentPosTagger is a part-of-speech tagger based on Maximum Entropy models.\n    \"\"\"</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">train</span>(<span class=\"hljs-params\">self, train_sents, algorithm=<span class=\"hljs-string\">'megam'</span>, rare_word_cutoff=<span class=\"hljs-number\">5</span>,\n              rare_feat_cutoff=<span class=\"hljs-number\">5</span>, uppercase_letters=<span class=\"hljs-string\">'[A-Z]'</span>, trace=<span class=\"hljs-number\">3</span>,\n              **cutoffs</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        MaxentPosTagger trains a Maximum Entropy model from a C{list} of tagged\n        sentences.\n\n        @type train_sents: C{list} of C{list} of tuples of (C{str}, C{str})\n        @param train_sents: A list of tagged sentences. Each sentence is\n        represented by a list of tuples. Each tuple holds two strings, a\n        word and its tag, e.g. ('company','NN').\n\n        @type algorithm: C{str}\n        @param algorithm: The algorithm that is used by\n        L{nltk.MaxentClassifier.train()} to train and optimise the model. It is\n        B{strongly recommended} to use the C{LM-BFGS} algorithm provided by the\n        external package U{megam&lt;http://hal3.name/megam/&gt;} as it is much faster\n        and uses less memory than any of the algorithms provided by NLTK (i.e.\n        C{GIS}, C{IIS}) or L{scipy} (e.g. C{CG} and C{BFGS}).\n\n        @type rare_word_cutoff: C{int}\n        @param rare_word_cutoff: Words with less occurrences than\n        C{rare_word_cutoff} will be treated differently by L{extract_feats}\n        than non-rare words (cf. Ratnaparkhi 1996).\n\n        @type rare_feat_cutoff: C{int}\n        @param rare_feat_cutoff: ignore features that occur less than\n        C{rare_feat_cutoff} during training.\n\n        @type uppercase_letters: C{regex}\n        @param uppercase_letters: a regular expression that covers all\n        uppercase letters of the language of your corpus (e.g. '[A-Z]' for\n        German)\n\n        @type trace: C{int}\n        @param trace: The level of diagnostic output to produce. C{0} doesn't\n        produce any output, while C{3} will give all the output that C{megam}\n        produces plus the time it took to train the model.\n\n        @param cutoffs: Arguments specifying various conditions under\n            which the training should be halted. When using C{MEGAM}, only\n            C{max_iter} should be relevant. For other cutoffs see\n            L{nltk.MaxentClassifier}\n\n              - C{max_iter=v}: Terminate after C{v} iterations.\n       \"\"\"</span>\n        self.uppercase_letters = uppercase_letters\n        self.word_freqdist = self.gen_word_freqs(train_sents)\n        self.featuresets = self.gen_featsets(train_sents,\n                rare_word_cutoff)\n        self.features_freqdist = self.gen_feat_freqs(self.featuresets)\n        self.cutoff_rare_feats(self.featuresets, rare_feat_cutoff)\n\n        t1 = time.time()\n        <div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">self.classifier = MaxentClassifier.train(self.featuresets, algorithm,\n                                                 trace, **cutoffs)</div>\n        t2 = time.time()\n        <span class=\"hljs-keyword\">if</span> trace &gt; <span class=\"hljs-number\">0</span>:\n            <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"time to train the classifier: {0}\"</span>.<span class=\"hljs-built_in\">format</span>(<span class=\"hljs-built_in\">round</span>(t2-t1, <span class=\"hljs-number\">3</span>))\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">gen_feat_freqs</span>(<span class=\"hljs-params\">self, featuresets</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Generates a frequency distribution of joint features (feature, tag)\n        tuples. The frequency distribution will be used by the tagger to\n        determine which (rare) features should not be considered during\n        training (feature cutoff).\n\n        This is how joint features look like::\n            (('t-2 t-1', 'IN DT'), 'NN')\n            (('w-2', '&lt;START&gt;'), 'NNP')\n            (('w+1', 'of'), 'NN')\n\n        @type featuresets: {list} of C{tuples} of (C{dict}, C{str})\n        @param featuresets: a list of tuples that contain the featureset of a\n        word from the training set and its POS tag.\n\n        @rtype: C{FreqDist}\n        @return: a L{frequency distribution&lt;nltk.FreqDist()&gt;},\n        counting how often each (context information feature, tag) tuple occurs\n        in the training sentences.\n        \"\"\"</span>\n        features_freqdist = defaultdict(<span class=\"hljs-built_in\">int</span>)\n        <span class=\"hljs-keyword\">for</span> (feat_dict, tag) <span class=\"hljs-keyword\">in</span> featuresets:\n            <span class=\"hljs-keyword\">for</span> (feature, value) <span class=\"hljs-keyword\">in</span> feat_dict.items():\n                features_freqdist[ ((feature, value), tag) ] += <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">return</span> features_freqdist\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">gen_word_freqs</span>(<span class=\"hljs-params\">self, train_sents</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Generates word frequencies from the training sentences for the feature\n        extractor.\n\n        @type train_sents: C{list} of C{list} of tuples of (C{str}, C{str})\n        @param train_sents: A list of tagged sentences.\n\n        @rtype: C{FreqDist}\n        @return: a L{frequency distribution&lt;nltk.FreqDist()&gt;},\n        counting how often each word occurs in the training sentences.\n        \"\"\"</span>\n        word_freqdist = FreqDist()\n        <span class=\"hljs-keyword\">for</span> tagged_sent <span class=\"hljs-keyword\">in</span> train_sents:\n            <span class=\"hljs-keyword\">for</span> (word, _tag) <span class=\"hljs-keyword\">in</span> tagged_sent:\n                word_freqdist[word] += <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">return</span> word_freqdist\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">gen_featsets</span>(<span class=\"hljs-params\">self, train_sents, rare_word_cutoff</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Generates featuresets for each token in the training sentences.\n\n        @type train_sents: C{list} of C{list} of tuples of (C{str}, C{str})\n        @param train_sents: A list of tagged sentences.\n\n        @type rare_word_cutoff: C{int}\n        @param rare_word_cutoff: Words with less occurrences than\n        C{rare_word_cutoff} will be treated differently by L{extract_feats}\n        than non-rare words (cf. Ratnaparkhi 1996).\n\n        @rtype: {list} of C{tuples} of (C{dict}, C{str})\n        @return:  a list of tuples that contains the featureset of\n        a token and its POS-tag.\n        \"\"\"</span>\n        featuresets = []\n        <span class=\"hljs-keyword\">for</span> tagged_sent <span class=\"hljs-keyword\">in</span> train_sents:\n            history = []\n            untagged_sent = untag(tagged_sent)\n            <span class=\"hljs-keyword\">for</span> (i, (_word, tag)) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(tagged_sent):\n                featuresets.append( (self.extract_feats(untagged_sent, i,\n                    history, rare_word_cutoff), tag) )\n                history.append(tag)\n        <span class=\"hljs-keyword\">return</span> featuresets\n\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">cutoff_rare_feats</span>(<span class=\"hljs-params\">self, featuresets, rare_feat_cutoff</span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Cuts off rare features to reduce training time and prevent overfitting.\n\n        Example\n        =======\n\n            Let's say, the suffixes of this featureset are too rare to learn.\n\n            &gt;&gt;&gt; featuresets[46712]\n            ({'suffix(1)': 't',\n            'prefix(1)': 'L',\n            'prefix(2)': 'Le',\n            'prefix(3)': 'Lem',\n            'suffix(3)': 'ont',\n            'suffix(2)': 'nt',\n            'contains-uppercase': True,\n            'prefix(4)': 'Lemo',\n            'suffix(4)': 'mont'},\n            'NNP')\n\n            C{cutoff_rare_feats} would then remove the rare joint features::\n\n                (('suffix(1)', 't'), 'NNP')\n                (('suffix(3)', 'ont'), 'NNP')\n                ((suffix(2)': 'nt'), 'NNP')\n                (('suffix(4)', 'mont'), 'NNP')\n\n            and return a featureset that only contains non-rare features:\n\n            &gt;&gt;&gt; featuresets[46712]\n            ({'prefix(1)': 'L',\n            'prefix(2)': 'Le',\n            'prefix(3)': 'Lem',\n            'contains-uppercase': True,\n            'prefix(4)': 'Lemo'},\n            'NNP')\n\n\n        @type featuresets: {list} of C{tuples} of (C{dict}, C{str})\n        @param featuresets: a list of tuples that contain the featureset of a\n        word from the training set and its POS tag\n\n        @type rare_feat_cutoff: C{int}\n        @param rare_feat_cutoff: if a (context information feature, tag)\n        tuple occurs less than C{rare_feat_cutoff} times in the training\n        set, then its corresponding feature will be removed from the\n        C{featuresets} to be learned.\n        \"\"\"</span>\n        never_cutoff_features = <span class=\"hljs-built_in\">set</span>([<span class=\"hljs-string\">'w'</span>,<span class=\"hljs-string\">'t'</span>])\n\n        <span class=\"hljs-keyword\">for</span> (feat_dict, tag) <span class=\"hljs-keyword\">in</span> featuresets:\n            <span class=\"hljs-keyword\">for</span> (feature, value) <span class=\"hljs-keyword\">in</span> feat_dict.items():\n                feat_value_tag = ((feature, value), tag)\n                <span class=\"hljs-keyword\">if</span> self.features_freqdist[feat_value_tag] &lt; rare_feat_cutoff:\n                    <span class=\"hljs-keyword\">if</span> feature <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> never_cutoff_features:\n                        feat_dict.pop(feature)\n\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">extract_feats</span>(<span class=\"hljs-params\">self, sentence, i, history, rare_word_cutoff=<span class=\"hljs-number\">5</span></span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Generates a featureset from a word (in a sentence). The features\n        were chosen as described in Ratnaparkhi (1996) and his Java\n        software package U{MXPOST&lt;ftp://ftp.cis.upenn.edu/pub/adwait/jmx&gt;}.\n\n        The following features are extracted:\n\n            - features for all words: last tag (C{t-1}), last two tags (C{t-2\n              t-1}), last words (C{w-1}) and (C{w-2}), next words (C{w+1}) and\n              (C{w+2})\n            - features for non-rare words: current word (C{w})\n            - features for rare words: word suffixes (last 1-4 letters),\n              word prefixes (first 1-4 letters),\n              word contains number (C{bool}), word contains uppercase character\n              (C{bool}), word contains hyphen (C{bool})\n\n        Ratnaparkhi experimented with his tagger on the Wall Street Journal\n        corpus (Penn Treebank project). He found that the tagger yields\n        better results when words which occur less than 5 times are treated\n        as rare. As your mileage may vary, please adjust\n        L{rare_word_cutoff} accordingly.\n\n        Examples\n        ========\n\n            1. This is a featureset extracted from the nonrare (word, tag)\n            tuple ('considerably', 'RB')\n\n            &gt;&gt;&gt; featuresets[22356]\n            ({'t-1': 'VB',\n            't-2 t-1': 'TO VB',\n            'w': 'considerably',\n            'w+1': '.',\n            'w+2': '&lt;END&gt;',\n            'w-1': 'improve',\n            'w-2': 'to'},\n            'RB')\n\n            2. A featureset extracted from the rare tuple ('Lemont', 'NN')\n\n            &gt;&gt;&gt; featuresets[46712]\n            ({'suffix(1)': 't',\n            'prefix(1)': 'L',\n            'prefix(2)': 'Le',\n            'prefix(3)': 'Lem',\n            'suffix(3)': 'ont',\n            'suffix(2)': 'nt',\n            'contains-uppercase': True,\n            'prefix(4)': 'Lemo',\n            'suffix(4)': 'mont'},\n            'NNP')\n\n\n        @type sentence: C{list} of C{str}\n        @param sentence: A list of words, usually a sentence.\n\n        @type i: C{int}\n        @param i: The index of a word in a sentence, where C{sentence[0]} would\n        represent the first word of a sentence.\n\n        @type history: C{int} of C{str}\n        @param history: A list of POS-tags that have been assigned to the\n        preceding words in a sentence.\n\n        @type rare_word_cutoff: C{int}\n        @param rare_word_cutoff: Words with less occurrences than\n        C{rare_word_cutoff} will be treated differently than non-rare words\n        (cf. Ratnaparkhi 1996).\n\n        @rtype: C{dict}\n        @return: a dictionary of features extracted from a word's\n        context.\n        \"\"\"</span>\n        features = {}\n        hyphen = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"-\"</span>)\n        number = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">\"\\d\"</span>)\n        uppercase = re.<span class=\"hljs-built_in\">compile</span>(self.uppercase_letters)\n\n        <span class=\"hljs-comment\">#get features: w-1, w-2, t-1, t-2.</span>\n        <span class=\"hljs-comment\">#takes care of the beginning of a sentence</span>\n        <span class=\"hljs-keyword\">if</span> i == <span class=\"hljs-number\">0</span>: <span class=\"hljs-comment\">#first word of sentence</span>\n            features.update({<span class=\"hljs-string\">\"w-1\"</span>: <span class=\"hljs-string\">\"&lt;START&gt;\"</span>, <span class=\"hljs-string\">\"t-1\"</span>: <span class=\"hljs-string\">\"&lt;START&gt;\"</span>,\n                             <span class=\"hljs-string\">\"w-2\"</span>: <span class=\"hljs-string\">\"&lt;START&gt;\"</span>, <span class=\"hljs-string\">\"t-2 t-1\"</span>: <span class=\"hljs-string\">\"&lt;START&gt; &lt;START&gt;\"</span>})\n        <span class=\"hljs-keyword\">elif</span> i == <span class=\"hljs-number\">1</span>: <span class=\"hljs-comment\">#second word of sentence</span>\n            features.update({<span class=\"hljs-string\">\"w-1\"</span>: sentence[i-<span class=\"hljs-number\">1</span>], <span class=\"hljs-string\">\"t-1\"</span>: history[i-<span class=\"hljs-number\">1</span>],\n                             <span class=\"hljs-string\">\"w-2\"</span>: <span class=\"hljs-string\">\"&lt;START&gt;\"</span>,\n                             <span class=\"hljs-string\">\"t-2 t-1\"</span>: <span class=\"hljs-string\">\"&lt;START&gt; %s\"</span> % (history[i-<span class=\"hljs-number\">1</span>])})\n        <span class=\"hljs-keyword\">else</span>:\n            features.update({<span class=\"hljs-string\">\"w-1\"</span>: sentence[i-<span class=\"hljs-number\">1</span>], <span class=\"hljs-string\">\"t-1\"</span>: history[i-<span class=\"hljs-number\">1</span>],\n                <span class=\"hljs-string\">\"w-2\"</span>: sentence[i-<span class=\"hljs-number\">2</span>],\n                <span class=\"hljs-string\">\"t-2 t-1\"</span>: <span class=\"hljs-string\">\"%s %s\"</span> % (history[i-<span class=\"hljs-number\">2</span>], history[i-<span class=\"hljs-number\">1</span>])})\n\n        <span class=\"hljs-comment\">#get features: w+1, w+2. takes care of the end of a sentence.</span>\n        <span class=\"hljs-keyword\">for</span> inc <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>]:\n            <span class=\"hljs-keyword\">try</span>:\n                features[<span class=\"hljs-string\">\"w+%i\"</span> % (inc)] = sentence[i+inc]\n            <span class=\"hljs-keyword\">except</span> IndexError:\n                features[<span class=\"hljs-string\">\"w+%i\"</span> % (inc)] = <span class=\"hljs-string\">\"&lt;END&gt;\"</span>\n\n        <span class=\"hljs-keyword\">if</span> self.word_freqdist[sentence[i]] &gt;= rare_word_cutoff:\n            <span class=\"hljs-comment\">#additional features for 'non-rare' words</span>\n            features[<span class=\"hljs-string\">\"w\"</span>] = sentence[i]\n\n        <span class=\"hljs-keyword\">else</span>: <span class=\"hljs-comment\">#additional features for 'rare' or 'unseen' words</span>\n            features.update({<span class=\"hljs-string\">\"suffix(1)\"</span>: sentence[i][-<span class=\"hljs-number\">1</span>:],\n                <span class=\"hljs-string\">\"suffix(2)\"</span>: sentence[i][-<span class=\"hljs-number\">2</span>:], <span class=\"hljs-string\">\"suffix(3)\"</span>: sentence[i][-<span class=\"hljs-number\">3</span>:],\n                <span class=\"hljs-string\">\"suffix(4)\"</span>: sentence[i][-<span class=\"hljs-number\">4</span>:], <span class=\"hljs-string\">\"prefix(1)\"</span>: sentence[i][:<span class=\"hljs-number\">1</span>],\n                <span class=\"hljs-string\">\"prefix(2)\"</span>: sentence[i][:<span class=\"hljs-number\">2</span>], <span class=\"hljs-string\">\"prefix(3)\"</span>: sentence[i][:<span class=\"hljs-number\">3</span>],\n                <span class=\"hljs-string\">\"prefix(4)\"</span>: sentence[i][:<span class=\"hljs-number\">4</span>]})\n            <span class=\"hljs-keyword\">if</span> hyphen.search(sentence[i]) != <span class=\"hljs-literal\">None</span>:\n                <span class=\"hljs-comment\">#set True, if regex is found at least once</span>\n                features[<span class=\"hljs-string\">\"contains-hyphen\"</span>] = <span class=\"hljs-literal\">True</span>\n            <span class=\"hljs-keyword\">if</span> number.search(sentence[i]) != <span class=\"hljs-literal\">None</span>:\n                features[<span class=\"hljs-string\">\"contains-number\"</span>] = <span class=\"hljs-literal\">True</span>\n            <span class=\"hljs-keyword\">if</span> uppercase.search(sentence[i]) != <span class=\"hljs-literal\">None</span>:\n                features[<span class=\"hljs-string\">\"contains-uppercase\"</span>] = <span class=\"hljs-literal\">True</span>\n\n        <span class=\"hljs-keyword\">return</span> features\n\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">tag</span>(<span class=\"hljs-params\">self, sentence, rare_word_cutoff=<span class=\"hljs-number\">5</span></span>):</span>\n        <span class=\"hljs-string\">\"\"\"\n        Attaches a part-of-speech tag to each word in a sequence.\n\n        @type sentence: C{list} of C{str}\n        @param sentence: a list of words to be tagged.\n\n        @type rare_word_cutoff: C{int}\n        @param rare_word_cutoff: words with less occurrences than\n        C{rare_word_cutoff} will be treated differently than non-rare words\n        (cf. Ratnaparkhi 1996).\n\n        @rtype: C{list} of C{tuples} of (C{str}, C{str})\n        @return: a list of tuples consisting of a word and its corresponding\n        part-of-speech tag.\n        \"\"\"</span>\n        history = []\n        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> xrange(<span class=\"hljs-built_in\">len</span>(sentence)):\n            featureset = self.extract_feats(sentence, i, history,\n                                               rare_word_cutoff)\n            tag = self.classifier.classify(featureset)\n            history.append(tag)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">zip</span>(sentence, history)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">demo</span>(<span class=\"hljs-params\">corpus, num_sents</span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    Loads a few sentences from the Brown corpus or the Wall Street Journal\n    corpus, trains them, tests the tagger's accuracy and tags an unseen\n    sentence.\n\n    @type corpus: C{str}\n    @param corpus: Name of the corpus to load, either C{brown} or C{treebank}.\n\n    @type num_sents: C{int}\n    @param num_sents: Number of sentences to load from a corpus. Use a small\n    number, as training might take a while.\n    \"\"\"</span>\n    <span class=\"hljs-keyword\">if</span> corpus.lower() == <span class=\"hljs-string\">\"brown\"</span>:\n        <span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> brown\n        tagged_sents = brown.tagged_sents()[:num_sents]\n    <span class=\"hljs-keyword\">elif</span> corpus.lower() == <span class=\"hljs-string\">\"treebank\"</span>:\n        <span class=\"hljs-keyword\">from</span> nltk.corpus <span class=\"hljs-keyword\">import</span> treebank\n        tagged_sents = treebank.tagged_sents()[:num_sents]\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"Please load either the 'brown' or the 'treebank' corpus.\"</span>\n\n    size = <span class=\"hljs-built_in\">int</span>(<span class=\"hljs-built_in\">len</span>(tagged_sents) * <span class=\"hljs-number\">0.1</span>)\n    train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n    maxent_tagger = MaxentPosTagger()\n    maxent_tagger.train(train_sents)\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"tagger accuracy (test %i sentences, after training %i):\"</span> % \\\n        (size, (num_sents - size)), maxent_tagger.evaluate(test_sents)\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"\\n\\n\"</span>\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"classify unseen sentence: \"</span>, maxent_tagger.tag([<span class=\"hljs-string\">\"This\"</span>, <span class=\"hljs-string\">\"is\"</span>, <span class=\"hljs-string\">\"so\"</span>,\n        <span class=\"hljs-string\">\"slow\"</span>, <span class=\"hljs-string\">\"!\"</span>])\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"\\n\\n\"</span>\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"show the 10 most informative features:\"</span>\n    <span class=\"hljs-built_in\">print</span> maxent_tagger.classifier.show_most_informative_features(<span class=\"hljs-number\">10</span>)\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    demo(<span class=\"hljs-string\">\"treebank\"</span>, <span class=\"hljs-number\">200</span>)\n    <span class=\"hljs-comment\">#~ featuresets = demo_debugger(\"treebank\", 10000)</span>\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"\\n\\n\\n\"</span>\n\n<span class=\"hljs-comment\">#https://github.com/arne-cl/nltk-maxent-pos-tagger/blob/master/mxpost.py</span></code></pre></div>",
    "sec_7.py": "<div class=\"codeBlock hljs coffeescript\" id=\"sec_7\"><pre id=\"sec_7_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">from</span> textblob.parsers <span class=\"hljs-keyword\">import</span> PatternParser\n<div style=\"display: inline;\" id=\"parsing_0\" class=\"highlights fea_parsing\">blob = TextBlob(<span class=\"hljs-string\">\"Parsing is fun.\"</span>, parser=PatternParser())</div>\n<div style=\"display: inline;\" id=\"parsing_1\" class=\"highlights fea_parsing\">blob.parse()</div>\n<span class=\"hljs-comment\">#https://textblob.readthedocs.io/en/dev/advanced_usage.html</span></code></pre></div>",
    "sec_10.py": "<div class=\"codeBlock hljs python\" id=\"sec_10\"><pre id=\"sec_10_code\" ><code class=\"json\">\n<span class=\"hljs-keyword\">from</span> flask <span class=\"hljs-keyword\">import</span> Flask, render_template, request\napp = Flask(__name__)\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> Word\n<span class=\"hljs-keyword\">import</span> sys\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">parse</span>(<span class=\"hljs-params\">string</span>):</span>\n   <span class=\"hljs-string\">\"\"\"\n   Parse a paragraph. Devide it into sentences and try to generate quesstions from each sentences.\n   \"\"\"</span>\n   data = []\n   <span class=\"hljs-keyword\">try</span>:\n      txt = TextBlob(string)\n      <span class=\"hljs-comment\"># Each sentence is taken from the string input and passed to genQuestion() to generate questions.</span>\n      <span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> txt.sentences:\n         question = genQuestion(sentence)\n         <span class=\"hljs-keyword\">if</span> question != <span class=\"hljs-literal\">None</span>:\n            data.append(question)\n      <span class=\"hljs-keyword\">return</span> data\n   <span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:\n      <span class=\"hljs-keyword\">raise</span> e\n\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">genQuestion</span>(<span class=\"hljs-params\">line</span>):</span>\n\n   <span class=\"hljs-string\">\"\"\"\n   outputs question from the given text\n   \"\"\"</span>\n   answer = line\n   <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">type</span>(line) <span class=\"hljs-keyword\">is</span> <span class=\"hljs-built_in\">str</span>:\n      line = TextBlob(line) <span class=\"hljs-comment\"># Create object of type textblob.blob.TextBlob</span>\n\n   bucket = {}               <span class=\"hljs-comment\"># Create an empty dictionary</span>\n   <span class=\"hljs-keyword\">for</span> i,j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(<div style=\"display: inline;\" id=\"tagger_0\" class=\"highlights fea_tagger\">line.tags</div>):  <span class=\"hljs-comment\"># line.tags are the parts-of-speach in English</span>\n      <span class=\"hljs-keyword\">if</span> j[<span class=\"hljs-number\">1</span>] <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> bucket:\n         bucket[j[<span class=\"hljs-number\">1</span>]] = i  <span class=\"hljs-comment\"># Add all tags to the dictionary or bucket variable</span>\n    \n   <span class=\"hljs-keyword\">if</span> verbose:               <span class=\"hljs-comment\"># In verbose more print the key,values of dictionary</span>\n      print(<span class=\"hljs-string\">'\\n'</span>,<span class=\"hljs-string\">'-'</span>*<span class=\"hljs-number\">20</span>)\n      print(line ,<span class=\"hljs-string\">'\\n'</span>)  \n      print(<span class=\"hljs-string\">\"TAGS:\"</span>,line.tags, <span class=\"hljs-string\">'\\n'</span>)  \n      print(bucket)\n    \n   question = <span class=\"hljs-string\">''</span>            <span class=\"hljs-comment\"># Create an empty string </span>\n\n    <span class=\"hljs-comment\"># These are the english part-of-speach tags used in this demo program.</span>\n    <span class=\"hljs-comment\">#.....................................................................</span>\n    <span class=\"hljs-comment\"># NNS     Noun, plural</span>\n    <span class=\"hljs-comment\"># JJ  Adjective </span>\n    <span class=\"hljs-comment\"># NNP     Proper noun, singular </span>\n    <span class=\"hljs-comment\"># VBG     Verb, gerund or present participle </span>\n    <span class=\"hljs-comment\"># VBN     Verb, past participle </span>\n    <span class=\"hljs-comment\"># VBZ     Verb, 3rd person singular present </span>\n    <span class=\"hljs-comment\"># VBD     Verb, past tense </span>\n    <span class=\"hljs-comment\"># IN      Preposition or subordinating conjunction </span>\n    <span class=\"hljs-comment\"># PRP     Personal pronoun </span>\n    <span class=\"hljs-comment\"># NN  Noun, singular or mass </span>\n    <span class=\"hljs-comment\">#.....................................................................</span>\n\n    <span class=\"hljs-comment\"># Create a list of tag-combination</span>\n\n   l1 = [<span class=\"hljs-string\">'NNP'</span>, <span class=\"hljs-string\">'VBG'</span>, <span class=\"hljs-string\">'VBZ'</span>, <span class=\"hljs-string\">'IN'</span>]\n   l2 = [<span class=\"hljs-string\">'NNP'</span>, <span class=\"hljs-string\">'VBG'</span>, <span class=\"hljs-string\">'VBZ'</span>]\n    \n\n   l3 = [<span class=\"hljs-string\">'PRP'</span>, <span class=\"hljs-string\">'VBG'</span>, <span class=\"hljs-string\">'VBZ'</span>, <span class=\"hljs-string\">'IN'</span>]\n   l4 = [<span class=\"hljs-string\">'PRP'</span>, <span class=\"hljs-string\">'VBG'</span>, <span class=\"hljs-string\">'VBZ'</span>]\n   l5 = [<span class=\"hljs-string\">'PRP'</span>, <span class=\"hljs-string\">'VBG'</span>, <span class=\"hljs-string\">'VBD'</span>]\n   l6 = [<span class=\"hljs-string\">'NNP'</span>, <span class=\"hljs-string\">'VBG'</span>, <span class=\"hljs-string\">'VBD'</span>]\n   l7 = [<span class=\"hljs-string\">'NN'</span>, <span class=\"hljs-string\">'VBG'</span>, <span class=\"hljs-string\">'VBZ'</span>]\n\n   l8 = [<span class=\"hljs-string\">'NNP'</span>, <span class=\"hljs-string\">'VBZ'</span>, <span class=\"hljs-string\">'JJ'</span>]\n   l9 = [<span class=\"hljs-string\">'NNP'</span>, <span class=\"hljs-string\">'VBZ'</span>, <span class=\"hljs-string\">'NN'</span>]\n\n   l10 = [<span class=\"hljs-string\">'NNP'</span>, <span class=\"hljs-string\">'VBZ'</span>]\n   l11 = [<span class=\"hljs-string\">'PRP'</span>, <span class=\"hljs-string\">'VBZ'</span>]\n   l12 = [<span class=\"hljs-string\">'NNP'</span>, <span class=\"hljs-string\">'NN'</span>, <span class=\"hljs-string\">'IN'</span>]\n   l13 = [<span class=\"hljs-string\">'NN'</span>, <span class=\"hljs-string\">'VBZ'</span>]\n\n   l14 = [<span class=\"hljs-string\">'DT'</span>, <span class=\"hljs-string\">'NNP'</span>, <span class=\"hljs-string\">'VBZ'</span>, <span class=\"hljs-string\">'JJ'</span>, <span class=\"hljs-string\">'IN'</span>]\n\n\n    <span class=\"hljs-comment\"># With the use of conditional statements the dictionary is compared with the list created above</span>\n\n   <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span> bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l14): <span class=\"hljs-comment\">#'NN', 'VBZ' in sentence.</span>\n      question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]] + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'NNP'</span>]] + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'JJ'</span>]] + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'IN'</span>]] + <span class=\"hljs-string\">'?'</span>\n\n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span>  bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l1): <span class=\"hljs-comment\">#'NNP', 'VBG', 'VBZ', 'IN' in sentence.</span>\n      question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]] +<span class=\"hljs-string\">' '</span>+ line.words[bucket[<span class=\"hljs-string\">'NNP'</span>]]+ <span class=\"hljs-string\">' '</span>+ line.words[bucket[<span class=\"hljs-string\">'VBG'</span>]] + <span class=\"hljs-string\">'?'</span>\n\n    \n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span>  bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l2): <span class=\"hljs-comment\">#'NNP', 'VBG', 'VBZ' in sentence.</span>\n      question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]] +<span class=\"hljs-string\">' '</span>+ line.words[bucket[<span class=\"hljs-string\">'NNP'</span>]] +<span class=\"hljs-string\">' '</span>+ line.words[bucket[<span class=\"hljs-string\">'VBG'</span>]] + <span class=\"hljs-string\">'?'</span>\n\n    \n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span>  bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l3): <span class=\"hljs-comment\">#'PRP', 'VBG', 'VBZ', 'IN' in sentence.</span>\n      question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]] +<span class=\"hljs-string\">' '</span>+ line.words[bucket[<span class=\"hljs-string\">'PRP'</span>]]+ <span class=\"hljs-string\">' '</span>+ line.words[bucket[<span class=\"hljs-string\">'VBG'</span>]] + <span class=\"hljs-string\">'?'</span>\n\n    \n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span>  bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l4): <span class=\"hljs-comment\">#'PRP', 'VBG', 'VBZ' in sentence.</span>\n      question = <span class=\"hljs-string\">'What '</span> + line.words[bucket[<span class=\"hljs-string\">'PRP'</span>]] +<span class=\"hljs-string\">' '</span>+  <span class=\"hljs-string\">' does '</span> + line.words[bucket[<span class=\"hljs-string\">'VBG'</span>]]+ <span class=\"hljs-string\">' '</span>+  line.words[bucket[<span class=\"hljs-string\">'VBG'</span>]] + <span class=\"hljs-string\">'?'</span>\n\n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span>  bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l7): <span class=\"hljs-comment\">#'NN', 'VBG', 'VBZ' in sentence.</span>\n      question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]] +<span class=\"hljs-string\">' '</span>+ line.words[bucket[<span class=\"hljs-string\">'NN'</span>]] +<span class=\"hljs-string\">' '</span>+ line.words[bucket[<span class=\"hljs-string\">'VBG'</span>]] + <span class=\"hljs-string\">'?'</span>\n\n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span> bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l8): <span class=\"hljs-comment\">#'NNP', 'VBZ', 'JJ' in sentence.</span>\n      question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]] + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'NNP'</span>]] + <span class=\"hljs-string\">'?'</span>\n\n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span> bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l9): <span class=\"hljs-comment\">#'NNP', 'VBZ', 'NN' in sentence</span>\n      question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]] + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'NNP'</span>]] + <span class=\"hljs-string\">'?'</span>\n\n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span> bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l11): <span class=\"hljs-comment\">#'PRP', 'VBZ' in sentence.</span>\n      <span class=\"hljs-keyword\">if</span> line.words[bucket[<span class=\"hljs-string\">'PRP'</span>]] <span class=\"hljs-keyword\">in</span> [<span class=\"hljs-string\">'she'</span>,<span class=\"hljs-string\">'he'</span>]:\n          question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' does '</span> + line.words[bucket[<span class=\"hljs-string\">'PRP'</span>]].lower() + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]].singularize() + <span class=\"hljs-string\">'?'</span>\n\n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span> bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l10): <span class=\"hljs-comment\">#'NNP', 'VBZ' in sentence.</span>\n      question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' does '</span> + line.words[bucket[<span class=\"hljs-string\">'NNP'</span>]] + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]].singularize() + <span class=\"hljs-string\">'?'</span>\n\n   <span class=\"hljs-keyword\">elif</span> <span class=\"hljs-built_in\">all</span>(key <span class=\"hljs-keyword\">in</span> bucket <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> l13): <span class=\"hljs-comment\">#'NN', 'VBZ' in sentence.</span>\n      question = <span class=\"hljs-string\">'What'</span> + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]] + <span class=\"hljs-string\">' '</span> + line.words[bucket[<span class=\"hljs-string\">'NN'</span>]] + <span class=\"hljs-string\">'?'</span>\n    \n \n\n    <span class=\"hljs-comment\"># When the tags are generated 's is split to ' and s. To overcome this issue.</span>\n   <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">'VBZ'</span> <span class=\"hljs-keyword\">in</span> bucket <span class=\"hljs-keyword\">and</span> line.words[bucket[<span class=\"hljs-string\">'VBZ'</span>]] == <span class=\"hljs-string\">\"\"</span>:\n      question = question.replace(<span class=\"hljs-string\">\"  \"</span>,<span class=\"hljs-string\">\"'s \"</span>)\n\n   <span class=\"hljs-comment\"># Print the genetated questions as output.</span>\n   <span class=\"hljs-keyword\">if</span> question != <span class=\"hljs-string\">''</span>:\n      print(<span class=\"hljs-string\">'\\n'</span>, <span class=\"hljs-string\">'Question: '</span> + question )\n\n      <span class=\"hljs-keyword\">return</span> {<span class=\"hljs-string\">'question'</span>:question,<span class=\"hljs-string\">'answer'</span>:answer}\n      <span class=\"hljs-comment\"># print('\\n', 'Question: ' + question )</span>\n   \n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">'/'</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">student</span>():</span>\n   <span class=\"hljs-keyword\">return</span> render_template(<span class=\"hljs-string\">'form.html'</span>)\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">'/result'</span>,methods = [<span class=\"hljs-string\">'POST'</span>, <span class=\"hljs-string\">'GET'</span>]</span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">result</span>():</span>\n   <span class=\"hljs-keyword\">global</span> verbose \n   verbose = <span class=\"hljs-literal\">False</span>\n   text_input = <span class=\"hljs-string\">''</span>\n   <span class=\"hljs-keyword\">if</span> request.method == <span class=\"hljs-string\">'POST'</span>:\n      result = request.form\n      <span class=\"hljs-keyword\">for</span> key, value <span class=\"hljs-keyword\">in</span> result.items():\n         text_input += value\n      data = (<div style=\"display: inline;\" id=\"parsing_0\" class=\"highlights fea_parsing\">parse(text_input)</div>)\n     \n      <span class=\"hljs-keyword\">return</span> render_template(<span class=\"hljs-string\">\"result.html\"</span>,result = data)\n   <span class=\"hljs-keyword\">else</span>:\n      <span class=\"hljs-keyword\">return</span> render_template(<span class=\"hljs-string\">'form.html'</span>)\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n   app.run(debug = <span class=\"hljs-literal\">True</span>)\n   <span class=\"hljs-comment\">#https://github.com/huudangdev/generator-question-textblob-nlp/blob/master/app.py</span></code></pre></div>",
    "sec_2.py": "<div class=\"codeBlock hljs coffeescript\" id=\"sec_2\"><pre id=\"sec_2_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> Word\n\nword1 = Word(<span class=\"hljs-string\">\"apples\"</span>)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"apples:\"</span>, <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">word1.lemmatize()</div>)\n\nword2 = Word(<span class=\"hljs-string\">\"media\"</span>)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"media:\"</span>, word2.lemmatize())\n\nworfir = Word(<span class=\"hljs-string\">\"greater\"</span>)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"greater:\"</span>, worfir.lemmatize(<span class=\"hljs-string\">\"a\"</span>))\n\n<span class=\"hljs-keyword\">for</span> word, pos <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">text_blob_object.tags</div>:\n    <span class=\"hljs-built_in\">print</span>(word + <span class=\"hljs-string\">\" =&gt; \"</span> + pos)\n\ntext = (<span class=\"hljs-string\">\"Football is a good game. It has many health benefit\"</span>)\ntext_blob_object = TextBlob(text)\n<span class=\"hljs-built_in\"></span><span class=\"hljs-built_in\"></span><div style=\"display: inline;\" id=\"text_simplify_0\" class=\"highlights fea_text_simplify\"><span class=\"hljs-built_in\">print</span>(text_blob_object.words.pluralize())\n<span class=\"hljs-built_in\">print</span>(text_blob_object.words.singularize())</div>\n\n    <span class=\"hljs-comment\">#https://stackabuse.com/python-for-nlp-introduction-to-the-textblob-library/</span></code></pre></div>",
    "sec_12.py": "<div class=\"codeBlock hljs python\" id=\"sec_12\"><pre id=\"sec_12_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> flask <span class=\"hljs-keyword\">import</span> Flask, request, jsonify\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob, Word\n<span class=\"hljs-keyword\">from</span> textblob.exceptions <span class=\"hljs-keyword\">import</span> NotTranslated\napp = Flask(__name__)\n\n<span class=\"hljs-keyword\">from</span> signal <span class=\"hljs-keyword\">import</span> *\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/sentiment\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">singularize</span>():</span>\n\ttext = request.args.get(<span class=\"hljs-string\">'text'</span>).strip().encode(<span class=\"hljs-string\">'utf-8'</span>, <span class=\"hljs-string\">\"ignore\"</span>)\n\tblob = TextBlob(text)\n\t\n\t<span class=\"hljs-keyword\">return</span> jsonify(blob.sentiment)\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/singularize\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">sentiment</span>():</span>\n\ttext = request.args.get(<span class=\"hljs-string\">'text'</span>).strip().encode(<span class=\"hljs-string\">'utf-8'</span>, <span class=\"hljs-string\">\"ignore\"</span>)\n\tblob = TextBlob(text)\n\t\n\t<span class=\"hljs-keyword\">return</span> jsonify(blob.words.singularize())\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/lemmatize\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">lemmatize</span>():</span>\n\ttext = request.args.get(<span class=\"hljs-string\">'text'</span>).strip().encode(<span class=\"hljs-string\">'utf-8'</span>, <span class=\"hljs-string\">\"ignore\"</span>)\n\tblob = TextBlob(text)\n\t\n\t<span class=\"hljs-keyword\">return</span> jsonify(<div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">blob.words.lemmatize()</div>)\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/correct\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">correct</span>():</span>\n\ttext = request.args.get(<span class=\"hljs-string\">'text'</span>).strip().encode(<span class=\"hljs-string\">'utf-8'</span>, <span class=\"hljs-string\">\"ignore\"</span>)\n\tblob = TextBlob(text)\n\t\n\t<span class=\"hljs-keyword\">return</span> jsonify({<span class=\"hljs-string\">'correct'</span>:<span class=\"hljs-built_in\">str</span>(<div style=\"display: inline;\" id=\"spellcheck_0\" class=\"highlights fea_spellcheck\">blob.correct()</div>)})\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/spelling\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">spelling</span>():</span>\n\ttext = request.args.get(<span class=\"hljs-string\">'text'</span>).strip().encode(<span class=\"hljs-string\">'utf-8'</span>, <span class=\"hljs-string\">\"ignore\"</span>)\n\tblob = TextBlob(text)\n\n\tsuggestions = {}\n\t<span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> blob.words:\n\t\tword = Word(token)\n\t\tsuggestions[token] = word.spellcheck()\n\t\t\n\t<span class=\"hljs-keyword\">return</span> jsonify(suggestions)\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/language\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">language</span>():</span>\n\ttext = request.args.get(<span class=\"hljs-string\">'text'</span>).strip()\n\tblob = TextBlob(text)\n\t\n\t<span class=\"hljs-keyword\">return</span> jsonify({<span class=\"hljs-string\">\"language\"</span>:blob.detect_language()})\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/translate\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">translate</span>():</span>\n\ttext = request.args.get(<span class=\"hljs-string\">'text'</span>).strip()\n\tl_from = request.args.get(<span class=\"hljs-string\">'from'</span>)\n\tl_to = request.args.get(<span class=\"hljs-string\">'to'</span>)\n\n\tblob = TextBlob(text)\n\n\t<span class=\"hljs-keyword\">if</span> l_from <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n\t\t<div style=\"display: inline;\" id=\"language_detection_0\" class=\"highlights fea_language_detection\">l_from = blob.detect_language()</div>\n\t\n\t<span class=\"hljs-keyword\">try</span>:\n\t\t<div style=\"display: inline;\" id=\"translation_0\" class=\"highlights fea_translation\">translated = blob.translate(from_lang = l_from, to = l_to)</div>\n\t<span class=\"hljs-keyword\">except</span> NotTranslated:\n\t\ttranslated = text\t\t\n\n\t<span class=\"hljs-keyword\">return</span> jsonify({<span class=\"hljs-string\">\"translation\"</span>:<span class=\"hljs-built_in\">str</span>(translated)})\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    app.run(host=<span class=\"hljs-string\">'0.0.0.0'</span>, port=<span class=\"hljs-number\">8593</span>)\n    <span class=\"hljs-comment\">#https://github.com/dpasch01/textblob-service/blob/master/textblob-service.py</span></code></pre></div>",
    "sec_6.py": "<div class=\"codeBlock hljs coffeescript\" id=\"sec_6\"><pre id=\"sec_6_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">from</span> textblob.taggers <span class=\"hljs-keyword\">import</span> NLTKTagger\n<div style=\"display: inline;\" id=\"tagger_0\" class=\"highlights fea_tagger\">nltk_tagger = NLTKTagger()</div>\nblob = TextBlob(<span class=\"hljs-string\">\"Tag! You're It!\"</span>, pos_tagger=nltk_tagger)\n<div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">blob.pos_tags</div>\n<span class=\"hljs-comment\">#https://textblob.readthedocs.io/en/dev/advanced_usage.html</span></code></pre></div>",
    "sec_9.py": "<div class=\"codeBlock hljs python\" id=\"sec_9\"><pre id=\"sec_9_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> textblob\n<div style=\"display: inline;\" id=\"text_simplify_0\" class=\"highlights fea_text_simplify\">stringText = textblob.TextBlob(<span class=\"hljs-built_in\">str</span>(<span class=\"hljs-built_in\">list</span>(dataset[<span class=\"hljs-string\">\"Summary\"</span>]))).lower()</div>\nwords = stringText.words\nwordCount = {}\nignore = [<span class=\"hljs-string\">'a'</span>, <span class=\"hljs-string\">'an'</span>, <span class=\"hljs-string\">'the'</span>, <span class=\"hljs-string\">\"'the\"</span>, <span class=\"hljs-string\">'and'</span>, <span class=\"hljs-string\">'to'</span>, <span class=\"hljs-string\">'of'</span>, <span class=\"hljs-string\">'in'</span>, <span class=\"hljs-string\">'into'</span>, <span class=\"hljs-string\">'is'</span>, <span class=\"hljs-string\">'was'</span>, <span class=\"hljs-string\">'on'</span>, <span class=\"hljs-string\">'at'</span>, <span class=\"hljs-string\">'from'</span>, <span class=\"hljs-string\">'with'</span>,\n          <span class=\"hljs-string\">'while'</span>, <span class=\"hljs-string\">'for'</span>, <span class=\"hljs-string\">\"'s\"</span>, <span class=\"hljs-string\">'as'</span>, <span class=\"hljs-string\">'not'</span>, <span class=\"hljs-string\">'by'</span>, <span class=\"hljs-string\">'after'</span>, <span class=\"hljs-string\">'during'</span>]\n\n<span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> words:\n    <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> ignore:\n        <span class=\"hljs-keyword\">continue</span>\n    <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">in</span> wordCount:\n        wordCount[word] = wordCount[word] + <span class=\"hljs-number\">1</span>\n    <span class=\"hljs-keyword\">else</span>:\n        wordCount[word] = <span class=\"hljs-number\">1</span>\n\n<span class=\"hljs-keyword\">import</span> operator\nsorted_word = <span class=\"hljs-built_in\">sorted</span>(wordCount.items(), key=operator.itemgetter(<span class=\"hljs-number\">1</span>), reverse=<span class=\"hljs-literal\">True</span>)[:<span class=\"hljs-number\">500</span>]\n<span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"sorted-word-count.txt\"</span>, <span class=\"hljs-string\">\"w\"</span>) <span class=\"hljs-keyword\">as</span> f:\n    f.write(<span class=\"hljs-built_in\">str</span>(sorted_word))\n\nreasons = [<span class=\"hljs-string\">'weather'</span>, <span class=\"hljs-string\">'fire'</span>, <span class=\"hljs-string\">'shot down'</span>, <span class=\"hljs-string\">'stall/runway'</span>, <span class=\"hljs-string\">'pilot/crew error'</span>, <span class=\"hljs-string\">'systems failure'</span>]\n\nexpresion = [<span class=\"hljs-string\">'((poor|bad).*(weather|visibility)|thunderstorm|fog)'</span>,<span class=\"hljs-string\">'(caught fire)|(caught on fire)'</span>, \n           <span class=\"hljs-string\">'(shot down) | (terrorist) | (terrorism)'</span>, <span class=\"hljs-string\">'(stall)|(runway)'</span>, <span class=\"hljs-string\">'(pilot|crew) (error|fatigue)'</span>,\n            <span class=\"hljs-string\">'(engine.*(fire|fail))|(structural fail)|(fuel leak)|(langing gear)|(turbulence)|(electrical)|(out of fuel)|(fuel.*exhaust)'</span>]\n\ndataset[<span class=\"hljs-string\">'Label'</span>] = pd.Series(np.nan, index=dataset.index)\n\ntrainData = []\n<span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(dataset)):\n    <span class=\"hljs-keyword\">if</span> dataset.loc[x,<span class=\"hljs-string\">\"Summary\"</span>] <span class=\"hljs-keyword\">is</span> np.nan:\n        dataset.loc[x,<span class=\"hljs-string\">\"Label\"</span>] = <span class=\"hljs-string\">\"unknown\"</span>\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">for</span> y <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(expresion)):\n            <span class=\"hljs-keyword\">if</span> re.search(expresion[y], dataset.loc[x,<span class=\"hljs-string\">\"Summary\"</span>].lower()):\n                dataset.loc[x,<span class=\"hljs-string\">\"Label\"</span>] = reasons[y]\n                temp = dataset.loc[x,<span class=\"hljs-string\">\"Summary\"</span>].lower(), dataset.loc[x,<span class=\"hljs-string\">\"Label\"</span>]\n                trainData.append(temp)\n                <span class=\"hljs-keyword\">break</span>\n\n<span class=\"hljs-keyword\">from</span> textblob.classifiers <span class=\"hljs-keyword\">import</span> NaiveBayesClassifier\n<div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">cl = NaiveBayesClassifier(trainData)</div>\n\nreasons.append(<span class=\"hljs-string\">\"unknown\"</span>)\n<span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">30</span>,<span class=\"hljs-built_in\">len</span>(dataset)):\n    <span class=\"hljs-keyword\">if</span> dataset.loc[x,<span class=\"hljs-string\">\"Label\"</span>] <span class=\"hljs-keyword\">in</span> reasons:\n       <span class=\"hljs-keyword\">continue</span>\n    <span class=\"hljs-keyword\">else</span>:\n        dataset.loc[x,<span class=\"hljs-string\">\"Label\"</span>] = cl.classify(dataset.loc[x,<span class=\"hljs-string\">\"Summary\"</span>])\n        <span class=\"hljs-comment\">#https://github.com/arif-zaman/airplane-crash/blob/master/Airplane.ipynb</span></code></pre></div>",
    "sec_27.py": "<div class=\"codeBlock hljs python\" id=\"sec_27\"><pre id=\"sec_27_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> argparse\n<span class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n\nDEFAULT_SUBJECT_LIMIT = <span class=\"hljs-number\">50</span>\nDEFAULT_BODY_LIMIT = <span class=\"hljs-number\">72</span>\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">CliColors</span>:</span>\n    HEADER = <span class=\"hljs-string\">'\\033[95m'</span>\n    OKBLUE = <span class=\"hljs-string\">'\\033[94m'</span>\n    OKGREEN = <span class=\"hljs-string\">'\\033[92m'</span>\n    WARNING = <span class=\"hljs-string\">'\\033[93m'</span>\n    FAIL = <span class=\"hljs-string\">'\\033[91m'</span>\n    ENDC = <span class=\"hljs-string\">'\\033[0m'</span>\n    BOLD = <span class=\"hljs-string\">'\\033[1m'</span>\n    UNDERLINE = <span class=\"hljs-string\">'\\033[4m'</span>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">check_subject_is_separated_from_body</span>(<span class=\"hljs-params\">commit_message</span>):</span>\n    lines = commit_message.splitlines()\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(lines) &gt; <span class=\"hljs-number\">1</span>:\n        <span class=\"hljs-comment\"># The second line should be empty</span>\n        check_result = <span class=\"hljs-keyword\">not</span> lines[<span class=\"hljs-number\">1</span>]\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-comment\"># If there is just one line then this rule doesn't apply</span>\n        check_result = <span class=\"hljs-literal\">True</span>\n    print_result(check_result, <span class=\"hljs-string\">\"Separate subject from body with a blank line\"</span>)\n\n    <span class=\"hljs-keyword\">return</span> check_result\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">check_subject_is_not_too_long</span>(<span class=\"hljs-params\">commit_message, subject_limit</span>):</span>\n    lines = commit_message.splitlines()\n    check_result = <span class=\"hljs-built_in\">len</span>(lines[<span class=\"hljs-number\">0</span>]) &lt;= subject_limit\n    print_result(check_result, <span class=\"hljs-string\">\"Limit the subject line to \"</span> +\n                 <span class=\"hljs-built_in\">str</span>(subject_limit) + <span class=\"hljs-string\">\" characters\"</span>)\n\n    <span class=\"hljs-keyword\">return</span> check_result\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">check_subject_is_capitalized</span>(<span class=\"hljs-params\">commit_message</span>):</span>\n    lines = commit_message.splitlines()\n    <span class=\"hljs-comment\"># Check if first character is in upper case</span>\n    check_result = lines[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">0</span>].isupper()\n    print_result(check_result, <span class=\"hljs-string\">\"Capitalize the subject line\"</span>)\n\n    <span class=\"hljs-keyword\">return</span> check_result\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">check_subject_does_not_end_with_period</span>(<span class=\"hljs-params\">commit_message</span>):</span>\n    lines = commit_message.splitlines()\n    check_result = <span class=\"hljs-keyword\">not</span> lines[<span class=\"hljs-number\">0</span>].endswith(<span class=\"hljs-string\">\".\"</span>)\n    print_result(check_result, <span class=\"hljs-string\">\"Do not end the subject line with a period\"</span>)\n\n    <span class=\"hljs-keyword\">return</span> check_result\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">check_subject_uses_imperative</span>(<span class=\"hljs-params\">commit_message</span>):</span>\n    first = commit_message.splitlines()[<span class=\"hljs-number\">0</span>]\n    <div style=\"display: inline;\" id=\"n_grams_0\" class=\"highlights fea_n_grams\">third_person_singular_present_verb = <span class=\"hljs-string\">\"VBZ\"</span>\n    non_third_person_singular_present_verb = <span class=\"hljs-string\">\"VBP\"</span></div><span class=\"hljs-string\"></span>\n    <span class=\"hljs-comment\"># The default NLTK parser is not very good with imperative sentences</span>\n    <span class=\"hljs-comment\"># so we prefix the commit message with a personal pronoun so to</span>\n    <span class=\"hljs-comment\"># help it determine easier whether the upcoming word is a verb</span>\n    <span class=\"hljs-comment\"># and not a noun.</span>\n    <span class=\"hljs-comment\"># We will prefix in two different ways, so to avoid false results.</span>\n    <span class=\"hljs-comment\"># Read more here: https://stackoverflow.com/a/30823202/6485320</span>\n    <span class=\"hljs-comment\"># and here: https://stackoverflow.com/a/9572724/6485320</span>\n    third_person_prefix = <span class=\"hljs-string\">\"It \"</span>\n    words_in_third_person_prefix_blob = <span class=\"hljs-built_in\">len</span>(third_person_prefix.split())\n    non_third_person_prefix = <span class=\"hljs-string\">\"You \"</span>\n    words_in_non_third_person_prefix_blob = <span class=\"hljs-built_in\">len</span>(\n        non_third_person_prefix.split())\n    <span class=\"hljs-comment\"># Turn the first character into a lowercase so to make it easier for</span>\n    <span class=\"hljs-comment\"># the parser to determine whether the word is a verb and its tense</span>\n    first_character_in_lowercase = first[<span class=\"hljs-number\">0</span>].lower()\n    first = first_character_in_lowercase + first[<span class=\"hljs-number\">1</span>:]\n    third_person_blob = TextBlob(third_person_prefix + first)\n    non_third_person_blob = TextBlob(non_third_person_prefix + first)\n\n    first_word, third_person_result = third_person_blob.tags[words_in_third_person_prefix_blob]\n    _, non_third_person_result = non_third_person_blob.tags[words_in_non_third_person_prefix_blob]\n\n    <span class=\"hljs-comment\"># We need to determine whether the first word is a non-third person verb</span>\n    <span class=\"hljs-comment\"># when parsed in a non-third person blob. However, there were some</span>\n    <span class=\"hljs-comment\"># false positives so we use a third person blob to ensure it is not a</span>\n    <span class=\"hljs-comment\"># third person verb. Unfortunately, there were now some false negatives</span>\n    <span class=\"hljs-comment\"># due to verbs in a non-third person form, being classified as being in</span>\n    <span class=\"hljs-comment\"># third person, when parsed in the third person blob.</span>\n    <span class=\"hljs-comment\"># So, we ultimately check if the verb ends with an 's' which is a pretty</span>\n    <span class=\"hljs-comment\"># good indicator of a third person, simple present tense verb.</span>\n    <div style=\"display: inline;\" id=\"text_simplify_0\" class=\"highlights fea_text_simplify\">check_result = non_third_person_result == non_third_person_singular_present_verb <span class=\"hljs-keyword\">and</span> (\n        third_person_result != third_person_singular_present_verb <span class=\"hljs-keyword\">or</span> <span class=\"hljs-keyword\">not</span> first_word.endswith(<span class=\"hljs-string\">\"s\"</span>))</div>\n    print_result(check_result, <span class=\"hljs-string\">\"Use the imperative mood in the subject line\"</span>)\n\n    <span class=\"hljs-keyword\">return</span> check_result\n<span class=\"hljs-comment\">#https://github.com/platisd/bad-commit-message-blocker/blob/master/bad_commit_message_blocker.py</span></code></pre></div>",
    "sec_1.py": "<div class=\"codeBlock hljs swift\" id=\"sec_1\"><pre id=\"sec_1_code\" ><code class=\"json\">from textblob <span class=\"hljs-keyword\">import</span> TextBlob\nfrom textblob <span class=\"hljs-keyword\">import</span> Word\ndocument <span class=\"hljs-operator\">=</span> (<span class=\"hljs-string\">\"In computer science, artificial intelligence (AI), \\\n            sometimes called machine intelligence, is intelligence \\\n            demonstrated by machines, in contrast to the natural intelligence \\\n            displayed by humans and animals. Computer science defines AI \\\n            research as the study of <span class=\"hljs-subst\">\\\"</span>intelligent agents<span class=\"hljs-subst\">\\\"</span>: any device that \\\n            perceives its environment and takes actions that maximize its\\\n            chance of successfully achieving its goals.[1] Colloquially,\\\n            the term <span class=\"hljs-subst\">\\\"</span>artificial intelligence<span class=\"hljs-subst\">\\\"</span> is used to describe machines\\\n            that mimic <span class=\"hljs-subst\">\\\"</span>cognitive<span class=\"hljs-subst\">\\\"</span> functions that humans associate with other\\\n            human minds, such as <span class=\"hljs-subst\">\\\"</span>learning<span class=\"hljs-subst\">\\\"</span> and <span class=\"hljs-subst\">\\\"</span>problem solving<span class=\"hljs-subst\">\\\"</span>.[2]\"</span>)\ntext_blob_object <span class=\"hljs-operator\">=</span> <span class=\"hljs-type\">TextBlob</span>(document)\n<span class=\"hljs-keyword\"></span><div style=\"display: inline;\" id=\"n_grams_0\" class=\"highlights fea_n_grams\"><span class=\"hljs-keyword\">for</span> noun_phrase <span class=\"hljs-keyword\">in</span> text_blob_object.noun_phrases:\n    <span class=\"hljs-built_in\">print</span>(noun_phrase)</div>\n\ntext <span class=\"hljs-operator\">=</span> <span class=\"hljs-string\">\"I love to watch football, but I have never played it\"</span>\ntext_blob_object <span class=\"hljs-operator\">=</span> <span class=\"hljs-type\">TextBlob</span>(text)\n<span class=\"hljs-keyword\">for</span> ngram <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"n_grams_1\" class=\"highlights fea_n_grams\">text_blob_object.ngrams(<span class=\"hljs-number\">2</span>)</div>:\n    <span class=\"hljs-built_in\">print</span>(ngram)\n    #https:<span class=\"hljs-comment\">//stackabuse.com/python-for-nlp-introduction-to-the-textblob-library/</span></code></pre></div>",
    "sec_8.py": "<div class=\"codeBlock hljs coffeescript\" id=\"sec_8\"><pre id=\"sec_8_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">from</span> textblob.np_extractors <span class=\"hljs-keyword\">import</span> ConllExtractor\nextractor = ConllExtractor()\nblob = TextBlob(<span class=\"hljs-string\">\"Python is a high-level programming language.\"</span>, np_extractor=extractor)\n<div style=\"display: inline;\" id=\"n_grams_0\" class=\"highlights fea_n_grams\">blob.noun_phrases</div>\n<span class=\"hljs-comment\">#https://textblob.readthedocs.io/en/dev/advanced_usage.html</span></code></pre></div>",
    "sec_17.py": "<div class=\"codeBlock hljs python\" id=\"sec_17\"><pre id=\"sec_17_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">from</span> spellchecker <span class=\"hljs-keyword\">import</span> SpellChecker\n\n\na = <span class=\"hljs-built_in\">input</span>(<span class=\"hljs-string\">'Enter an Incorrect String : '</span>)\nprint(<span class=\"hljs-string\">'Original Text : '</span> + <span class=\"hljs-built_in\">str</span>(a))\nb = TextBlob(a)\n<div style=\"display: inline;\" id=\"spellcheck_0\" class=\"highlights fea_spellcheck\">print(<span class=\"hljs-string\">'Corrected Text : '</span> + <span class=\"hljs-built_in\">str</span>(b.correct()))</div>\n\n\nspell = SpellChecker()\n<span class=\"hljs-comment\"># Find those words that may be misspelled</span>\nmisspelled = spell.unknown([<span class=\"hljs-string\">'Good'</span>, <span class=\"hljs-string\">'Evening'</span>])\n\n<span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> misspelled:\n    <span class=\"hljs-comment\"># getting the one `most likely` answer</span>\n    print(spell.correction(word))\n    <span class=\"hljs-comment\"># getting a list of `likely` options</span>\n    print(spell.candidates(word))\n    <span class=\"hljs-comment\">#https://github.com/OjasBarawal/Spell-Checker/blob/main/app.py</span></code></pre></div>",
    "sec_26.py": "<div class=\"codeBlock hljs python\" id=\"sec_26\"><pre id=\"sec_26_code\" ><code class=\"json\"><span class=\"hljs-comment\"># The main package to help us with our text analysis</span>\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n\n<span class=\"hljs-comment\"># For reading input files in CSV format</span>\n<span class=\"hljs-keyword\">import</span> csv\n\n<span class=\"hljs-comment\"># For doing cool regular expressions</span>\n<span class=\"hljs-keyword\">import</span> re\n\n<span class=\"hljs-comment\"># For sorting dictionaries</span>\n<span class=\"hljs-keyword\">import</span> operator\n\n\n<span class=\"hljs-comment\"># For plotting results</span>\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">import</span> matplotlib.mlab <span class=\"hljs-keyword\">as</span> mlab\n<span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> thr\n\n<span class=\"hljs-comment\"># Intialize an empty list to hold all of our tweets</span>\ntweets = []\n\n\n<span class=\"hljs-comment\"># A helper function that removes all the non ASCII characters</span>\n<span class=\"hljs-comment\"># from the given string. Retuns a string with only ASCII characters.</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">strip_non_ascii</span>(<span class=\"hljs-params\">string</span>):</span>\n    <span class=\"hljs-string\">''' Returns the string without non ASCII characters'''</span>\n    stripped = (c <span class=\"hljs-keyword\">for</span> c <span class=\"hljs-keyword\">in</span> string <span class=\"hljs-keyword\">if</span> <span class=\"hljs-number\">0</span> &lt; <span class=\"hljs-built_in\">ord</span>(c) &lt; <span class=\"hljs-number\">127</span>)\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">''</span>.join(stripped)\n\n\n\n<span class=\"hljs-comment\"># LOAD AND CLEAN DATA</span>\n\n<span class=\"hljs-comment\"># Load in the input file and process each row at a time.</span>\n<span class=\"hljs-comment\"># We assume that the file has three columns:</span>\n<span class=\"hljs-comment\"># 0. The tweet text.</span>\n<span class=\"hljs-comment\"># 1. The tweet ID.</span>\n<span class=\"hljs-comment\"># 2. The tweet publish date</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># We create a data structure for each tweet:</span>\n<span class=\"hljs-comment\">#</span>\n<span class=\"hljs-comment\"># id:       The ID of the tweet</span>\n<span class=\"hljs-comment\"># pubdate:  The publication date of the tweet</span>\n<span class=\"hljs-comment\"># orig:     The original, unpreprocessed string of characters</span>\n<span class=\"hljs-comment\"># clean:    The preprocessed string of characters</span>\n<span class=\"hljs-comment\"># TextBlob: The TextBlob object, created from the 'clean' string</span>\n\n<span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">'newtwitter.csv'</span>, <span class=\"hljs-string\">'rb'</span>) <span class=\"hljs-keyword\">as</span> csvfile:\n    reader = csv.reader(csvfile, delimiter=<span class=\"hljs-string\">','</span>)\n    reader.<span class=\"hljs-built_in\">next</span>()\n    <span class=\"hljs-keyword\">for</span> row <span class=\"hljs-keyword\">in</span> reader:\n\n        tweet= <span class=\"hljs-built_in\">dict</span>()\n        tweet[<span class=\"hljs-string\">'orig'</span>] = row[<span class=\"hljs-number\">0</span>]\n        tweet[<span class=\"hljs-string\">'id'</span>] = <span class=\"hljs-built_in\">int</span>(row[<span class=\"hljs-number\">1</span>])\n        tweet[<span class=\"hljs-string\">'pubdate'</span>] = <span class=\"hljs-built_in\">int</span>(row[<span class=\"hljs-number\">2</span>])\n\n        <span class=\"hljs-comment\"># Ignore retweets</span>\n        <span class=\"hljs-keyword\">if</span> re.match(<span class=\"hljs-string\">r'^RT.*'</span>, tweet[<span class=\"hljs-string\">'orig'</span>]):\n            <span class=\"hljs-keyword\">continue</span>\n\n        tweet[<span class=\"hljs-string\">'clean'</span>] = tweet[<span class=\"hljs-string\">'orig'</span>]\n\n        <span class=\"hljs-comment\"># Remove all non-ascii characters</span>\n        tweet[<span class=\"hljs-string\">'clean'</span>] = strip_non_ascii(tweet[<span class=\"hljs-string\">'clean'</span>])\n\n        <span class=\"hljs-comment\"># Normalize case</span>\n        tweet[<span class=\"hljs-string\">'clean'</span>] = tweet[<span class=\"hljs-string\">'clean'</span>].lower()\n\n        <span class=\"hljs-comment\"># Remove URLS. (I stole this regex from the internet.)</span>\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'</span>, <span class=\"hljs-string\">''</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n\n        <span class=\"hljs-comment\"># Fix classic tweet lingo</span>\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bthats\\b'</span>, <span class=\"hljs-string\">'that is'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bive\\b'</span>, <span class=\"hljs-string\">'i have'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bim\\b'</span>, <span class=\"hljs-string\">'i am'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bya\\b'</span>, <span class=\"hljs-string\">'yeah'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bcant\\b'</span>, <span class=\"hljs-string\">'can not'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bwont\\b'</span>, <span class=\"hljs-string\">'will not'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bid\\b'</span>, <span class=\"hljs-string\">'i would'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'wtf'</span>, <span class=\"hljs-string\">'what the fuck'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bwth\\b'</span>, <span class=\"hljs-string\">'what the hell'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\br\\b'</span>, <span class=\"hljs-string\">'are'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bu\\b'</span>, <span class=\"hljs-string\">'you'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bk\\b'</span>, <span class=\"hljs-string\">'OK'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bsux\\b'</span>, <span class=\"hljs-string\">'sucks'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bno+\\b'</span>, <span class=\"hljs-string\">'no'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n        tweet[<span class=\"hljs-string\">'clean'</span>] = re.sub(<span class=\"hljs-string\">r'\\bcoo+\\b'</span>, <span class=\"hljs-string\">'cool'</span>, tweet[<span class=\"hljs-string\">'clean'</span>])\n\n        <span class=\"hljs-comment\"># Emoticons?</span>\n        <span class=\"hljs-comment\"># <span class=\"hljs-doctag\">NOTE:</span> Turns out that TextBlob already handles emoticons well, so the</span>\n        <span class=\"hljs-comment\"># following is not actually needed.</span>\n        <span class=\"hljs-comment\"># See http://www.datagenetics.com/blog/october52012/index.html</span>\n        <span class=\"hljs-comment\"># tweet['clean'] = re.sub(r'\\b:\\)\\b', 'good', tweet['clean'])</span>\n        <span class=\"hljs-comment\"># tweet['clean'] = re.sub(r'\\b:D\\b', 'good', tweet['clean'])</span>\n        <span class=\"hljs-comment\"># tweet['clean'] = re.sub(r'\\b:\\(\\b', 'sad', tweet['clean'])</span>\n        <span class=\"hljs-comment\"># tweet['clean'] = re.sub(r'\\b:-\\)\\b', 'good', tweet['clean'])</span>\n        <span class=\"hljs-comment\"># tweet['clean'] = re.sub(r'\\b=\\)\\b', 'good', tweet['clean'])</span>\n        <span class=\"hljs-comment\"># tweet['clean'] = re.sub(r'\\b\\(:\\b', 'good', tweet['clean'])</span>\n        <span class=\"hljs-comment\"># tweet['clean'] = re.sub(r'\\b:\\\\\\b', 'annoyed', tweet['clean'])</span>\n\n        <span class=\"hljs-comment\"># Create textblob object</span>\n        tweet[<span class=\"hljs-string\">'TextBlob'</span>] = TextBlob(tweet[<span class=\"hljs-string\">'clean'</span>])\n\n        <span class=\"hljs-comment\"># Correct spelling (WARNING: SLOW)</span>\n        <span class=\"hljs-comment\">#tweet['TextBlob'] = tweet['TextBlob'].correct()</span>\n\n        tweets.append(tweet)\n\n\n\n<span class=\"hljs-comment\"># DEVELOP MODELS</span>\n\n<span class=\"hljs-keyword\"></span><span class=\"hljs-keyword\"></span><span class=\"hljs-keyword\"></span><span class=\"hljs-keyword\"></span><div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\"><span class=\"hljs-keyword\">for</span> tweet <span class=\"hljs-keyword\">in</span> tweets:\n    tweet[<span class=\"hljs-string\">'polarity'</span>] = <span class=\"hljs-built_in\">float</span>(tweet[<span class=\"hljs-string\">'TextBlob'</span>].sentiment.polarity)\n    tweet[<span class=\"hljs-string\">'subjectivity'</span>] = <span class=\"hljs-built_in\">float</span>(tweet[<span class=\"hljs-string\">'TextBlob'</span>].sentiment.subjectivity)\n\n    <span class=\"hljs-keyword\">if</span> tweet[<span class=\"hljs-string\">'polarity'</span>] &gt;= <span class=\"hljs-number\">0.1</span>:\n        tweet[<span class=\"hljs-string\">'sentiment'</span>] = <span class=\"hljs-string\">'positive'</span>\n    <span class=\"hljs-keyword\">elif</span> tweet[<span class=\"hljs-string\">'polarity'</span>] &lt;= -<span class=\"hljs-number\">0.1</span>:\n        tweet[<span class=\"hljs-string\">'sentiment'</span>] = <span class=\"hljs-string\">'negative'</span>\n    <span class=\"hljs-keyword\">else</span>:\n        tweet[<span class=\"hljs-string\">'sentiment'</span>] = <span class=\"hljs-string\">'neutral'</span></div><span class=\"hljs-string\"></span>\n\n<div style=\"display: inline;\" id=\"text_scoring_0\" class=\"highlights fea_text_scoring\">tweets_sorted = <span class=\"hljs-built_in\">sorted</span>(tweets, key=<span class=\"hljs-keyword\">lambda</span> k: k[<span class=\"hljs-string\">'polarity'</span>])</div>\n\n\n<span class=\"hljs-comment\"># EVALUATE RESULTS</span>\n\n<span class=\"hljs-comment\"># First, print out a few example tweets from each sentiment category.</span>\n\n<span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"\\n\\nTOP NEGATIVE TWEETS\"</span>\nnegative_tweets = [d <span class=\"hljs-keyword\">for</span> d <span class=\"hljs-keyword\">in</span> tweets_sorted <span class=\"hljs-keyword\">if</span> d[<span class=\"hljs-string\">'sentiment'</span>] == <span class=\"hljs-string\">'negative'</span>]\n<span class=\"hljs-keyword\">for</span> tweet <span class=\"hljs-keyword\">in</span> negative_tweets[<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">100</span>]:\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"id=%d, polarity=%.2f, clean=%s\"</span> % (tweet[<span class=\"hljs-string\">'id'</span>], tweet[<span class=\"hljs-string\">'polarity'</span>], tweet[<span class=\"hljs-string\">'clean'</span>])\n\n<span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"\\n\\nTOP POSITIVE TWEETS\"</span>\npositive_tweets = [d <span class=\"hljs-keyword\">for</span> d <span class=\"hljs-keyword\">in</span> tweets_sorted <span class=\"hljs-keyword\">if</span> d[<span class=\"hljs-string\">'sentiment'</span>] == <span class=\"hljs-string\">'positive'</span>]\n<span class=\"hljs-keyword\">for</span> tweet <span class=\"hljs-keyword\">in</span> positive_tweets[-<span class=\"hljs-number\">100</span>:]:\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"id=%d, polarity=%.2f, clean=%s\"</span> % (tweet[<span class=\"hljs-string\">'id'</span>], tweet[<span class=\"hljs-string\">'polarity'</span>], tweet[<span class=\"hljs-string\">'clean'</span>])\n\n<span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"\\n\\nTOP NEUTRAL TWEETS\"</span>\nneutral_tweets = [d <span class=\"hljs-keyword\">for</span> d <span class=\"hljs-keyword\">in</span> tweets_sorted <span class=\"hljs-keyword\">if</span> d[<span class=\"hljs-string\">'sentiment'</span>] == <span class=\"hljs-string\">'neutral'</span>]\n<span class=\"hljs-keyword\">for</span> tweet <span class=\"hljs-keyword\">in</span> neutral_tweets[<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">500</span>]:\n    <span class=\"hljs-built_in\">print</span> <span class=\"hljs-string\">\"id=%d, polarity=%.2f, clean=%s\"</span> % (tweet[<span class=\"hljs-string\">'id'</span>], tweet[<span class=\"hljs-string\">'polarity'</span>], tweet[<span class=\"hljs-string\">'clean'</span>])\n\n<span class=\"hljs-comment\">#https://github.com/stepthom/textblob-sentiment-analysis/blob/master/doAnalysis.py</span></code></pre></div>",
    "sec_29.py": "<div class=\"codeBlock hljs python\" id=\"sec_29\"><pre id=\"sec_29_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> time\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">import</span> nltk\n<span class=\"hljs-keyword\">import</span> argparse\n<span class=\"hljs-keyword\">import</span> logging\n<span class=\"hljs-keyword\">import</span> string\n<span class=\"hljs-keyword\">try</span>:\n    <span class=\"hljs-keyword\">import</span> urllib.parse <span class=\"hljs-keyword\">as</span> urlparse\n<span class=\"hljs-keyword\">except</span> ImportError:\n    <span class=\"hljs-keyword\">import</span> urlparse\n<span class=\"hljs-keyword\">from</span> tweepy.streaming <span class=\"hljs-keyword\">import</span> StreamListener\n<span class=\"hljs-keyword\">from</span> tweepy <span class=\"hljs-keyword\">import</span> API, Stream, OAuthHandler, TweepError\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">from</span> vaderSentiment.vaderSentiment <span class=\"hljs-keyword\">import</span> SentimentIntensityAnalyzer\n<span class=\"hljs-keyword\">from</span> bs4 <span class=\"hljs-keyword\">import</span> BeautifulSoup\n<span class=\"hljs-keyword\">from</span> elasticsearch <span class=\"hljs-keyword\">import</span> Elasticsearch\n<span class=\"hljs-keyword\">from</span> random <span class=\"hljs-keyword\">import</span> randint, randrange\n<span class=\"hljs-keyword\">from</span> datetime <span class=\"hljs-keyword\">import</span> datetime\n<span class=\"hljs-keyword\">from</span> newspaper <span class=\"hljs-keyword\">import</span> Article, ArticleException\n\n<span class=\"hljs-comment\"># import elasticsearch host, twitter keys and tokens</span>\n<span class=\"hljs-keyword\">from</span> config <span class=\"hljs-keyword\">import</span> *\n\n\nSTOCKSIGHT_VERSION = <span class=\"hljs-string\">'0.1-b.12'</span>\n__version__ = STOCKSIGHT_VERSION\n\nIS_PY3 = sys.version_info &gt;= (<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">0</span>)\n\n<span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> IS_PY3:\n    print(<span class=\"hljs-string\">\"Sorry, stocksight requires Python 3.\"</span>)\n    sys.exit(<span class=\"hljs-number\">1</span>)\n\n<span class=\"hljs-comment\"># sentiment text-processing url</span>\nsentimentURL = <span class=\"hljs-string\">'http://text-processing.com/api/sentiment/'</span>\n\n<span class=\"hljs-comment\"># tweet id list</span>\ntweet_ids = []\n\n<span class=\"hljs-comment\"># file to hold twitter user ids</span>\ntwitter_users_file = <span class=\"hljs-string\">'./twitteruserids.txt'</span>\n\nprev_time = time.time()\nsentiment_avg = [<span class=\"hljs-number\">0.0</span>,<span class=\"hljs-number\">0.0</span>,<span class=\"hljs-number\">0.0</span>]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">sentiment_analysis</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-string\">\"\"\"Determine if sentiment is positive, negative, or neutral\n    algorithm to figure out if sentiment is positive, negative or neutral\n    uses sentiment polarity from TextBlob, VADER Sentiment and\n    sentiment from text-processing URL\n    could be made better :)\n    \"\"\"</span>\n\n    <span class=\"hljs-comment\"># pass text into sentiment url</span>\n    <span class=\"hljs-keyword\">if</span> args.websentiment:\n        ret = get_sentiment_from_url(text, sentimentURL)\n        <span class=\"hljs-keyword\">if</span> ret <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n            sentiment_url = <span class=\"hljs-literal\">None</span>\n        <span class=\"hljs-keyword\">else</span>:\n            sentiment_url, neg_url, pos_url, neu_url = ret\n    <span class=\"hljs-keyword\">else</span>:\n        sentiment_url = <span class=\"hljs-literal\">None</span>\n\n    <span class=\"hljs-comment\"># pass text into TextBlob</span>\n    text_tb = TextBlob(text)\n\n    <span class=\"hljs-comment\"># pass text into VADER Sentiment</span>\n    analyzer = SentimentIntensityAnalyzer()\n    <div style=\"display: inline;\" id=\"text_scoring_0\" class=\"highlights fea_text_scoring\">text_vs = analyzer.polarity_scores(text)</div>\n\n    <span class=\"hljs-comment\"># determine sentiment from our sources</span>\n    <span class=\"hljs-keyword\"></span><div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\"><span class=\"hljs-keyword\">if</span> sentiment_url <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\n        <span class=\"hljs-keyword\">if</span> text_tb.sentiment.polarity &lt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> text_vs[<span class=\"hljs-string\">'compound'</span>] &lt;= -<span class=\"hljs-number\">0.05</span>:\n            sentiment = <span class=\"hljs-string\">\"negative\"</span>\n        <span class=\"hljs-keyword\">elif</span> text_tb.sentiment.polarity &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> text_vs[<span class=\"hljs-string\">'compound'</span>] &gt;= <span class=\"hljs-number\">0.05</span>:\n            sentiment = <span class=\"hljs-string\">\"positive\"</span>\n        <span class=\"hljs-keyword\">else</span>:\n            sentiment = <span class=\"hljs-string\">\"neutral\"</span>\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">if</span> text_tb.sentiment.polarity &lt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> text_vs[<span class=\"hljs-string\">'compound'</span>] &lt;= -<span class=\"hljs-number\">0.05</span> <span class=\"hljs-keyword\">and</span> sentiment_url == <span class=\"hljs-string\">\"negative\"</span>:\n            sentiment = <span class=\"hljs-string\">\"negative\"</span>\n        <span class=\"hljs-keyword\">elif</span> text_tb.sentiment.polarity &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> text_vs[<span class=\"hljs-string\">'compound'</span>] &gt;= <span class=\"hljs-number\">0.05</span> <span class=\"hljs-keyword\">and</span> sentiment_url == <span class=\"hljs-string\">\"positive\"</span>:\n            sentiment = <span class=\"hljs-string\">\"positive\"</span>\n        <span class=\"hljs-keyword\">else</span>:\n            sentiment = <span class=\"hljs-string\">\"neutral\"</span></div><span class=\"hljs-string\"></span>\n\n    <span class=\"hljs-comment\"># calculate average polarity from TextBlob and VADER</span>\n    polarity = (text_tb.sentiment.polarity + text_vs[<span class=\"hljs-string\">'compound'</span>]) / <span class=\"hljs-number\">2</span>\n\n    <span class=\"hljs-comment\"># output sentiment polarity</span>\n    print(<span class=\"hljs-string\">\"************\"</span>)\n    print(<span class=\"hljs-string\">\"Sentiment Polarity: \"</span> + <span class=\"hljs-built_in\">str</span>(<span class=\"hljs-built_in\">round</span>(polarity, <span class=\"hljs-number\">3</span>)))\n\n    <span class=\"hljs-comment\"># output sentiment subjectivity (TextBlob)</span>\n    print(<span class=\"hljs-string\">\"Sentiment Subjectivity: \"</span> + <span class=\"hljs-built_in\">str</span>(<span class=\"hljs-built_in\">round</span>(text_tb.sentiment.subjectivity, <span class=\"hljs-number\">3</span>)))\n\n    <span class=\"hljs-comment\"># output sentiment</span>\n    print(<span class=\"hljs-string\">\"Sentiment (url): \"</span> + <span class=\"hljs-built_in\">str</span>(sentiment_url))\n    print(<span class=\"hljs-string\">\"Sentiment (algorithm): \"</span> + <span class=\"hljs-built_in\">str</span>(sentiment))\n    print(<span class=\"hljs-string\">\"Overall sentiment (textblob): \"</span>, text_tb.sentiment) \n    print(<span class=\"hljs-string\">\"Overall sentiment (vader): \"</span>, text_vs) \n    print(<span class=\"hljs-string\">\"sentence was rated as \"</span>, <span class=\"hljs-built_in\">round</span>(text_vs[<span class=\"hljs-string\">'neg'</span>]*<span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">3</span>), <span class=\"hljs-string\">\"% Negative\"</span>) \n    print(<span class=\"hljs-string\">\"sentence was rated as \"</span>, <span class=\"hljs-built_in\">round</span>(text_vs[<span class=\"hljs-string\">'neu'</span>]*<span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">3</span>), <span class=\"hljs-string\">\"% Neutral\"</span>) \n    print(<span class=\"hljs-string\">\"sentence was rated as \"</span>, <span class=\"hljs-built_in\">round</span>(text_vs[<span class=\"hljs-string\">'pos'</span>]*<span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">3</span>), <span class=\"hljs-string\">\"% Positive\"</span>) \n    print(<span class=\"hljs-string\">\"************\"</span>)\n\n    <span class=\"hljs-keyword\">return</span> polarity, text_tb.sentiment.subjectivity, sentiment\n<span class=\"hljs-comment\">#https://github.com/shirosaidev/stocksight/blob/master/sentiment.py</span></code></pre></div>",
    "sec_15.py": "<div class=\"codeBlock hljs python\" id=\"sec_15\"><pre id=\"sec_15_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">tweet_sentiment</span>(<span class=\"hljs-params\">text, verbose=<span class=\"hljs-literal\">False</span></span>):</span>\n    <span class=\"hljs-string\">\"\"\"\n    The sentiment function of textblob returns two properties, polarity, and subjectivity.\n    Polarity is float which lies in the range of [-1,1] where 1 means positive statement\n    and -1 means a negative statement.\n    Subjective sentences generally refer to personal opinion, emotion or judgment whereas\n    objective refers to factual information. Subjectivity is also a float which lies in\n    the range of [0,1].\n    \"\"\"</span>\n    <span class=\"hljs-comment\"># parse the tweet into textblob object</span>\n    blob = TextBlob(text)\n    <span class=\"hljs-comment\"># we define the sentiment of sentence to be the product of its polarity and subjectivity</span>\n    <span class=\"hljs-comment\"># tweet sentiment is the sum of sentiment for all sentences in a tweet</span>\n    <div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\">sentiment = <span class=\"hljs-built_in\">sum</span>(s.polarity * s.subjectivity <span class=\"hljs-keyword\">for</span> s <span class=\"hljs-keyword\">in</span> blob.sentences)</div>\n    <span class=\"hljs-comment\"># print if verbose</span>\n    <span class=\"hljs-keyword\">if</span> verbose:\n        polarity = <span class=\"hljs-built_in\">sum</span>(s.polarity <span class=\"hljs-keyword\">for</span> s <span class=\"hljs-keyword\">in</span> blob.sentences)\n        subjectivity = <span class=\"hljs-built_in\">sum</span>(s.subjectivity <span class=\"hljs-keyword\">for</span> s <span class=\"hljs-keyword\">in</span> blob.sentences)\n        num_sentence = <span class=\"hljs-built_in\">len</span>(blob.sentences)\n        <span class=\"hljs-keyword\">return</span> text, num_sentence, polarity, subjectivity, sentiment\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-keyword\">return</span> sentiment\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">test</span>():</span>\n    sentences = [\n        <span class=\"hljs-string\">'$AAPL so is this the price that gets split? If so, looks like itll be $125.50 a share on Monday. Nice.'</span>,\n        <span class=\"hljs-string\">'Stocks head into September in high gear as Apple and Tesla split, and markets await the August jobs report'</span>,\n        <span class=\"hljs-string\">'S&amp;P 500 SETS FRESH RECORD CLOSING HIGH OF 3,508.01'</span>,\n        <span class=\"hljs-string\">'Massive $tsla dump be careful out there short term oversold tho $spy $amzn'</span>,\n        <span class=\"hljs-string\">'$SPX is overbought but momentum is very very strong. My bet is unless we correct quickly this week, we are looking for a blow off top. '</span>,\n        <span class=\"hljs-string\">'$SPY reached 350 2 points from our target of 352.. RSI is overbought - sell and wait ti buy for later. Short $SHOP and $NVAX.'</span>,\n        <span class=\"hljs-string\">'Slight setback, nothing to worry about. Outlook dismal. 28 trade session left - Target $SPX 2394.25'</span>,\n        <span class=\"hljs-string\">'Russell looks bad. Big bearish RSI divergence and ejected from the channel after riding up the bottom rail.'</span>,\n    ]\n    print(<span class=\"hljs-string\">' | '</span>.join([<span class=\"hljs-string\">''</span>,<span class=\"hljs-string\">' #'</span>,<span class=\"hljs-string\">'Sentence'</span>+<span class=\"hljs-string\">' '</span>*<span class=\"hljs-number\">92</span>,<span class=\"hljs-string\">'# sentence'</span>,<span class=\"hljs-string\">'polarity'</span>,<span class=\"hljs-string\">'subjectivity'</span>,<span class=\"hljs-string\">'sentiment'</span>,<span class=\"hljs-string\">''</span>]))\n    print(<span class=\"hljs-string\">'-'</span>*<span class=\"hljs-number\">162</span>)\n    <span class=\"hljs-keyword\">for</span> i,sentence <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(sentences):\n        text, num_sentence, polarity, subjectivity, sentiment = tweet_sentiment(sentence, verbose=<span class=\"hljs-literal\">True</span>)\n        print(<span class=\"hljs-string\">f' | <span class=\"hljs-subst\">{i+<span class=\"hljs-number\">1</span>:2d}</span> | <span class=\"hljs-subst\">{text[:<span class=\"hljs-number\">100</span>]: &lt;<span class=\"hljs-number\">100</span>}</span> | <span class=\"hljs-subst\">{num_sentence: &gt;<span class=\"hljs-number\">10</span>}</span> | <span class=\"hljs-subst\">{polarity:+<span class=\"hljs-number\">8.2</span>f}</span> | <span class=\"hljs-subst\">{subjectivity:+<span class=\"hljs-number\">12.2</span>f}</span> | <span class=\"hljs-subst\">{sentiment:+<span class=\"hljs-number\">9.2</span>f}</span> |'</span>)\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    test()\n    <span class=\"hljs-comment\">#https://github.com/quantumsnowball/AppleDaily20200907/blob/master/sentiment.py</span></code></pre></div>",
    "sec_20.py": "<div class=\"codeBlock hljs python\" id=\"sec_20\"><pre id=\"sec_20_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> random\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> csv\n<span class=\"hljs-keyword\">import</span> string\n<span class=\"hljs-keyword\">import</span> operator\n\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">from</span> textblob.classifiers <span class=\"hljs-keyword\">import</span> NaiveBayesClassifier <span class=\"hljs-comment\"># update sentiment, if textblob returns neutral</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">determineSentiment</span>(<span class=\"hljs-params\">sent_dict</span>):</span>\n\t<span class=\"hljs-comment\"># takes in a dictionary or sub-dictionary to return the sentiment in a list</span>\n\tfinal_sent_dict = {}\n\tsentence_list = []\n\t<span class=\"hljs-keyword\">for</span> speech <span class=\"hljs-keyword\">in</span> sent_dict:\n\t\ttext_sent = TextBlob(sent_dict[speech])\n\t\t<span class=\"hljs-comment\">#text_tag = text_sent.tags</span>\n\t\tcounter = <span class=\"hljs-number\">1</span>\n\t\t<span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> text_sent.sentences:\n\t\t\t<span class=\"hljs-comment\">#print(speech)</span>\n\t\t\tfinal_sent_dict[speech + <span class=\"hljs-string\">'_'</span> + <span class=\"hljs-built_in\">str</span>(counter)] = (sentence.sentiment, sentence)\n\t\t\tcounter += <span class=\"hljs-number\">1</span> <span class=\"hljs-comment\"># each sub-sentence in a speech has it's own dictionary key</span>\n\t<div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\">final_sent_dict[<span class=\"hljs-string\">\"_average\"</span>] = text_sent.sentiment</div> <span class=\"hljs-comment\"># beginning of an ordered dict</span>\n\t<span class=\"hljs-keyword\">return</span> final_sent_dict\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">trainSentiment</span>():</span>\n\t<span class=\"hljs-comment\"># if the sentence is neutral, update to attribute sentiment based on key words</span>\n\t<span class=\"hljs-comment\"># example: villian -&gt; negative, dying -&gt; negative, etc...</span>\n\t<span class=\"hljs-comment\"># https://textblob.readthedocs.io/en/dev/classifiers.html#classifiers</span>\n\n\t<span class=\"hljs-comment\"># train classifers on actual hamlet data</span>\n\thamlet_train = [\n\t<span class=\"hljs-comment\"># act 1</span>\n\t\t(<span class=\"hljs-string\">'this dreaded sight'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'o god!'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'o fie!'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'break my heart,  for i must hold my tongue!'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'funeral'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'he was a man,  take him for all in all, i shall not look upon his like again'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'i doubt some foul play would the night were come!'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'foul deeds will rise'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'pooh!'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'angels and ministers of grace defend us!'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'you shall not go'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'hold off your hands'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'my fate cries out'</span> , <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">\"i'll make a ghost of him that lets me\"</span> , <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'something is rotten in the state of denmark'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'harrow up thy soul'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'revenge'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'incest'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'adulterate'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'beast'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'lust'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'a serpent stung me'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'villain'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'perturbed spirit!'</span>, <span class=\"hljs-string\">'neg'</span>)\n\t]\n\n\thamlet_test = [\n\t<span class=\"hljs-comment\"># act 2</span>\n\t\t(<span class=\"hljs-string\">'dishonour'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'taints of liberty'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'flash and outbreak of a fiery mind'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'falsehood'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'fouled'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'piteous'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'i do not know'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'i do fear it'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'madness wherein now he raves'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'madness'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'indifferent children of the earth'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'beggars bodies'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'murder'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'that he should weep for her?'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'am i a coward?'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t\t(<span class=\"hljs-string\">'who calls me villain?'</span>, <span class=\"hljs-string\">'neg'</span>),\n\t]\n\t<div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">cl = NaiveBayesClassifier(hamlet_train)</div>\n\t<span class=\"hljs-keyword\">return</span> cl\n\t<span class=\"hljs-comment\">#https://github.com/cyschneck/Billy-Bot/blob/master/shakespeare_sentiment.py</span></code></pre></div>",
    "sec_21.py": "<div class=\"codeBlock hljs python\" id=\"sec_21\"><pre id=\"sec_21_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> TwitterSearch <span class=\"hljs-keyword\">import</span> *\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">import</span> sys\nreload(sys)\nsys.setdefaultencoding(<span class=\"hljs-string\">'utf8'</span>)\n\nfilepath = <span class=\"hljs-string\">\"2017.txt\"</span>\n<span class=\"hljs-keyword\">try</span>:\n\tfp = <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"2017.txt\"</span>,<span class=\"hljs-string\">\"r\"</span>)\n\tdi = { }\n\t<span class=\"hljs-keyword\">for</span> line <span class=\"hljs-keyword\">in</span> fp.read().splitlines():\n\t\tcnt = <span class=\"hljs-number\">0</span>\n\t\tscore = <span class=\"hljs-number\">0</span>\n\t\ttemp = <span class=\"hljs-number\">0</span>;\n\t\t<span class=\"hljs-comment\">#print line</span>\n\t\n\t\t\n\t\ttso = TwitterSearchOrder() \n\t\ttso.set_keywords([line]) \n\t\ttso.set_language(<span class=\"hljs-string\">'en'</span>) \n\t\ttso.set_include_entities(<span class=\"hljs-literal\">False</span>)\n\t\ttso.set_count(<span class=\"hljs-number\">100</span>)\n\n<span class=\"hljs-comment\"># it's about time to create a TwitterSearch object with our secret tokens</span>\n\t\tts = TwitterSearch(\n\t\t\t\tconsumer_key = <span class=\"hljs-string\">\"XXXX\"</span>,\n        \t\tconsumer_secret = <span class=\"hljs-string\">\"YY\"</span>,\n        \t\taccess_token = <span class=\"hljs-string\">\"ZZ\"</span>,\n        \t\taccess_token_secret = <span class=\"hljs-string\">\"MM\"</span>\n\t\t )\n\n\n <span class=\"hljs-comment\"># this is where the fun actually starts :)</span>\n\t\t<span class=\"hljs-keyword\">for</span> tweet <span class=\"hljs-keyword\">in</span> ts.search_tweets_iterable(tso):\n\t\t\t<span class=\"hljs-keyword\">if</span>(cnt&lt;<span class=\"hljs-number\">20</span>):\n\t\t\t\t<div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\">analysis = TextBlob(tweet[<span class=\"hljs-string\">'text'</span>])\n\t\t\t\tcnt=cnt+<span class=\"hljs-number\">1</span>;\n\t\t\t\ttemp = temp+<span class=\"hljs-number\">1</span>;\n\t\t\t\t<span class=\"hljs-keyword\">if</span> analysis.sentiment.polarity &gt; <span class=\"hljs-number\">0</span>:\n\t\t\t\t\t<span class=\"hljs-comment\">#print '1'</span>\n\t\t\t\t\tscore=score+<span class=\"hljs-number\">1</span>\n\t\t\t\t<span class=\"hljs-keyword\">elif</span> analysis.sentiment.polarity == <span class=\"hljs-number\">0</span>:\n\t\t\t\t\t<span class=\"hljs-comment\">#print '0'</span>\n\t\t\t\t\tscore = score;\n\t\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\t\tscore=score-<span class=\"hljs-number\">1</span></div><span class=\"hljs-number\"></span>\n\t\t\t<span class=\"hljs-keyword\">else</span>:\n\t\t\t\t<span class=\"hljs-keyword\">break</span>\n\t<span class=\"hljs-comment\">#F.write(tweet['text'])</span>\n\t\t\t<span class=\"hljs-comment\">#print(tweet['text'])</span>\n\t\tx = <span class=\"hljs-built_in\">float</span>(score)/<span class=\"hljs-built_in\">float</span>(temp)\n\t\t<span class=\"hljs-comment\">#print x</span>\n\t\tdi.update({line : x})\n\td_view = [ (v,k) <span class=\"hljs-keyword\">for</span> k,v <span class=\"hljs-keyword\">in</span> di.iteritems() ]\n\td_view.sort(reverse=<span class=\"hljs-literal\">True</span>) <span class=\"hljs-comment\"># natively sort tuples by first element</span>\n\t<span class=\"hljs-keyword\">for</span> v,k <span class=\"hljs-keyword\">in</span> d_view:\n\t\t\t<span class=\"hljs-built_in\">print</span> v, k\n\t\t\n<span class=\"hljs-keyword\">except</span> TwitterSearchException <span class=\"hljs-keyword\">as</span> e: <span class=\"hljs-comment\"># take care of all those ugly errors if there are some</span>\n\tprint(e)\n\t<span class=\"hljs-comment\">#https://github.com/avaiyang/Movie-Rating-and-Prediction-Model/blob/master/twittersearch.py</span></code></pre></div>",
    "sec_24.py": "<div class=\"codeBlock hljs python\" id=\"sec_24\"><pre id=\"sec_24_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">from</span> datetime <span class=\"hljs-keyword\">import</span> datetime, timedelta\n<span class=\"hljs-keyword\">from</span> pickle <span class=\"hljs-keyword\">import</span> load\n\n<span class=\"hljs-keyword\">import</span> pytz\n<span class=\"hljs-keyword\">from</span> flask <span class=\"hljs-keyword\">import</span> Flask, jsonify, redirect, render_template, request, session, url_for\n<span class=\"hljs-keyword\">from</span> flask_sqlalchemy <span class=\"hljs-keyword\">import</span> SQLAlchemy\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n\n<span class=\"hljs-keyword\">from</span> model_nltk <span class=\"hljs-keyword\">import</span> predict_sentiment\n\napp = Flask(__name__, template_folder=<span class=\"hljs-string\">\"templates\"</span>)\n\n<span class=\"hljs-comment\"># \"sqlite:///data.sqlite\"</span>\n<span class=\"hljs-comment\"># /// for relative path</span>\n<span class=\"hljs-comment\"># //// for absolute path</span>\napp.config[<span class=\"hljs-string\">\"SQLALCHEMY_DATABASE_URI\"</span>] = os.environ.get(\n    <span class=\"hljs-string\">\"DATABASE_URL\"</span>, <span class=\"hljs-string\">\"sqlite:///data.sqlite\"</span>\n)\napp.config[<span class=\"hljs-string\">\"SQLALCHEMY_TRACK_MODIFICATIONS\"</span>] = <span class=\"hljs-literal\">False</span>\napp.config[<span class=\"hljs-string\">\"SECRET_KEY\"</span>] = os.environ.get(<span class=\"hljs-string\">\"SECRET_KEY\"</span>, <span class=\"hljs-string\">\"thisissecret\"</span>)\napp.config[<span class=\"hljs-string\">\"PERMANENT_SESSION_LIFETIME\"</span>] = timedelta(hours=<span class=\"hljs-number\">12</span>)\n\ndb = SQLAlchemy(app)\n\n<span class=\"hljs-comment\"># since the app is hosted on heroku so this line of code is to change the timezone</span>\nIST = pytz.timezone(<span class=\"hljs-string\">\"Asia/Kolkata\"</span>)\n\n\n<span class=\"hljs-comment\"># I have creted two models but I am using model_nltk because of its high accurcy and less execution time.</span>\n<span class=\"hljs-comment\"># textblob is used for ploting the subjectivity and polarity curve for the input data</span>\n\n<span class=\"hljs-comment\"># class for creating and initialising database</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">New_Data</span>(<span class=\"hljs-params\">db.Model</span>):</span>\n\n    Id = db.Column(db.Integer, primary_key=<span class=\"hljs-literal\">True</span>)\n    Text = db.Column(db.Text)\n    Sentiment = db.Column(db.String(<span class=\"hljs-number\">20</span>))\n    <span class=\"hljs-comment\"># .now(IST).strftime('%Y-%m-%d %H:%M:%S'))</span>\n    Date = db.Column(\n        db.DateTime, default=datetime.now(IST).strftime(<span class=\"hljs-string\">\"%Y-%m-%d %H:%M:%S\"</span>)\n    )\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, Text, Sentiment</span>):</span>\n        self.Text = Text\n        self.Sentiment = Sentiment\n\n\n<span class=\"hljs-comment\"># loading classifier</span>\n<span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"my_classifier.pickle\"</span>, <span class=\"hljs-string\">\"rb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n    classifier = load(f)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">allowed_file</span>(<span class=\"hljs-params\">filename</span>):</span>\n    <span class=\"hljs-string\">\"\"\"Checking file extension i.e. text file or not\"\"\"</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\".\"</span> <span class=\"hljs-keyword\">in</span> filename <span class=\"hljs-keyword\">and</span> filename.split(<span class=\"hljs-string\">\".\"</span>)[<span class=\"hljs-number\">1</span>] == <span class=\"hljs-string\">\"txt\"</span>\n\n\n<span class=\"hljs-comment\"># route for home page</span>\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/\"</span>, methods=[<span class=\"hljs-string\">\"POST\"</span>, <span class=\"hljs-string\">\"GET\"</span>]</span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">home</span>():</span>\n    <span class=\"hljs-keyword\">if</span> request.method == <span class=\"hljs-string\">\"POST\"</span>:\n        sentence = <span class=\"hljs-built_in\">str</span>(request.form.get(<span class=\"hljs-string\">\"twt\"</span>))\n\n        <div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\">sentiment = predict_sentiment(sentence, classifier)</div>\n\n        <span class=\"hljs-comment\"># adding emoji to the sentiment</span>\n        <span class=\"hljs-keyword\">if</span> sentiment == <span class=\"hljs-string\">\"Positive\"</span>:\n            sentiment += <span class=\"hljs-string\">\" \\U0001f600\"</span>\n\n        <span class=\"hljs-keyword\">elif</span> sentiment == <span class=\"hljs-string\">\"Negative\"</span>:\n            sentiment += <span class=\"hljs-string\">\" \\U0001F641\"</span>\n\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-keyword\">pass</span>\n\n        <span class=\"hljs-comment\"># creating an instance of the data table for the database and commiting the changes</span>\n        usr_data = New_Data(sentence, sentiment.split()[<span class=\"hljs-number\">0</span>])\n        <span class=\"hljs-keyword\">try</span>:\n            db.session.add(usr_data)\n            db.session.commit()\n        <span class=\"hljs-keyword\">except</span>:\n            <span class=\"hljs-keyword\">pass</span>\n\n        text = <span class=\"hljs-string\">'You have entered \"'</span> + sentence + <span class=\"hljs-string\">'\"'</span>\n        <span class=\"hljs-keyword\">return</span> render_template(\n            <span class=\"hljs-string\">\"index.html\"</span>, text=text, sentiment=<span class=\"hljs-string\">\"Sentiment: \"</span> + sentiment\n        )\n\n    <span class=\"hljs-keyword\">return</span> render_template(<span class=\"hljs-string\">\"index.html\"</span>)\n\n\n<span class=\"hljs-comment\"># route for about page</span>\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/about\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">about</span>():</span>\n    <span class=\"hljs-keyword\">return</span> render_template(<span class=\"hljs-string\">\"about.html\"</span>)\n\n\n<span class=\"hljs-comment\"># route for members page</span>\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/member\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">contact</span>():</span>\n    <span class=\"hljs-keyword\">return</span> render_template(<span class=\"hljs-string\">\"members.html\"</span>)\n\n\n<span class=\"hljs-comment\"># route for fastapi</span>\n<span class=\"hljs-comment\"># setting default value for the api</span>\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/fast-api/\"</span>, defaults={<span class=\"hljs-string\">\"sentence\"</span>: <span class=\"hljs-string\">\"Great\"</span>}</span>)</span>\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/fast-api/&lt;sentence&gt;\"</span></span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">fast_api</span>(<span class=\"hljs-params\">sentence</span>):</span>\n    sentiment = predict_sentiment(sentence, classifier)\n\n    <span class=\"hljs-keyword\">return</span> jsonify({<span class=\"hljs-string\">\"sentence\"</span>: sentence, <span class=\"hljs-string\">\"sentiment\"</span>: sentiment})\n\n\n<span class=\"hljs-comment\"># setting post method for the api</span>\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">\"/fastapi\"</span>, methods=[<span class=\"hljs-string\">\"POST\"</span>]</span>)</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">fastapi</span>():</span>\n    text = request.form[<span class=\"hljs-string\">\"text\"</span>]\n    <div style=\"display: inline;\" id=\"sentiment_analysis_1\" class=\"highlights fea_sentiment_analysis\">polarity = TextBlob(text).sentiment.polarity\n    <span class=\"hljs-keyword\">if</span> polarity &gt; <span class=\"hljs-number\">0</span>:\n        sentiment = <span class=\"hljs-string\">\"Positive\"</span>\n    <span class=\"hljs-keyword\">elif</span> polarity &lt; <span class=\"hljs-number\">0</span>:\n        sentiment = <span class=\"hljs-string\">\"Negative\"</span>\n    <span class=\"hljs-keyword\">else</span>:\n        sentiment = <span class=\"hljs-string\">\"Neutral\"</span>\n    <span class=\"hljs-keyword\">return</span> jsonify({<span class=\"hljs-string\">\"sentiment\"</span>: sentiment})</div>\n<span class=\"hljs-comment\">#https://github.com/g-paras/sentiment-analysis-api/blob/master/app.py</span></code></pre></div>",
    "sec_25.py": "<div class=\"codeBlock hljs python\" id=\"sec_25\"><pre id=\"sec_25_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> facebook <span class=\"hljs-keyword\">as</span> fb\n<span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">import</span> argparse\n<span class=\"hljs-keyword\">import</span> textblob <span class=\"hljs-keyword\">as</span> tb\n\nFLAGS = <span class=\"hljs-literal\">None</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">sentiment_analysis</span>(<span class=\"hljs-params\">post</span>):</span>\n\n    <span class=\"hljs-comment\"># Here's where the magic happens</span>\n    <div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\">tb_msg = tb(post[<span class=\"hljs-string\">'message'</span>])\n    score = tb_msg.sentiment</div>\n\n    print(<span class=\"hljs-string\">\"Date: %s, From: %s\\n\"</span>, post[<span class=\"hljs-string\">'created_time'</span>], post[<span class=\"hljs-string\">'from'</span>])\n    print(<span class=\"hljs-string\">\"%s\\nShared: %s, Score: %f\"</span>, post[<span class=\"hljs-string\">'message'</span>], post[<span class=\"hljs-string\">'share'</span>], score)\n\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">connect</span>(<span class=\"hljs-params\">access_token, user</span>):</span>\n    graph = fb.GraphAPI(access_token)\n    profile = graph.get_object(user)\n\n    <span class=\"hljs-keyword\">return</span> graph, profile\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">main</span>():</span>\n\n    access_token = FLAGS.access_token\n    user = FLAGS.profile\n\n    graph, profile = connect(access_token, user)\n    \n    posts = graph.get_connections(profile[<span class=\"hljs-string\">'id'</span>], <span class=\"hljs-string\">'posts'</span>)\n\n\n    <span class=\"hljs-comment\">#Let's grab all the posts and analyze them!</span>\n    <span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n        <span class=\"hljs-keyword\">try</span>:\n            [sentiment_analysis(post=post) <span class=\"hljs-keyword\">for</span> post <span class=\"hljs-keyword\">in</span> posts[<span class=\"hljs-string\">'data'</span>]]\n            posts= requests.get(posts[<span class=\"hljs-string\">'paging'</span>][<span class=\"hljs-string\">'next'</span>]).json()\n        <span class=\"hljs-keyword\">except</span> KeyError:\n            <span class=\"hljs-keyword\">break</span>\n            \n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    parser = argparse.ArgumentParser(description=<span class=\"hljs-string\">'Simple Facebook Sentiment Analysis Script'</span>)\n    parser.add_argument(<span class=\"hljs-string\">'--access_token'</span>, <span class=\"hljs-built_in\">type</span>=<span class=\"hljs-built_in\">str</span>, required=<span class=\"hljs-literal\">True</span>, default=<span class=\"hljs-string\">''</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'Your Facebook API Access Token: https://developers.facebook.com/docs/graph-api/overview'</span>)\n    parser.add_argument(<span class=\"hljs-string\">'--profile'</span>, <span class=\"hljs-built_in\">type</span>=<span class=\"hljs-built_in\">str</span>, required=<span class=\"hljs-literal\">True</span>, default=<span class=\"hljs-string\">''</span>, <span class=\"hljs-built_in\">help</span>=<span class=\"hljs-string\">'The profile name to retrieve the posts from'</span>)\n    FLAGS = parser.parse_args()\n    main()\n    <span class=\"hljs-comment\">#https://github.com/cosimoiaia/Facebook-Sentiment-Analysis/blob/master/simple_facebook_sentiment_analysis.py</span></code></pre></div>",
    "sec_28.py": "<div class=\"codeBlock hljs python\" id=\"sec_28\"><pre id=\"sec_28_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> tweepy\n<span class=\"hljs-keyword\">from</span> tweepy <span class=\"hljs-keyword\">import</span> OAuthHandler\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n \n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">TwitterClient</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-string\">'''\n    Generic Twitter Class for sentiment analysis.\n    '''</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span>\n        <span class=\"hljs-string\">'''\n        Class constructor or initialization method.\n        '''</span>\n       \n        consumer_key = <span class=\"hljs-string\">'XXXXXXXXXXXX'</span>\n        consumer_secret = <span class=\"hljs-string\">'XXXXXXXXXXXX'</span>\n        access_token = <span class=\"hljs-string\">'XXXXXXXXXXXX'</span>\n        access_token_secret = <span class=\"hljs-string\">'XXXXXXXXXXXX'</span>\n \n       \n        <span class=\"hljs-keyword\">try</span>:\n         \n            self.auth = OAuthHandler(consumer_key, consumer_secret)\n         \n            self.auth.set_access_token(access_token, access_token_secret)\n        \n            self.api = tweepy.API(self.auth)\n        <span class=\"hljs-keyword\">except</span>:\n            print(<span class=\"hljs-string\">\"Error: Authentication Failed\"</span>)\n \n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">clean_tweet</span>(<span class=\"hljs-params\">self, tweet</span>):</span>\n        <span class=\"hljs-string\">'''\n        Utility function to clean tweet text by removing links, special characters\n        using simple regex statements.\n        '''</span>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">' '</span>.join(re.sub(<span class=\"hljs-string\">\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"</span>, <span class=\"hljs-string\">\" \"</span>, tweet).split())\n \n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_tweet_sentiment</span>(<span class=\"hljs-params\">self, tweet</span>):</span>\n        <span class=\"hljs-string\">'''\n        Utility function to classify sentiment of passed tweet\n        using textblob's sentiment method\n        '''</span>\n        \n        <div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\">analysis = TextBlob(self.clean_tweet(tweet))\n       \n        <span class=\"hljs-keyword\">if</span> analysis.sentiment.polarity &gt; <span class=\"hljs-number\">0</span>:\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">'positive'</span>\n        <span class=\"hljs-keyword\">elif</span> analysis.sentiment.polarity == <span class=\"hljs-number\">0</span>:\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">'neutral'</span>\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">'negative'</span></div><span class=\"hljs-string\"></span>\n    <span class=\"hljs-comment\">#https://github.com/vinitshahdeo/jobtweets/blob/master/jobtweets.py</span></code></pre></div>",
    "sec_30.py": "<div class=\"codeBlock hljs python\" id=\"sec_30\"><pre id=\"sec_30_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> sys,tweepy,csv,re\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> thr\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">SentimentAnalysis</span>:</span>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span>\n        self.tweets = []\n        self.tweetText = []\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">DownloadData</span>(<span class=\"hljs-params\">self</span>):</span>\n        <span class=\"hljs-comment\"># authenticating</span>\n        consumerKey = <span class=\"hljs-string\">'your key here'</span>\n        consumerSecret = <span class=\"hljs-string\">'your key here'</span>\n        accessToken = <span class=\"hljs-string\">'your key here'</span>\n        accessTokenSecret = <span class=\"hljs-string\">'your key here'</span>\n        auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n        auth.set_access_token(accessToken, accessTokenSecret)\n        api = tweepy.API(auth)\n\n        <span class=\"hljs-comment\"># input for term to be searched and how many tweets to search</span>\n        searchTerm = <span class=\"hljs-built_in\">input</span>(<span class=\"hljs-string\">\"Enter Keyword/Tag to search about: \"</span>)\n        NoOfTerms = <span class=\"hljs-built_in\">int</span>(<span class=\"hljs-built_in\">input</span>(<span class=\"hljs-string\">\"Enter how many tweets to search: \"</span>))\n\n        <span class=\"hljs-comment\"># searching for tweets</span>\n        self.tweets = tweepy.Cursor(api.search, q=searchTerm, lang = <span class=\"hljs-string\">\"en\"</span>).items(NoOfTerms)\n\n        <span class=\"hljs-comment\"># Open/create a file to append data to</span>\n        csvFile = <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">'result.csv'</span>, <span class=\"hljs-string\">'a'</span>)\n\n        <span class=\"hljs-comment\"># Use csv writer</span>\n        csvWriter = csv.writer(csvFile)\n\n\n        <span class=\"hljs-comment\"># creating some variables to store info</span>\n        polarity = <span class=\"hljs-number\">0</span>\n        positive = <span class=\"hljs-number\">0</span>\n        wpositive = <span class=\"hljs-number\">0</span>\n        spositive = <span class=\"hljs-number\">0</span>\n        negative = <span class=\"hljs-number\">0</span>\n        wnegative = <span class=\"hljs-number\">0</span>\n        snegative = <span class=\"hljs-number\">0</span>\n        neutral = <span class=\"hljs-number\">0</span>\n\n\n        <span class=\"hljs-comment\"># iterating through tweets fetched</span>\n        <span class=\"hljs-keyword\">for</span> tweet <span class=\"hljs-keyword\">in</span> self.tweets:\n            <span class=\"hljs-comment\">#Append to temp so that we can store in csv later. I use encode UTF-8</span>\n            self.tweetText.append(self.cleanTweet(tweet.text).encode(<span class=\"hljs-string\">'utf-8'</span>))\n            <span class=\"hljs-comment\"># print (tweet.text.translate(non_bmp_map))    #print tweet's text</span>\n            analysis = TextBlob(tweet.text)\n            <span class=\"hljs-comment\"># print(analysis.sentiment)  # print tweet's polarity</span>\n            <div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\">polarity += analysis.sentiment.polarity</div>  <span class=\"hljs-comment\"># adding up polarities to find the average later</span>\n\n            <span class=\"hljs-keyword\">if</span> (analysis.sentiment.polarity == <span class=\"hljs-number\">0</span>):  <span class=\"hljs-comment\"># adding reaction of how people are reacting to find average later</span>\n                neutral += <span class=\"hljs-number\">1</span>\n            <span class=\"hljs-keyword\">elif</span> (analysis.sentiment.polarity &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> analysis.sentiment.polarity &lt;= <span class=\"hljs-number\">0.3</span>):\n                wpositive += <span class=\"hljs-number\">1</span>\n            <span class=\"hljs-keyword\">elif</span> (analysis.sentiment.polarity &gt; <span class=\"hljs-number\">0.3</span> <span class=\"hljs-keyword\">and</span> analysis.sentiment.polarity &lt;= <span class=\"hljs-number\">0.6</span>):\n                positive += <span class=\"hljs-number\">1</span>\n            <span class=\"hljs-keyword\">elif</span> (analysis.sentiment.polarity &gt; <span class=\"hljs-number\">0.6</span> <span class=\"hljs-keyword\">and</span> analysis.sentiment.polarity &lt;= <span class=\"hljs-number\">1</span>):\n                spositive += <span class=\"hljs-number\">1</span>\n            <span class=\"hljs-keyword\">elif</span> (analysis.sentiment.polarity &gt; -<span class=\"hljs-number\">0.3</span> <span class=\"hljs-keyword\">and</span> analysis.sentiment.polarity &lt;= <span class=\"hljs-number\">0</span>):\n                wnegative += <span class=\"hljs-number\">1</span>\n            <span class=\"hljs-keyword\">elif</span> (analysis.sentiment.polarity &gt; -<span class=\"hljs-number\">0.6</span> <span class=\"hljs-keyword\">and</span> analysis.sentiment.polarity &lt;= -<span class=\"hljs-number\">0.3</span>):\n                negative += <span class=\"hljs-number\">1</span>\n            <span class=\"hljs-keyword\">elif</span> (analysis.sentiment.polarity &gt; -<span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">and</span> analysis.sentiment.polarity &lt;= -<span class=\"hljs-number\">0.6</span>):\n                snegative += <span class=\"hljs-number\">1</span>\n\n\n        <span class=\"hljs-comment\"># Write to csv and close csv file</span>\n        csvWriter.writerow(self.tweetText)\n        csvFile.close()\n\n        <span class=\"hljs-comment\"># finding average of how people are reacting</span>\n        positive = self.percentage(positive, NoOfTerms)\n        wpositive = self.percentage(wpositive, NoOfTerms)\n        spositive = self.percentage(spositive, NoOfTerms)\n        negative = self.percentage(negative, NoOfTerms)\n        wnegative = self.percentage(wnegative, NoOfTerms)\n        snegative = self.percentage(snegative, NoOfTerms)\n        neutral = self.percentage(neutral, NoOfTerms)\n\n        <span class=\"hljs-comment\"># finding average reaction</span>\n        polarity = polarity / NoOfTerms\n\n        <span class=\"hljs-comment\"># printing out data</span>\n        print(<span class=\"hljs-string\">\"How people are reacting on \"</span> + searchTerm + <span class=\"hljs-string\">\" by analyzing \"</span> + <span class=\"hljs-built_in\">str</span>(NoOfTerms) + <span class=\"hljs-string\">\" tweets.\"</span>)\n        print()\n        print(<span class=\"hljs-string\">\"General Report: \"</span>)\n\n        <span class=\"hljs-keyword\">if</span> (polarity == <span class=\"hljs-number\">0</span>):\n            print(<span class=\"hljs-string\">\"Neutral\"</span>)\n        <span class=\"hljs-keyword\">elif</span> (polarity &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> polarity &lt;= <span class=\"hljs-number\">0.3</span>):\n            print(<span class=\"hljs-string\">\"Weakly Positive\"</span>)\n        <span class=\"hljs-keyword\">elif</span> (polarity &gt; <span class=\"hljs-number\">0.3</span> <span class=\"hljs-keyword\">and</span> polarity &lt;= <span class=\"hljs-number\">0.6</span>):\n            print(<span class=\"hljs-string\">\"Positive\"</span>)\n        <span class=\"hljs-keyword\">elif</span> (polarity &gt; <span class=\"hljs-number\">0.6</span> <span class=\"hljs-keyword\">and</span> polarity &lt;= <span class=\"hljs-number\">1</span>):\n            print(<span class=\"hljs-string\">\"Strongly Positive\"</span>)\n        <span class=\"hljs-keyword\">elif</span> (polarity &gt; -<span class=\"hljs-number\">0.3</span> <span class=\"hljs-keyword\">and</span> polarity &lt;= <span class=\"hljs-number\">0</span>):\n            print(<span class=\"hljs-string\">\"Weakly Negative\"</span>)\n        <span class=\"hljs-keyword\">elif</span> (polarity &gt; -<span class=\"hljs-number\">0.6</span> <span class=\"hljs-keyword\">and</span> polarity &lt;= -<span class=\"hljs-number\">0.3</span>):\n            print(<span class=\"hljs-string\">\"Negative\"</span>)\n        <span class=\"hljs-keyword\">elif</span> (polarity &gt; -<span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">and</span> polarity &lt;= -<span class=\"hljs-number\">0.6</span>):\n            print(<span class=\"hljs-string\">\"Strongly Negative\"</span>)\n\n        print()\n        print(<span class=\"hljs-string\">\"Detailed Report: \"</span>)\n        print(<span class=\"hljs-built_in\">str</span>(positive) + <span class=\"hljs-string\">\"% people thought it was positive\"</span>)\n        print(<span class=\"hljs-built_in\">str</span>(wpositive) + <span class=\"hljs-string\">\"% people thought it was weakly positive\"</span>)\n        print(<span class=\"hljs-built_in\">str</span>(spositive) + <span class=\"hljs-string\">\"% people thought it was strongly positive\"</span>)\n        print(<span class=\"hljs-built_in\">str</span>(negative) + <span class=\"hljs-string\">\"% people thought it was negative\"</span>)\n        print(<span class=\"hljs-built_in\">str</span>(wnegative) + <span class=\"hljs-string\">\"% people thought it was weakly negative\"</span>)\n        print(<span class=\"hljs-built_in\">str</span>(snegative) + <span class=\"hljs-string\">\"% people thought it was strongly negative\"</span>)\n        print(<span class=\"hljs-built_in\">str</span>(neutral) + <span class=\"hljs-string\">\"% people thought it was neutral\"</span>)\n\n        self.plotPieChart(positive, wpositive, spositive, negative, wnegative, snegative, neutral, searchTerm, NoOfTerms)\n\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">cleanTweet</span>(<span class=\"hljs-params\">self, tweet</span>):</span>\n        <span class=\"hljs-comment\"># Remove Links, Special Characters etc from tweet</span>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">' '</span>.join(re.sub(<span class=\"hljs-string\">\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) | (\\w +:\\ / \\ / \\S +)\"</span>, <span class=\"hljs-string\">\" \"</span>, tweet).split())\n\n    <span class=\"hljs-comment\"># function to calculate percentage</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">percentage</span>(<span class=\"hljs-params\">self, part, whole</span>):</span>\n        temp = <span class=\"hljs-number\">100</span> * <span class=\"hljs-built_in\">float</span>(part) / <span class=\"hljs-built_in\">float</span>(whole)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">format</span>(temp, <span class=\"hljs-string\">'.2f'</span>)\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">plotPieChart</span>(<span class=\"hljs-params\">self, positive, wpositive, spositive, negative, wnegative, snegative, neutral, searchTerm, noOfSearchTerms</span>):</span>\n        labels = [<span class=\"hljs-string\">'Positive ['</span> + <span class=\"hljs-built_in\">str</span>(positive) + <span class=\"hljs-string\">'%]'</span>, <span class=\"hljs-string\">'Weakly Positive ['</span> + <span class=\"hljs-built_in\">str</span>(wpositive) + <span class=\"hljs-string\">'%]'</span>,<span class=\"hljs-string\">'Strongly Positive ['</span> + <span class=\"hljs-built_in\">str</span>(spositive) + <span class=\"hljs-string\">'%]'</span>, <span class=\"hljs-string\">'Neutral ['</span> + <span class=\"hljs-built_in\">str</span>(neutral) + <span class=\"hljs-string\">'%]'</span>,\n                  <span class=\"hljs-string\">'Negative ['</span> + <span class=\"hljs-built_in\">str</span>(negative) + <span class=\"hljs-string\">'%]'</span>, <span class=\"hljs-string\">'Weakly Negative ['</span> + <span class=\"hljs-built_in\">str</span>(wnegative) + <span class=\"hljs-string\">'%]'</span>, <span class=\"hljs-string\">'Strongly Negative ['</span> + <span class=\"hljs-built_in\">str</span>(snegative) + <span class=\"hljs-string\">'%]'</span>]\n        sizes = [positive, wpositive, spositive, neutral, negative, wnegative, snegative]\n        colors = [<span class=\"hljs-string\">'yellowgreen'</span>,<span class=\"hljs-string\">'lightgreen'</span>,<span class=\"hljs-string\">'darkgreen'</span>, <span class=\"hljs-string\">'gold'</span>, <span class=\"hljs-string\">'red'</span>,<span class=\"hljs-string\">'lightsalmon'</span>,<span class=\"hljs-string\">'darkred'</span>]\n        patches, texts = thr.pie(sizes, colors=colors, startangle=<span class=\"hljs-number\">90</span>)\n        thr.legend(patches, labels, loc=<span class=\"hljs-string\">\"best\"</span>)\n        thr.title(<span class=\"hljs-string\">'How people are reacting on '</span> + searchTerm + <span class=\"hljs-string\">' by analyzing '</span> + <span class=\"hljs-built_in\">str</span>(noOfSearchTerms) + <span class=\"hljs-string\">' Tweets.'</span>)\n        thr.axis(<span class=\"hljs-string\">'equal'</span>)\n        thr.tight_layout()\n        thr.show()\n\n\n\n<span class=\"hljs-keyword\">if</span> __name__== <span class=\"hljs-string\">\"__main__\"</span>:\n    sa = SentimentAnalysis()\n    sa.DownloadData()\n    <span class=\"hljs-comment\">#https://github.com/the-javapocalypse/Twitter-Sentiment-Analysis/blob/master/main.py</span></code></pre></div>",
    "sec_14.py": "<div class=\"codeBlock hljs python\" id=\"sec_14\"><pre id=\"sec_14_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob                   <span class=\"hljs-comment\">##language translation API</span>\n<span class=\"hljs-keyword\">from</span> tkinter.scrolledtext <span class=\"hljs-keyword\">import</span> ScrolledText   <span class=\"hljs-comment\">##for scrollable text box</span>\n\n<span class=\"hljs-comment\">#-----translation function----------------------------------------------------------------------</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">toLang</span>(<span class=\"hljs-params\">lang</span>):</span>\n    <span class=\"hljs-keyword\">try</span>:\n        output.delete(<span class=\"hljs-string\">\"1.0\"</span>,END)            <span class=\"hljs-comment\">##to delete previous entry in the output box</span>\n        inputSTR = input_str.get(<span class=\"hljs-string\">\"1.0\"</span>,END)\n        obj = TextBlob(<span class=\"hljs-built_in\">str</span>(inputSTR))\n        <div style=\"display: inline;\" id=\"translation_0\" class=\"highlights fea_translation\">outputSTR = obj.translate(to=lang)</div>\n        output.insert(END,<span class=\"hljs-built_in\">str</span>(outputSTR))   <span class=\"hljs-comment\">##insert output to the output box</span>\n    <span class=\"hljs-keyword\">except</span>:\n        output.insert(END, <span class=\"hljs-string\">\"**Please enter a meaningful word/sentence**\"</span>)\n        <span class=\"hljs-comment\">#https://github.com/DeepakJha01/GUI-Translator/blob/master/main/gui_translator.py</span></code></pre></div>",
    "sec_16.py": "<div class=\"codeBlock hljs python\" id=\"sec_16\"><pre id=\"sec_16_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> webbrowser\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob, exceptions\n<span class=\"hljs-keyword\">from</span> wox <span class=\"hljs-keyword\">import</span> Wox, WoxAPI\n\nLANGUAGE = <span class=\"hljs-string\">'ru'</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">translate</span>(<span class=\"hljs-params\">query</span>):</span>\n    query_modified = query.strip().lower()\n    en = <span class=\"hljs-built_in\">set</span>(<span class=\"hljs-built_in\">chr</span>(i) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">ord</span>(<span class=\"hljs-string\">'a'</span>), <span class=\"hljs-built_in\">ord</span>(<span class=\"hljs-string\">'z'</span>) + <span class=\"hljs-number\">1</span>))\n    results = []\n    <span class=\"hljs-keyword\">if</span> query_modified:\n        <span class=\"hljs-keyword\">try</span>:\n            from_lang, to_lang = (<span class=\"hljs-string\">'en'</span>, LANGUAGE) <span class=\"hljs-keyword\">if</span> query_modified[<span class=\"hljs-number\">0</span>] <span class=\"hljs-keyword\">in</span> en <span class=\"hljs-keyword\">else</span> (LANGUAGE, <span class=\"hljs-string\">'en'</span>)\n            translation = TextBlob(query_modified).translate(from_lang, to_lang)\n            results.append({\n                <span class=\"hljs-string\">\"Title\"</span>: <span class=\"hljs-built_in\">str</span>(translation),\n                <span class=\"hljs-string\">\"SubTitle\"</span>: query,\n                <span class=\"hljs-string\">\"IcoPath\"</span>:<span class=\"hljs-string\">\"Images/app.png\"</span>,\n                <span class=\"hljs-string\">\"JsonRPCAction\"</span>:{<span class=\"hljs-string\">'method'</span>: <span class=\"hljs-string\">'openUrl'</span>,\n                                 <span class=\"hljs-string\">'parameters'</span>: [<span class=\"hljs-string\">r'http://translate.google.com/#{}/{}/{}'</span>.<span class=\"hljs-built_in\">format</span>(from_lang, to_lang, query)],\n                                 <span class=\"hljs-string\">'dontHideAfterAction'</span>: <span class=\"hljs-literal\">False</span>}\n            })\n        <span class=\"hljs-keyword\">except</span> exceptions.NotTranslated:\n            <span class=\"hljs-keyword\">pass</span>\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> results:\n        results.append({\n                <span class=\"hljs-string\">\"Title\"</span>: <span class=\"hljs-string\">'Not found'</span>,\n                <span class=\"hljs-string\">\"SubTitle\"</span>: <span class=\"hljs-string\">''</span>,\n                <span class=\"hljs-string\">\"IcoPath\"</span>:<span class=\"hljs-string\">\"Images/app.png\"</span>\n            })\n    <span class=\"hljs-keyword\">return</span> results\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Translate</span>(<span class=\"hljs-params\">Wox</span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">query</span>(<span class=\"hljs-params\">self, query</span>):</span>\n        <span class=\"hljs-keyword\">return</span> <div style=\"display: inline;\" id=\"translation_0\" class=\"highlights fea_translation\">translate(query)</div>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">openUrl</span>(<span class=\"hljs-params\">self, url</span>):</span>\n        webbrowser.<span class=\"hljs-built_in\">open</span>(url)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    Translate()\n    <span class=\"hljs-comment\">#https://github.com/RomanKornev/Translate/blob/master/main.py</span></code></pre></div>",
    "sec_19.py": "<div class=\"codeBlock hljs python\" id=\"sec_19\"><pre id=\"sec_19_code\" ><code class=\"json\"><span class=\"hljs-keyword\">import</span> googletrans\n<span class=\"hljs-keyword\">from</span> googletrans <span class=\"hljs-keyword\">import</span> Translator\n\n<span class=\"hljs-comment\">#from pygoogletranslation import Translator</span>\n\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n\n<span class=\"hljs-keyword\">import</span> time\nepis = {}\n\ntranslator = Translator(service_urls = [<span class=\"hljs-string\">'translate.google.com'</span>, <span class=\"hljs-string\">'translate.google.co.kr'</span>])\n<span class=\"hljs-comment\">#translator = Translator()</span>\n\n<span class=\"hljs-comment\">#bad_result_message = '**!!! BAD RESULT OF RECOGNITION. U CAN TRY AGAIN**'</span>\n\n\nlang_dic = {value.title(): key <span class=\"hljs-keyword\">for</span> key, value <span class=\"hljs-keyword\">in</span> googletrans.LANGUAGES.items()}\nlang_dic_reversed = {key: <span class=\"hljs-string\">f'*<span class=\"hljs-subst\">{value.capitalize()}</span>*'</span> <span class=\"hljs-keyword\">for</span> key, value <span class=\"hljs-keyword\">in</span> googletrans.LANGUAGES.items()}\n\nall_langs = <span class=\"hljs-built_in\">list</span>(lang_dic.keys())\n\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">from_code_to_name</span>(<span class=\"hljs-params\">language</span>):</span>\n    <span class=\"hljs-keyword\">return</span>  lang_dic_reversed[language]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">smart_to_tidy</span>(<span class=\"hljs-params\">langs</span>):</span>\n    <span class=\"hljs-keyword\">return</span> [lang_dic_reversed[l] <span class=\"hljs-keyword\">for</span> l <span class=\"hljs-keyword\">in</span> langs]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_code_from_lang</span>(<span class=\"hljs-params\">lang</span>):</span>\n    <span class=\"hljs-keyword\">return</span> lang_dic[lang.tolower()]\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">log_text</span>(<span class=\"hljs-params\">text, lang_list = [<span class=\"hljs-string\">'en'</span>,<span class=\"hljs-string\">'ru'</span>]</span>):</span>\n    \n    result = []\n    \n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(text) &lt; <span class=\"hljs-number\">3</span>:\n        result.append(<span class=\"hljs-string\">f'*too shirt text*: <span class=\"hljs-subst\">{text}</span>'</span>)\n        <span class=\"hljs-keyword\">return</span> result\n    \n\n    lang_of_text = translator.detect(text).lang\n    <span class=\"hljs-comment\">#if len(lang_of_text) == 0: lang_of_text = 'en'</span>\n    <span class=\"hljs-comment\">#print(lang_of_text)</span>\n\n    bool_list = [r != lang_of_text <span class=\"hljs-keyword\">for</span> r <span class=\"hljs-keyword\">in</span> lang_list]\n    \n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">all</span>(bool_list):\n        bool_list.append(<span class=\"hljs-literal\">False</span>)\n        lang_list.append(lang_of_text)\n    \n    <span class=\"hljs-keyword\">for</span> lang, it <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(lang_list, bool_list):\n        result.append(<span class=\"hljs-string\">f'<span class=\"hljs-subst\">{lang_dic_reversed[lang].upper()}</span>:'</span>)\n        <span class=\"hljs-keyword\">if</span> it:\n            time.sleep(<span class=\"hljs-number\">0.7</span>)\n            <span class=\"hljs-comment\">#print(f\"{text}, {lang}, {lang_of_text}\")</span>\n            txt = translator.translate(text, dest = lang, src = lang_of_text).text\n            result.append(txt)\n        <span class=\"hljs-keyword\">else</span>:\n            txt = text\n            result.append(<span class=\"hljs-string\">f'_(original text)_ <span class=\"hljs-subst\">{text}</span>'</span>)\n        result.append(<span class=\"hljs-string\">''</span>)\n    \n    <span class=\"hljs-keyword\">return</span> result\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">log_text_better</span>(<span class=\"hljs-params\">text, lang_list = [<span class=\"hljs-string\">'en'</span>,<span class=\"hljs-string\">'ru'</span>]</span>):</span>\n    \n    result = []\n    \n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(text) &lt; <span class=\"hljs-number\">3</span>:\n        result.append(<span class=\"hljs-string\">f'*too shirt text*: <span class=\"hljs-subst\">{text}</span>'</span>)\n        <span class=\"hljs-keyword\">return</span> result\n    \n    blob = TextBlob(text)\n\n    <div style=\"display: inline;\" id=\"language_detection_0\" class=\"highlights fea_language_detection\">lang_of_text = blob.detect_language()</div>\n\n    bool_list = [r != lang_of_text <span class=\"hljs-keyword\">for</span> r <span class=\"hljs-keyword\">in</span> lang_list]\n    \n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">all</span>(bool_list):\n        bool_list.append(<span class=\"hljs-literal\">False</span>)\n        lang_list.append(lang_of_text)\n    \n    <span class=\"hljs-keyword\">for</span> lang, it <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(lang_list, bool_list):\n        result.append(<span class=\"hljs-string\">f'<span class=\"hljs-subst\">{lang_dic_reversed[lang].upper()}</span>:'</span>)\n        <span class=\"hljs-keyword\">if</span> it:\n            time.sleep(<span class=\"hljs-number\">1.3</span>)\n            <div style=\"display: inline;\" id=\"translation_0\" class=\"highlights fea_translation\">txt = <span class=\"hljs-built_in\">str</span>(blob.translate(from_lang = lang_of_text, to=lang))</div>\n            result.append(txt)\n        <span class=\"hljs-keyword\">else</span>:\n            txt = text\n            result.append(<span class=\"hljs-string\">f'_(original text)_ <span class=\"hljs-subst\">{text}</span>'</span>)\n        result.append(<span class=\"hljs-string\">''</span>)\n    \n    <span class=\"hljs-keyword\">return</span> result\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_langs_from_numbers</span>(<span class=\"hljs-params\">numbers</span>):</span>\n    \n    l1 = [all_langs[k-<span class=\"hljs-number\">1</span>] <span class=\"hljs-keyword\">for</span> k <span class=\"hljs-keyword\">in</span> numbers]\n    \n    <span class=\"hljs-keyword\">return</span> l1, [lang_dic[k] <span class=\"hljs-keyword\">for</span> k <span class=\"hljs-keyword\">in</span> l1]\n\n\n\n\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n\n    <span class=\"hljs-comment\">#trans = Translator()</span>\n    <span class=\"hljs-comment\">#print(trans.detect(''))</span>\n    <span class=\"hljs-comment\">#print(trans.detect('Hello').lang)</span>\n    <span class=\"hljs-comment\">#print(trans.translate(''))</span>\n\n\n\n\n   \n    defs = [<span class=\"hljs-string\">'en'</span>,<span class=\"hljs-string\">'ru'</span>]\n    \n    r = log_text(<span class=\"hljs-string\">'hello my friend'</span>,defs)\n    \n    print(<span class=\"hljs-string\">'\\n'</span>.join(r))\n\n    r = log_text(<span class=\"hljs-string\">'Ich will'</span>,defs)\n    \n    print(<span class=\"hljs-string\">'\\n'</span>.join(r))\n    \n    print(defs)\n    \n    r = log_text_better(<span class=\"hljs-string\">'hello my friend'</span>,defs)\n    \n    print(<span class=\"hljs-string\">'\\n'</span>.join(r))\n\n    lang = Translator().detect(<span class=\"hljs-string\">'Hello boy'</span>)\n    print(lang)\n\n<span class=\"hljs-comment\">#https://github.com/PasaOpasen/TranslatorBot/blob/master/translator_tools.py</span></code></pre></div>",
    "sec_22.py": "<div class=\"codeBlock hljs python\" id=\"sec_22\"><pre id=\"sec_22_code\" ><code class=\"json\"><span class=\"hljs-comment\"># -*- coding: utf-8 -*-</span>\n<span class=\"hljs-string\">\"\"\"\nTranslator module that uses the Google Translate API.\n\nAdapted from Terry Yin's google-translate-python.\nLanguage detection added by Steven Loria.\n\"\"\"</span>\n<span class=\"hljs-comment\"># I(Dhyey thumar) have done some modifications in this file.</span>\n\n<span class=\"hljs-comment\"># import codecs</span>\n<span class=\"hljs-comment\"># import re</span>\n<span class=\"hljs-keyword\">import</span> ctypes\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> sys\n\n<span class=\"hljs-keyword\">from</span> textblob.compat <span class=\"hljs-keyword\">import</span> PY2, request, urlencode\n<span class=\"hljs-comment\"># from textblob.exceptions import TranslatorError, NotTranslated</span>\n\nsource_lang_code = <span class=\"hljs-built_in\">str</span>(sys.argv[<span class=\"hljs-number\">1</span>])\ninput_string = <span class=\"hljs-built_in\">str</span>(sys.argv[<span class=\"hljs-number\">2</span>])\ndest_lang_code = <span class=\"hljs-built_in\">str</span>(sys.argv[<span class=\"hljs-number\">3</span>])\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Translator</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n\n    <span class=\"hljs-string\">\"\"\"A language translator and detector.\n\n    Usage:\n    ::\n        &gt;&gt;&gt; from textblob.translate import Translator\n        &gt;&gt;&gt; t = Translator()\n        &gt;&gt;&gt; t.translate('hello', from_lang='en', to_lang='fr')\n        u'bonjour'\n        &gt;&gt;&gt; t.detect(\"hola\")\n        u'es'\n    \"\"\"</span>\n\n    url = <span class=\"hljs-string\">\"http://translate.google.com/translate_a/t?client=webapp&amp;dt=bd&amp;dt=ex&amp;dt=ld&amp;dt=md&amp;dt=qca&amp;dt=rw&amp;dt=rm&amp;dt=ss&amp;dt=t&amp;dt=at&amp;ie=UTF-8&amp;oe=UTF-8&amp;otf=2&amp;ssel=0&amp;tsel=0&amp;kc=1\"</span>\n\n    headers = {\n        <span class=\"hljs-string\">'Accept'</span>: <span class=\"hljs-string\">'*/*'</span>,\n        <span class=\"hljs-string\">'Connection'</span>: <span class=\"hljs-string\">'keep-alive'</span>,\n        <span class=\"hljs-string\">'User-Agent'</span>: (\n            <span class=\"hljs-string\">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Safari/537.36'</span>)\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">translate</span>(<span class=\"hljs-params\">self, source, from_lang=<span class=\"hljs-string\">'auto'</span>, to_lang=<span class=\"hljs-string\">'en'</span>, host=<span class=\"hljs-literal\">None</span>, type_=<span class=\"hljs-literal\">None</span></span>):</span>\n        <span class=\"hljs-string\">\"\"\"Translate the source text from one language to another.\"\"\"</span>\n        <span class=\"hljs-keyword\">if</span> PY2:\n            source = source.encode(<span class=\"hljs-string\">'utf-8'</span>)\n        data = {<span class=\"hljs-string\">\"q\"</span>: source}\n        url = <span class=\"hljs-string\">u'{url}&amp;sl={from_lang}&amp;tl={to_lang}&amp;hl={to_lang}&amp;tk={tk}'</span>.<span class=\"hljs-built_in\">format</span>(\n            url=self.url,\n            from_lang=from_lang,\n            to_lang=to_lang,\n            tk=_calculate_tk(source),\n        )\n        response = self._request(url, host=host, type_=type_, data=data)\n        result = json.loads(response)\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(result, <span class=\"hljs-built_in\">list</span>):\n            <span class=\"hljs-keyword\">try</span>:\n                result = result[<span class=\"hljs-number\">0</span>]  <span class=\"hljs-comment\"># ignore detected language</span>\n            <span class=\"hljs-keyword\">except</span> IndexError:\n                <span class=\"hljs-keyword\">pass</span>\n        <span class=\"hljs-comment\"># self._validate_translation(source, result)</span>\n        <span class=\"hljs-keyword\">return</span> result\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">detect</span>(<span class=\"hljs-params\">self, source, host=<span class=\"hljs-literal\">None</span>, type_=<span class=\"hljs-literal\">None</span></span>):</span>\n        <span class=\"hljs-string\">\"\"\"Detect the source text's language.\"\"\"</span>\n        <span class=\"hljs-keyword\">if</span> PY2:\n            source = source.encode(<span class=\"hljs-string\">'utf-8'</span>)\n        <span class=\"hljs-comment\"># if len(source) &lt; 3:</span>\n        <span class=\"hljs-comment\">#     return 1</span>\n            <span class=\"hljs-comment\"># raise TranslatorError('Must provide a string with at least 3 characters.')</span>\n        data = {<span class=\"hljs-string\">\"q\"</span>: source}\n        url = <span class=\"hljs-string\">u'{url}&amp;sl=auto&amp;tk={tk}'</span>.<span class=\"hljs-built_in\">format</span>(\n            url=self.url, tk=_calculate_tk(source))\n        response = self._request(url, host=host, type_=type_, data=data)\n        result, language = json.loads(response)\n        <span class=\"hljs-keyword\">return</span> language\n\n    <span class=\"hljs-comment\"># def _validate_translation(self, source, result):</span>\n    <span class=\"hljs-comment\">#     \"\"\"Validate API returned expected schema, and that the translated text</span>\n    <span class=\"hljs-comment\">#     is different than the original string.</span>\n    <span class=\"hljs-comment\">#     \"\"\"</span>\n    <span class=\"hljs-comment\">#     if not result:</span>\n    <span class=\"hljs-comment\">#         raise NotTranslated('Translation API returned and empty response.')</span>\n    <span class=\"hljs-comment\">#     if PY2:</span>\n    <span class=\"hljs-comment\">#         result = result.encode('utf-8')</span>\n    <span class=\"hljs-comment\">#     if result.strip() == source.strip():</span>\n    <span class=\"hljs-comment\">#         raise NotTranslated('Translation API returned the input string unchanged.')</span>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_request</span>(<span class=\"hljs-params\">self, url, host=<span class=\"hljs-literal\">None</span>, type_=<span class=\"hljs-literal\">None</span>, data=<span class=\"hljs-literal\">None</span></span>):</span>\n        encoded_data = urlencode(data).encode(<span class=\"hljs-string\">'utf-8'</span>)\n        req = request.Request(url=url, headers=self.headers, data=encoded_data)\n        <span class=\"hljs-keyword\">if</span> host <span class=\"hljs-keyword\">or</span> type_:\n            req.set_proxy(host=host, <span class=\"hljs-built_in\">type</span>=type_)\n        resp = request.urlopen(req)\n        content = resp.read()\n        <span class=\"hljs-keyword\">return</span> content.decode(<span class=\"hljs-string\">'utf-8'</span>)\n\n\n<span class=\"hljs-comment\"># def _unescape(text):</span>\n<span class=\"hljs-comment\">#     \"\"\"Unescape unicode character codes within a string.</span>\n<span class=\"hljs-comment\">#     \"\"\"</span>\n<span class=\"hljs-comment\">#     pattern = r'\\\\{1,2}u[0-9a-fA-F]{4}'</span>\n<span class=\"hljs-comment\">#     decode = lambda x: codecs.getdecoder('unicode_escape')(x.group())[0]</span>\n<span class=\"hljs-comment\">#     return re.sub(pattern, decode, text)</span>\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_calculate_tk</span>(<span class=\"hljs-params\">source</span>):</span>\n    <span class=\"hljs-string\">\"\"\"Reverse engineered cross-site request protection.\"\"\"</span>\n    <span class=\"hljs-comment\"># Source: https://github.com/soimort/translate-shell/issues/94#issuecomment-165433715</span>\n    <span class=\"hljs-comment\"># Source: http://www.liuxiatool.com/t.php</span>\n\n    tkk = [<span class=\"hljs-number\">406398</span>, <span class=\"hljs-number\">561666268</span> + <span class=\"hljs-number\">1526272306</span>]\n    b = tkk[<span class=\"hljs-number\">0</span>]\n\n    <span class=\"hljs-keyword\">if</span> PY2:\n        d = <span class=\"hljs-built_in\">map</span>(<span class=\"hljs-built_in\">ord</span>, source)\n    <span class=\"hljs-keyword\">else</span>:\n        d = source.encode(<span class=\"hljs-string\">'utf-8'</span>)\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">RL</span>(<span class=\"hljs-params\">a, b</span>):</span>\n        <span class=\"hljs-keyword\">for</span> c <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(b) - <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>):\n            d = b[c + <span class=\"hljs-number\">2</span>]\n            d = <span class=\"hljs-built_in\">ord</span>(d) - <span class=\"hljs-number\">87</span> <span class=\"hljs-keyword\">if</span> d &gt;= <span class=\"hljs-string\">'a'</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-built_in\">int</span>(d)\n            xa = ctypes.c_uint32(a).value\n            d = xa &gt;&gt; d <span class=\"hljs-keyword\">if</span> b[c + <span class=\"hljs-number\">1</span>] == <span class=\"hljs-string\">'+'</span> <span class=\"hljs-keyword\">else</span> xa &lt;&lt; d\n            a = a + d &amp; <span class=\"hljs-number\">4294967295</span> <span class=\"hljs-keyword\">if</span> b[c] == <span class=\"hljs-string\">'+'</span> <span class=\"hljs-keyword\">else</span> a ^ d\n        <span class=\"hljs-keyword\">return</span> ctypes.c_int32(a).value\n\n    a = b\n\n    <span class=\"hljs-keyword\">for</span> di <span class=\"hljs-keyword\">in</span> d:\n        a = RL(a + di, <span class=\"hljs-string\">\"+-a^+6\"</span>)\n\n    a = RL(a, <span class=\"hljs-string\">\"+-3^+b+-f\"</span>)\n    a ^= tkk[<span class=\"hljs-number\">1</span>]\n    a = a <span class=\"hljs-keyword\">if</span> a &gt;= <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> ((a &amp; <span class=\"hljs-number\">2147483647</span>) + <span class=\"hljs-number\">2147483648</span>)\n    a %= <span class=\"hljs-built_in\">pow</span>(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">6</span>)\n\n    tk = <span class=\"hljs-string\">'{0:d}.{1:d}'</span>.<span class=\"hljs-built_in\">format</span>(a, a ^ b)\n    <span class=\"hljs-keyword\">return</span> tk\n\n\n<div style=\"display: inline;\" id=\"translation_0\" class=\"highlights fea_translation\">translator_instance = Translator()</div>\n<span class=\"hljs-keyword\">if</span> source_lang_code == <span class=\"hljs-string\">\"null\"</span>:\n    source_lang_code = translator_instance.detect(input_string)\n\ntranslated_string = translator_instance.translate(input_string, source_lang_code, dest_lang_code)\n\n<span class=\"hljs-keyword\">if</span> translated_string:\n    translated_string = <span class=\"hljs-built_in\">str</span>(translated_string)\n    result = []\n    <span class=\"hljs-keyword\">for</span> char <span class=\"hljs-keyword\">in</span> translated_string:\n        result.append(<span class=\"hljs-built_in\">str</span>(<span class=\"hljs-built_in\">ord</span>(char)))\n    seperator = <span class=\"hljs-string\">','</span>\n    trans_string = seperator.join(result)\n    print(trans_string, end=<span class=\"hljs-string\">'\\n'</span>)\n<span class=\"hljs-keyword\">else</span>:\n    print(<span class=\"hljs-string\">'empty response'</span>)\n    <span class=\"hljs-comment\">#https://github.com/dhyeythumar/Search-Engine/blob/master/Python_scripts/lang_trans1.py</span></code></pre></div>",
    "sec_23.py": "<div class=\"codeBlock hljs python\" id=\"sec_23\"><pre id=\"sec_23_code\" ><code class=\"json\"><span class=\"hljs-string\">''' This is language translation script '''</span>\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">import</span> sys\n\n\nsource_lang_code = <span class=\"hljs-built_in\">str</span>(sys.argv[<span class=\"hljs-number\">1</span>])\ninput_string = <span class=\"hljs-built_in\">str</span>(sys.argv[<span class=\"hljs-number\">2</span>])\ndest_lang_code = <span class=\"hljs-built_in\">str</span>(sys.argv[<span class=\"hljs-number\">3</span>])\n\ninput_blob = TextBlob(input_string)\n\n<span class=\"hljs-keyword\">if</span> source_lang_code == <span class=\"hljs-string\">\"null\"</span>:\n    <span class=\"hljs-keyword\">try</span>:\n        <div style=\"display: inline;\" id=\"language_detection_0\" class=\"highlights fea_language_detection\">source_lang_code = input_blob.detect_language()</div>\n        <span class=\"hljs-comment\"># print(\"Detected language:  \", source_lang_code)</span>\n    <span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:  <span class=\"hljs-comment\"># What if the input_string language is not detected</span>\n        print(<span class=\"hljs-string\">\"Error_1\"</span>, e)\n\n<span class=\"hljs-keyword\">try</span>:\n    translated_string = <div style=\"display: inline;\" id=\"translation_0\" class=\"highlights fea_translation\">input_blob.translate(\n        from_lang=source_lang_code, to=dest_lang_code)</div>\n    <span class=\"hljs-comment\"># print(translated_string) give character in unicode format.</span>\n    <span class=\"hljs-comment\"># translated_string =&gt; is a &lt;class 'textblob.blob.TextBlob'&gt; type of object</span>\n    <span class=\"hljs-comment\"># str(translated_string) =&gt; is a &lt;class 'str'&gt; type of object</span>\n    <span class=\"hljs-comment\"># str(translated_string).encode('utf8) =&gt; is a &lt;class 'bytes'&gt; type of object</span>\n\n    translated_string = <span class=\"hljs-built_in\">str</span>(translated_string)\n    result = []\n    <span class=\"hljs-keyword\">for</span> char <span class=\"hljs-keyword\">in</span> translated_string:\n        result.append(<span class=\"hljs-built_in\">str</span>(<span class=\"hljs-built_in\">ord</span>(char)))\n    seperator = <span class=\"hljs-string\">', '</span>\n    trans_string = seperator.join(result)\n    print(trans_string, end=<span class=\"hljs-string\">'\\n'</span>)\n\n<span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:  <span class=\"hljs-comment\"># What if the dest_lang code is null</span>\n    print(<span class=\"hljs-string\">\"Error_2\"</span>, e)\n    <span class=\"hljs-comment\">#https://github.com/dhyeythumar/Search-Engine/blob/master/Python_scripts/lang_trans.py</span></code></pre></div>",
    "sec_11.py": "<div class=\"codeBlock hljs python\" id=\"sec_11\"><pre id=\"sec_11_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">from</span> time <span class=\"hljs-keyword\">import</span> sleep\n<span class=\"hljs-keyword\">import</span> csv\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n\ndf = pd.read_csv(<span class=\"hljs-string\">\"cleaned_data01.csv\"</span>)\ntexts = df[<span class=\"hljs-string\">'cleaned_text'</span>]\n\ncounter = <span class=\"hljs-number\">188277</span>\nremains = texts.shape[<span class=\"hljs-number\">0</span>] - <span class=\"hljs-number\">188277</span>\nreq_counter = <span class=\"hljs-number\">0</span>\n\n<span class=\"hljs-comment\">#========================= textblob ==========================</span>\n\n<span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">'tweet_lang02.csv'</span>, <span class=\"hljs-string\">'a'</span>, encoding=<span class=\"hljs-string\">\"utf-8-sig\"</span>) <span class=\"hljs-keyword\">as</span> csvFile:\n    csvWriter = csv.writer(csvFile)\n    csvWriter.writerow([<span class=\"hljs-string\">'text'</span>,<span class=\"hljs-string\">'language'</span>])\n    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">188277</span>, texts.shape[<span class=\"hljs-number\">0</span>]):\n        counter +=<span class=\"hljs-number\">1</span>\n        remains -=<span class=\"hljs-number\">1</span>\n        req_counter +=<span class=\"hljs-number\">1</span>\n        print(counter, <span class=\"hljs-string\">' '</span>, remains)\n        t = texts[i]\n        s = t.replace(<span class=\"hljs-string\">\"#\"</span>,<span class=\"hljs-string\">\"\"</span>)\n        s = s.replace(<span class=\"hljs-string\">\"_\"</span>, <span class=\"hljs-string\">\" \"</span>)\n        <span class=\"hljs-keyword\">if</span> req_counter == <span class=\"hljs-number\">10</span>:\n            sleep(<span class=\"hljs-number\">3</span>)\n            req_counter = <span class=\"hljs-number\">0</span>\n\n        b = TextBlob(s)\n        <div style=\"display: inline;\" id=\"language_detection_0\" class=\"highlights fea_language_detection\">l = b.detect_language()</div>\n        csvWriter.writerow([t,l])\n        <span class=\"hljs-comment\">#https://github.com/khaledabbud/SA_of_Tweets_After_QS_Assassination_AR_FA/blob/master/textblob_lang_classification.py</span></code></pre></div>",
    "sec_18.py": "<div class=\"codeBlock hljs python\" id=\"sec_18\"><pre id=\"sec_18_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">log_text</span>(<span class=\"hljs-params\">text, lang_of_text=<span class=\"hljs-literal\">None</span>, lang_list = [<span class=\"hljs-string\">'en'</span>,<span class=\"hljs-string\">'ru'</span>], trans_list = [<span class=\"hljs-literal\">True</span>, <span class=\"hljs-literal\">True</span>]</span>):</span>\n    \n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(text) &lt; <span class=\"hljs-number\">3</span>:\n        print_on_yellow(<span class=\"hljs-string\">'too small text:'</span>,end=<span class=\"hljs-string\">' '</span>)\n        print(text)\n        <span class=\"hljs-keyword\">return</span>\n    \n    blob = TextBlob(text)\n    <span class=\"hljs-keyword\">if</span> lang_of_text == <span class=\"hljs-literal\">None</span>:\n        <div style=\"display: inline;\" id=\"language_detection_0\" class=\"highlights fea_language_detection\">lang_of_text = blob.detect_language()</div>\n\n    bool_list = [r != lang_of_text <span class=\"hljs-keyword\">for</span> r <span class=\"hljs-keyword\">in</span> lang_list]\n    \n    <span class=\"hljs-keyword\">for</span> lang, it, tc <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(lang_list, bool_list, trans_list):\n        print(colored(<span class=\"hljs-string\">f'\\t <span class=\"hljs-subst\">{lang}</span>:'</span>, color = <span class=\"hljs-string\">'cyan'</span>, attrs=[<span class=\"hljs-string\">'bold'</span>]), end=<span class=\"hljs-string\">' '</span>)\n        <span class=\"hljs-keyword\">if</span> it:\n           <div style=\"display: inline;\" id=\"language_detection_1\" class=\"highlights fea_language_detection\"> txt = <span class=\"hljs-built_in\">str</span>(blob.translate(from_lang = lang_of_text, to = lang))</div>\n            print(txt)\n        <span class=\"hljs-keyword\">else</span>:\n            txt = text\n            print(<span class=\"hljs-string\">f'<span class=\"hljs-subst\">{text}</span> (original text)'</span>)\n        \n        <span class=\"hljs-keyword\">if</span> tc:\n            pron = epis[lang].transliterate(txt)\n            print(<span class=\"hljs-string\">'\\t\\t\\t'</span>,end=<span class=\"hljs-string\">' '</span>)\n            print_on_magenta(<span class=\"hljs-string\">f'[<span class=\"hljs-subst\">{pron}</span>]'</span>)\n<span class=\"hljs-comment\">#https://github.com/PasaOpasen/SpeechLogger/blob/master/ThirdTry/text_logger5.py</span></code></pre></div>",
    "sec_4.py": "<div class=\"codeBlock hljs python\" id=\"sec_4\"><pre id=\"sec_4_code\" ><code class=\"json\">\n<span class=\"hljs-keyword\">from</span> textblob.classifiers <span class=\"hljs-keyword\">import</span> NaiveBayesClassifier\n\ntrain = [\n    (<span class=\"hljs-string\">'amor'</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"perro\"</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"playa\"</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"sal\"</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"oceano\"</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"love\"</span>, <span class=\"hljs-string\">\"english\"</span>),\n    (<span class=\"hljs-string\">\"dog\"</span>, <span class=\"hljs-string\">\"english\"</span>),\n    (<span class=\"hljs-string\">\"beach\"</span>, <span class=\"hljs-string\">\"english\"</span>),\n    (<span class=\"hljs-string\">\"salt\"</span>, <span class=\"hljs-string\">\"english\"</span>),\n    (<span class=\"hljs-string\">\"ocean\"</span>, <span class=\"hljs-string\">\"english\"</span>)\n]\ntest = [\n    (<span class=\"hljs-string\">\"ropa\"</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"comprar\"</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"camisa\"</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"agua\"</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"telefono\"</span>, <span class=\"hljs-string\">\"spanish\"</span>),\n    (<span class=\"hljs-string\">\"clothes\"</span>, <span class=\"hljs-string\">\"english\"</span>),\n    (<span class=\"hljs-string\">\"buy\"</span>, <span class=\"hljs-string\">\"english\"</span>),\n    (<span class=\"hljs-string\">\"shirt\"</span>, <span class=\"hljs-string\">\"english\"</span>),\n    (<span class=\"hljs-string\">\"water\"</span>, <span class=\"hljs-string\">\"english\"</span>),\n    (<span class=\"hljs-string\">\"telephone\"</span>, <span class=\"hljs-string\">\"english\"</span>)\n]\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">extractor</span>(<span class=\"hljs-params\">word</span>):</span>\n    <span class=\"hljs-string\">'''Extract the last letter of a word as the only feature.'''</span>\n    feats = {}\n    last_letter = word[-<span class=\"hljs-number\">1</span>]\n    feats[<span class=\"hljs-string\">\"last_letter({0})\"</span>.<span class=\"hljs-built_in\">format</span>(last_letter)] = <span class=\"hljs-literal\">True</span>\n    <span class=\"hljs-keyword\">return</span> feats\n\n<div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">lang_detector = NaiveBayesClassifier(train, feature_extractor=extractor)</div>\nprint(lang_detector.accuracy(test))\nprint(lang_detector.show_informative_features(<span class=\"hljs-number\">5</span>))\n<span class=\"hljs-comment\">#https://gist.github.com/sloria/6342158</span></code></pre></div>",
    "sec_5.py": "<div class=\"codeBlock hljs python\" id=\"sec_5\"><pre id=\"sec_5_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob.classifiers <span class=\"hljs-keyword\">import</span> NaiveBayesClassifier\n<span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\ntrain = [\n    (<span class=\"hljs-string\">'I love this sandwich.'</span>, <span class=\"hljs-string\">'pos'</span>),\n    (<span class=\"hljs-string\">'This is an amazing place!'</span>, <span class=\"hljs-string\">'pos'</span>),\n    (<span class=\"hljs-string\">'I feel very good about these beers.'</span>, <span class=\"hljs-string\">'pos'</span>),\n    (<span class=\"hljs-string\">'This is my best work.'</span>, <span class=\"hljs-string\">'pos'</span>),\n    (<span class=\"hljs-string\">\"What an awesome view\"</span>, <span class=\"hljs-string\">'pos'</span>),\n    (<span class=\"hljs-string\">'I do not like this restaurant'</span>, <span class=\"hljs-string\">'neg'</span>),\n    (<span class=\"hljs-string\">'I am tired of this stuff.'</span>, <span class=\"hljs-string\">'neg'</span>),\n    (<span class=\"hljs-string\">\"I can't deal with this\"</span>, <span class=\"hljs-string\">'neg'</span>),\n    (<span class=\"hljs-string\">'He is my sworn enemy!'</span>, <span class=\"hljs-string\">'neg'</span>),\n    (<span class=\"hljs-string\">'My boss is horrible.'</span>, <span class=\"hljs-string\">'neg'</span>)\n]\ntest = [\n    (<span class=\"hljs-string\">'The beer was good.'</span>, <span class=\"hljs-string\">'pos'</span>),\n    (<span class=\"hljs-string\">'I do not enjoy my job'</span>, <span class=\"hljs-string\">'neg'</span>),\n    (<span class=\"hljs-string\">\"I ain't feeling dandy today.\"</span>, <span class=\"hljs-string\">'neg'</span>),\n    (<span class=\"hljs-string\">\"I feel amazing!\"</span>, <span class=\"hljs-string\">'pos'</span>),\n    (<span class=\"hljs-string\">'Gary is a friend of mine.'</span>, <span class=\"hljs-string\">'pos'</span>),\n    (<span class=\"hljs-string\">\"I can't believe I'm doing this.\"</span>, <span class=\"hljs-string\">'neg'</span>)\n]\n<div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">cl = NaiveBayesClassifier(train)</div>\n<span class=\"hljs-comment\"># Classify some text</span>\nprint(cl.classify(<span class=\"hljs-string\">\"Their burgers are amazing.\"</span>))  <span class=\"hljs-comment\"># \"pos\"</span>\nprint(cl.classify(<span class=\"hljs-string\">\"I don't like their pizza.\"</span>))   <span class=\"hljs-comment\"># \"neg\"</span>\n<span class=\"hljs-comment\"># Classify a TextBlob</span>\nblob = TextBlob(<span class=\"hljs-string\">\"The beer was amazing. But the hangover was horrible. \"</span>\n<span class=\"hljs-string\">\"My boss was not pleased.\"</span>, classifier=cl)\nprint(blob)\nprint(blob.classify())\n<span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> blob.sentences:\nprint(sentence)\nprint(sentence.classify())\n<span class=\"hljs-comment\"># Compute accuracy</span>\nprint(<span class=\"hljs-string\">\"Accuracy: {0}\"</span>.<span class=\"hljs-built_in\">format</span>(cl.accuracy(test)))\n<span class=\"hljs-comment\"># Show 5 most informative features</span>\ncl.show_informative_features(<span class=\"hljs-number\">5</span>)\n<span class=\"hljs-comment\">#https://gist.github.com/sloria/6338202#file-tweet_classify-py</span></code></pre></div>",
    "sec_13.py": "<div class=\"codeBlock hljs python\" id=\"sec_13\"><pre id=\"sec_13_code\" ><code class=\"json\"><span class=\"hljs-keyword\">from</span> textblob <span class=\"hljs-keyword\">import</span> TextBlob\n<span class=\"hljs-keyword\">from</span> textblob.sentiments <span class=\"hljs-keyword\">import</span> NaiveBayesAnalyzer\n<span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> thr\n<span class=\"hljs-keyword\">import</span> random\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">twitter_analysis</span>(<span class=\"hljs-params\">string</span>):</span>\n\t<span class=\"hljs-comment\">## Aain function starts</span>\n\t<span class=\"hljs-comment\">## =====</span>\n\n\tprocessedTweet = []\n\tpos = <span class=\"hljs-number\">0</span>\n\tneg = <span class=\"hljs-number\">0</span>\n\tneutral = <span class=\"hljs-number\">0</span>\n\n\t<span class=\"hljs-comment\">#start process_tweet</span>\n\t<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">processTweet</span>(<span class=\"hljs-params\">tweet</span>):</span>\n\t    <span class=\"hljs-comment\"># process the tweets</span>\n\t    \n\t    <span class=\"hljs-comment\">#Convert to lower case</span>\n\t    tweet = tweet.lower()\n\t    <span class=\"hljs-comment\">#Convert www.* or https?://* to URL</span>\n\t    tweet = re.sub(<span class=\"hljs-string\">'((www\\.[^\\s]+)|(https?://[^\\s]+))'</span>,<span class=\"hljs-string\">'URL'</span>,tweet)\n\t    <span class=\"hljs-comment\">#Convert @username to AT_USER</span>\n\t    tweet = re.sub(<span class=\"hljs-string\">'@[^\\s]+'</span>,<span class=\"hljs-string\">'AT_USER'</span>,tweet)\n\t    <span class=\"hljs-comment\">#Remove additional white spaces</span>\n\t    tweet = re.sub(<span class=\"hljs-string\">'[\\s]+'</span>, <span class=\"hljs-string\">' '</span>, tweet)\n\t    <span class=\"hljs-comment\">#Replace #word with word</span>\n\t    tweet = re.sub(<span class=\"hljs-string\">r'#([^\\s]+)'</span>, <span class=\"hljs-string\">r'\\1'</span>, tweet)\n\t    <span class=\"hljs-comment\">#trim</span>\n\t    tweet = tweet.strip(<span class=\"hljs-string\">'\\'\"'</span>)\n\t    <span class=\"hljs-keyword\">return</span> tweet\n\t<span class=\"hljs-comment\">#end</span>\n\n\ttd = TwitterData()\n\trawtweet = td.getData(string)\n\n\t<span class=\"hljs-comment\">#print \"1. Tweets colleted and pre-processing steps started\"</span>\n\n\t<span class=\"hljs-comment\">#pre-processing tweets    </span>\n\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1</span>,<span class=\"hljs-built_in\">len</span>(rawtweet)):\n\t    processedTweet.append(processTweet(rawtweet[i]))\n\n\t<span class=\"hljs-comment\">#print \"2. preprocessing over and classifer begins\"</span>\n\n\t<span class=\"hljs-comment\"># classifying the processed tweets by NaiveBayesAnalyzer</span>\n\n\t<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1</span>,<span class=\"hljs-built_in\">len</span>(processedTweet)):\n\t   <div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\"> classifier = TextBlob(processedTweet[i], analyzer=NaiveBayesAnalyzer())\n\t    classification = classifier.sentiment.classification</div>\n\t    <span class=\"hljs-comment\">#print processedTweet[i],\"Polarity=\",classification</span>\n\t    \n\t    <span class=\"hljs-keyword\">if</span> classification == <span class=\"hljs-string\">\"pos\"</span>:\n\t        pos = pos + <span class=\"hljs-number\">1</span>\n\t        <span class=\"hljs-comment\">#print pos;</span>\n\t    <span class=\"hljs-keyword\">elif</span> classification == <span class=\"hljs-string\">\"neg\"</span>:     \n\t        neg = neg + <span class=\"hljs-number\">1</span>\n\t        <span class=\"hljs-comment\">#print neg</span>\n\t    <span class=\"hljs-keyword\">else</span>:\n\t        neutral = neutral + <span class=\"hljs-number\">1</span> \n\n\tfinal = []\n\tfinal.append(neg);\n\tfinal.append(neutral);\n\tfinal.append(pos);\n\n\t<span class=\"hljs-keyword\">return</span> final  \n\t<span class=\"hljs-comment\">#https://github.com/muthuvenki/Trend-Analysis/blob/master/sentimental_anlysis/views.py</span></code></pre></div>",
    "thr_17.py": "<div class=\"codeBlock hljs python\" id=\"thr_17\"><pre id=\"thr_17_code\" ><code class=\"python\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">from</span> sklearn.feature_extraction.text <span class=\"hljs-keyword\">import</span> CountVectorizer,TfidfVectorizer\n<span class=\"hljs-keyword\">from</span> sklearn.base <span class=\"hljs-keyword\">import</span> TransformerMixin\n<span class=\"hljs-keyword\">from</span> sklearn.pipeline <span class=\"hljs-keyword\">import</span> Pipeline\n\ndf_amazon = pd.read_csv (<span class=\"hljs-string\">\"datasets/amazon_alexa.tsv\"</span>, sep=<span class=\"hljs-string\">\"\\t\"</span>)\n\n<span class=\"hljs-keyword\">import</span> string\n<span class=\"hljs-keyword\">from</span> spacy.lang.en.stop_words <span class=\"hljs-keyword\">import</span> STOP_WORDS\n<span class=\"hljs-keyword\">from</span> spacy.lang.en <span class=\"hljs-keyword\">import</span> English\n\n<span class=\"hljs-comment\"># Create our list of punctuation marks</span>\npunctuations = string.punctuation\n\n<span class=\"hljs-comment\"># Create our list of stopwords</span>\nnlp = spacy.load(<span class=\"hljs-string\">'en'</span>)\n<div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stop_words = spacy.lang.en.stop_words.STOP_WORDS</div>\n\n<span class=\"hljs-comment\"># Load English tokenizer, tagger, parser, NER and word vectors</span>\nparser = English()\n\n<span class=\"hljs-comment\"># Creating our tokenizer function</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">spacy_tokenizer</span>(<span class=\"hljs-params\">sentence</span>):</span>\n    <span class=\"hljs-comment\"># Creating our token object, which is used to create documents with linguistic annotations.</span>\n    <div style=\"display: inline;\" id=\"parsing_0\" class=\"highlights fea_parsing\">mytokens = parser(sentence)</div>\n\n    <span class=\"hljs-comment\"># Lemmatizing each token and converting each token into lowercase</span>\n    mytokens = [ <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">word.lemma_.lower()</div>.strip() <span class=\"hljs-keyword\">if</span> word.lemma_ != <span class=\"hljs-string\">\"-PRON-\"</span> <span class=\"hljs-keyword\">else</span> word.lower_ <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> mytokens ]\n\n    <span class=\"hljs-comment\"># Removing stop words</span>\n    mytokens = [ word <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> mytokens <span class=\"hljs-keyword\">if</span> word <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> stop_words <span class=\"hljs-keyword\">and</span> word <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">in</span> punctuations ]\n\n    <span class=\"hljs-comment\"># return preprocessed list of tokens</span>\n    <span class=\"hljs-keyword\">return</span> mytokens\n\n<span class=\"hljs-comment\"># Custom transformer using spaCy</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">predictors</span>(<span class=\"hljs-params\">TransformerMixin</span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">transform</span>(<span class=\"hljs-params\">self, X, **transform_params</span>):</span>\n        <span class=\"hljs-comment\"># Cleaning Text</span>\n        <span class=\"hljs-keyword\">return</span> [clean_text(text) <span class=\"hljs-keyword\">for</span> text <span class=\"hljs-keyword\">in</span> X]\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">fit</span>(<span class=\"hljs-params\">self, X, y=<span class=\"hljs-literal\">None</span>, **fit_params</span>):</span>\n        <span class=\"hljs-keyword\">return</span> self\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_params</span>(<span class=\"hljs-params\">self, deep=<span class=\"hljs-literal\">True</span></span>):</span>\n        <span class=\"hljs-keyword\">return</span> {}\n\n<span class=\"hljs-comment\"># Basic function to clean the text</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">clean_text</span>(<span class=\"hljs-params\">text</span>):</span>\n    <span class=\"hljs-comment\"># Removing spaces and converting text into lowercase</span>\n    <span class=\"hljs-keyword\">return</span> text.strip().lower()\n\n<div style=\"display: inline;\" id=\"word_vectors_0\" class=\"highlights fea_word_vectors\">bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>))</div>\n\ntfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)\n\n<span class=\"hljs-keyword\">from</span> sklearn.model_selection <span class=\"hljs-keyword\">import</span> train_test_split\n\nX = df_amazon[<span class=\"hljs-string\">'verified_reviews'</span>] <span class=\"hljs-comment\"># the features we want to analyze</span>\nylabels = df_amazon[<span class=\"hljs-string\">'feedback'</span>] <span class=\"hljs-comment\"># the labels, or answers, we want to test against</span>\n\nX_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=<span class=\"hljs-number\">0.3</span>)\n\n<span class=\"hljs-comment\"># Logistic Regression Classifier</span>\n<span class=\"hljs-keyword\">from</span> sklearn.linear_model <span class=\"hljs-keyword\">import</span> LogisticRegression\n<div style=\"display: inline;\" id=\"classification_0\" class=\"highlights fea_classification\">classifier = LogisticRegression()</div>\n\n<span class=\"hljs-comment\"># Create pipeline using Bag of Words</span>\npipe = Pipeline([(<span class=\"hljs-string\">\"cleaner\"</span>, predictors()),\n                 (<span class=\"hljs-string\">'vectorizer'</span>, bow_vector),\n                 (<span class=\"hljs-string\">'classifier'</span>, classifier)])\n\n<span class=\"hljs-comment\"># model generation</span>\npipe.fit(X_train,y_train)\n\n<span class=\"hljs-keyword\">from</span> sklearn <span class=\"hljs-keyword\">import</span> metrics\n<span class=\"hljs-comment\"># Predicting with a test dataset</span>\npredicted = pipe.predict(X_test)\n\n<span class=\"hljs-comment\"># Model Accuracy</span>\nprint(<span class=\"hljs-string\">\"Logistic Regression Accuracy:\"</span>,metrics.accuracy_score(y_test, predicted))\nprint(<span class=\"hljs-string\">\"Logistic Regression Precision:\"</span>,metrics.precision_score(y_test, predicted))\nprint(<span class=\"hljs-string\">\"Logistic Regression Recall:\"</span>,metrics.recall_score(y_test, predicted))</code></pre></div>",
    "thr_10.py": "<div class=\"codeBlock hljs coffeescript\" id=\"thr_10\"><pre id=\"thr_10_code\" ><code class=\"python\"><span class=\"hljs-comment\"># Check if word vector is available</span>\n<span class=\"hljs-keyword\">import</span> spacy\n\n<span class=\"hljs-comment\"># Loading a spacy model</span>\nnlp = spacy.load(<span class=\"hljs-string\">\"en_core_web_md\"</span>)\ntokens = nlp(<span class=\"hljs-string\">\"I am an excellent cook\"</span>)\n\n<span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> tokens:\n  <span class=\"hljs-built_in\">print</span>(token.text ,<span class=\"hljs-string\">' '</span>,token.has_vector)\n  <span class=\"hljs-built_in\">print</span>(token.text,<span class=\"hljs-string\">' '</span>,<div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">token.vector_norm</div>)\n\nreview_1=nlp(<span class=\"hljs-string\">' The food was amazing'</span>)\nreview_2=nlp(<span class=\"hljs-string\">'The food was excellent'</span>)\nreview_3=nlp(<span class=\"hljs-string\">'I did not like the food'</span>)\nreview_4=nlp(<span class=\"hljs-string\">'It was very bad experience'</span>)\n\n<div style=\"display: inline;\" id=\"text_similarity_0\" class=\"highlights fea_text_similarity\">score_1=review_1.similarity(review_2)</div>\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">'Similarity between review 1 and 2'</span>,score_1)\n\n<div style=\"display: inline;\" id=\"text_similarity_1\" class=\"highlights fea_text_similarity\">score_2=review_3.similarity(review_4)</div>\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">'Similarity between review 3 and 4'</span>,score_2)\n\n<span class=\"hljs-comment\">#https://www.machinelearningplus.com/spacy-tutorial-nlp/#mergingandsplittingtokenswithretokenize</span></code></pre></div>",
    "thr_12.py": "<div class=\"codeBlock hljs python\" id=\"thr_12\"><pre id=\"thr_12_code\" ><code class=\"python\"><span class=\"hljs-string\">\"\"\"\nThis script extracts features from the transcript txt file and saves them to .csv files\nso they can be used in any toolkkit.\n\"\"\"</span>\n\n<span class=\"hljs-keyword\">import</span> csv\n<span class=\"hljs-keyword\">import</span> spacy\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">main</span>():</span>\n    <span class=\"hljs-string\">\"\"\"Loads the model and processes it.\n    \n    The model used can be installed by running this command on your CMD/Terminal:\n\n    python -m spacy download es_core_news_md\n    \n    \"\"\"</span>\n\n    corpus = <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"transcript_clean.txt\"</span>, <span class=\"hljs-string\">\"r\"</span>, encoding=<span class=\"hljs-string\">\"utf-8\"</span>).read()\n    nlp = spacy.load(<span class=\"hljs-string\">\"es_core_news_md\"</span>)\n\n    <span class=\"hljs-comment\"># Our corpus is bigger than the default limit, we will set</span>\n    <span class=\"hljs-comment\"># a new limit equal to its length.</span>\n    nlp.max_length = <span class=\"hljs-built_in\">len</span>(corpus)\n\n    doc = nlp(corpus)\n\n    get_tokens(doc)\n    get_entities(doc)\n    get_sentences(doc)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\"></span><div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\"><span class=\"hljs-title\">get_tokens</span>(<span class=\"hljs-params\">doc</span>)</div>:</span>\n    <span class=\"hljs-string\">\"\"\"Get the tokens and save them to .csv\n\n    Parameters\n    ----------\n    doc : spacy.doc\n        A doc object.\n\n    \"\"\"</span>\n\n    data_list = [[<span class=\"hljs-string\">\"text\"</span>, <span class=\"hljs-string\">\"text_lower\"</span>, <span class=\"hljs-string\">\"lemma\"</span>, <span class=\"hljs-string\">\"lemma_lower\"</span>,\n                  <span class=\"hljs-string\">\"part_of_speech\"</span>, <span class=\"hljs-string\">\"is_alphabet\"</span>, <span class=\"hljs-string\">\"is_stopword\"</span>]]\n\n    <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> doc:\n        data_list.append([\n            <div style=\"display: inline;\" id=\"tokenization_1\" class=\"highlights fea_tokenization\">token.text, token.lower_</div>, <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">token.lemma_, token.lemma_.lower()</div>,\n            <div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">token.pos_</div>, token.is_alpha, token.is_stop\n        ])\n\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"./tokens.csv\"</span>, <span class=\"hljs-string\">\"w\"</span>, encoding=<span class=\"hljs-string\">\"utf-8\"</span>, newline=<span class=\"hljs-string\">\"\"</span>) <span class=\"hljs-keyword\">as</span> tokens_file:\n        csv.writer(tokens_file).writerows(data_list)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_entities</span>(<span class=\"hljs-params\">doc</span>):</span>\n    <span class=\"hljs-string\">\"\"\"Get the entities and save them to .csv\n\n    Parameters\n    ----------\n    doc : spacy.doc\n        A doc object.\n\n    \"\"\"</span>\n\n    data_list = [[<span class=\"hljs-string\">\"text\"</span>, <span class=\"hljs-string\">\"text_lower\"</span>, <span class=\"hljs-string\">\"label\"</span>]]\n\n    <span class=\"hljs-keyword\">for</span> ent <span class=\"hljs-keyword\">in</span> doc.ents:\n        data_list.append([ent.text, ent.lower_, ent.label_])\n\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"./entities.csv\"</span>, <span class=\"hljs-string\">\"w\"</span>, encoding=<span class=\"hljs-string\">\"utf-8\"</span>, newline=<span class=\"hljs-string\">\"\"</span>) <span class=\"hljs-keyword\">as</span> entities_file:\n        csv.writer(entities_file).writerows(data_list)\n\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_sentences</span>(<span class=\"hljs-params\">doc</span>):</span>\n    <span class=\"hljs-string\">\"\"\"Get the sentences, score and save them to .csv\n\n    You will require to download the dataset (zip) from the following url:\n\n    https://www.kaggle.com/rtatman/sentiment-lexicons-for-81-languages\n\n    Once downloaded you will require to extract 2 .txt files:\n\n    negative_words_es.txt\n    positive_words_es.txt\n\n    Parameters\n    ----------\n    doc : spacy.doc\n        A doc object.\n\n    \"\"\"</span>\n\n    <span class=\"hljs-comment\"># Load positive and negative words into lists.</span>\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"positive_words_es.txt\"</span>, <span class=\"hljs-string\">\"r\"</span>, encoding=<span class=\"hljs-string\">\"utf-8\"</span>) <span class=\"hljs-keyword\">as</span> temp_file:\n        positive_words = temp_file.read().splitlines()\n\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"negative_words_es.txt\"</span>, <span class=\"hljs-string\">\"r\"</span>, encoding=<span class=\"hljs-string\">\"utf-8\"</span>) <span class=\"hljs-keyword\">as</span> temp_file:\n        negative_words = temp_file.read().splitlines()\n\n    data_list = [[<span class=\"hljs-string\">\"text\"</span>, <span class=\"hljs-string\">\"score\"</span>]]\n\n    <span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> doc.sents:\n\n        <span class=\"hljs-comment\"># Only take into account real sentences.</span>\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(sent.text) &gt; <span class=\"hljs-number\">10</span>:\n\n            score = <span class=\"hljs-number\">0</span>\n\n            <span class=\"hljs-comment\"># Start scoring the sentence.</span>\n            <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> sent:\n\n                <span class=\"hljs-keyword\">if</span> word.lower_ <span class=\"hljs-keyword\">in</span> positive_words:\n                    score += <span class=\"hljs-number\">1</span>\n\n                <span class=\"hljs-keyword\">if</span> word.lower_ <span class=\"hljs-keyword\">in</span> negative_words:\n                    score -= <span class=\"hljs-number\">1</span>\n\n            data_list.append([sent.text, score])\n\n\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"./sentences.csv\"</span>, <span class=\"hljs-string\">\"w\"</span>, encoding=<span class=\"hljs-string\">\"utf-8\"</span>, newline=<span class=\"hljs-string\">\"\"</span>) <span class=\"hljs-keyword\">as</span> sentences_file:\n        csv.writer(sentences_file).writerows(data_list)\n\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n\n    main()\n    https://github.com/PhantomInsights/mexican-government-report/blob/master/scripts/step2.py</code></pre></div>",
    "thr_18.py": "<div class=\"codeBlock hljs python\" id=\"thr_18\"><pre id=\"thr_18_code\" ><code class=\"python\">survey_text = (<span class=\"hljs-string\">'Out of 5 people surveyed, James Robert,'</span>\n               <span class=\"hljs-string\">' Julie Fuller and Benjamin Brooks like'</span>\n               <span class=\"hljs-string\">' apples. Kelly Cox and Matthew Evans'</span>\n               <span class=\"hljs-string\">' like oranges.'</span>)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">replace_person_names</span>(<span class=\"hljs-params\">token</span>):</span>\n    <span class=\"hljs-keyword\"></span><div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\"><span class=\"hljs-keyword\">if</span> token.ent_iob != <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">and</span> token.ent_type_ == <span class=\"hljs-string\">'PERSON'</span>:</div>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">'[REDACTED] '</span>\n    <span class=\"hljs-keyword\">return</span> token.string\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\"></span><div style=\"display: inline;\" id=\"named_entity_recognition_0\" class=\"highlights fea_named_entity_recognition\"><span class=\"hljs-title\">redact_names</span>(<span class=\"hljs-params\">nlp_doc</span>):</div></span>\n    <span class=\"hljs-keyword\">for</span> ent <span class=\"hljs-keyword\">in</span> nlp_doc.ents:\n        ent.merge()\n    tokens = <span class=\"hljs-built_in\">map</span>(replace_person_names, nlp_doc)\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">''</span>.join(tokens)\n\nsurvey_doc = nlp(survey_text)\nredact_names(survey_doc)</code></pre></div>",
    "thr_20.py": "<div class=\"codeBlock hljs python\" id=\"thr_20\"><pre id=\"thr_20_code\" ><code class=\"python\">one_about_text = (<span class=\"hljs-string\">'Gus Proto is a Python developer'</span>\n    <span class=\"hljs-string\">' currently working for a London-based Fintech company'</span>)\none_about_doc = nlp(one_about_text)\n<span class=\"hljs-comment\"># Extract children of `developer`</span>\nprint([token.text <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> one_about_doc[<span class=\"hljs-number\">5</span>].children])\n\n<span class=\"hljs-comment\"># Extract previous neighboring node of `developer`</span>\n<span class=\"hljs-built_in\">print</span> (one_about_doc[<span class=\"hljs-number\">5</span>].nbor(-<span class=\"hljs-number\">1</span>))\n\n<span class=\"hljs-comment\"># Extract next neighboring node of `developer`</span>\n<span class=\"hljs-built_in\">print</span> (one_about_doc[<span class=\"hljs-number\">5</span>].nbor())\n\n<span class=\"hljs-comment\"># Extract all tokens on the left of `developer`</span>\nprint([token.text <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> one_about_doc[<span class=\"hljs-number\">5</span>].lefts])\n\n<span class=\"hljs-comment\"># Extract tokens on the right of `developer`</span>\nprint([<div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">token.text <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> one_about_doc[<span class=\"hljs-number\">5</span>].rights</div>])\n\n<span class=\"hljs-comment\"># Print subtree of `developer`</span>\n<span class=\"hljs-built_in\">print</span> (<span class=\"hljs-built_in\">list</span>(one_about_doc[<span class=\"hljs-number\">5</span>].subtree))\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">flatten_tree</span>(<span class=\"hljs-params\">tree</span>):</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">''</span>.join([token.text_with_ws <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">list</span>(tree)]).strip()\n\n<span class=\"hljs-comment\"># Print flattened subtree of `developer`</span>\n<span class=\"hljs-built_in\">print</span> (flatten_tree(one_about_doc[<span class=\"hljs-number\">5</span>].subtree))</code></pre></div>",
    "thr_27.py": "<div class=\"codeBlock hljs python\" id=\"thr_27\"><pre id=\"thr_27_code\" ><code class=\"python\"><span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> spacy\n<span class=\"hljs-keyword\">from</span> spacy.tokenizer <span class=\"hljs-keyword\">import</span> Tokenizer\ncustom_nlp = spacy.load(<span class=\"hljs-string\">'en_core_web_sm'</span>)\n<div style=\"display: inline;\" id=\"text_simplify_0\" class=\"highlights fea_text_simplify\">prefix_re = spacy.util.compile_prefix_regex(custom_nlp.Defaults.prefixes)\nsuffix_re = spacy.util.compile_suffix_regex(custom_nlp.Defaults.suffixes)</div>\n<div style=\"display: inline;\" id=\"regular_expression_0\" class=\"highlights fea_regular_expression\">infix_re = re.<span class=\"hljs-built_in\">compile</span>(<span class=\"hljs-string\">r'''[-~]'''</span>)</div>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">customize_tokenizer</span>(<span class=\"hljs-params\">nlp</span>):</span>\n    <span class=\"hljs-comment\"># Adds support to use `-` as the delimiter for tokenization</span>\n    <span class=\"hljs-keyword\">return</span> <div style=\"display: inline;\" id=\"tokenization_0\" class=\"highlights fea_tokenization\">Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n                     suffix_search=suffix_re.search,\n                     infix_finditer=infix_re.finditer,\n                     token_match=<span class=\"hljs-literal\">None</span>\n                     )</div>\n\n\ncustom_nlp.tokenizer = customize_tokenizer(custom_nlp)\ncustom_tokenizer_about_doc = custom_nlp(about_text)\nprint([token.text <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> custom_tokenizer_about_doc])\n</code></pre></div>",
    "thr_22.py": "<div class=\"codeBlock hljs python\" id=\"thr_22\"><pre id=\"thr_22_code\" ><code class=\"python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">is_token_allowed</span>(<span class=\"hljs-params\">token</span>):</span>\n    <span class=\"hljs-string\">'''\n        Only allow valid tokens which are not stop words\n        and punctuation symbols.\n    '''</span>\n    <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-keyword\">not</span> token <span class=\"hljs-keyword\">or</span> <span class=\"hljs-keyword\">not</span> token.string.strip() <span class=\"hljs-keyword\">or</span>\n        token.is_stop <span class=\"hljs-keyword\">or</span> token.is_punct):\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">False</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">True</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">preprocess_token</span>(<span class=\"hljs-params\">token</span>):</span>\n    <span class=\"hljs-comment\"># Reduce token to its lowercase lemma form</span>\n    <span class=\"hljs-keyword\">return</span> <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">token.lemma_</div>.strip().lower()\n\ncomplete_filtered_tokens = [preprocess_token(token)\n    <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> complete_doc <span class=\"hljs-keyword\">if</span> is_token_allowed(token)]\ncomplete_filtered_tokens</code></pre></div>",
    "thr_26.py": "<div class=\"codeBlock hljs coffeescript\" id=\"thr_26\"><pre id=\"thr_26_code\" ><code class=\"python\"><span class=\"hljs-keyword\">import</span> spacy\nnlp = spacy.load(<span class=\"hljs-string\">'en_core_web_sm'</span>)\n\nconference_help_text = (<span class=\"hljs-string\">'Gus is helping organize a developer'</span>\n    <span class=\"hljs-string\">'conference on Applications of Natural Language'</span>\n    <span class=\"hljs-string\">' Processing. He keeps organizing local Python meetups'</span>\n    <span class=\"hljs-string\">' and several internal talks at his workplace.'</span>)\nconference_help_doc = nlp(conference_help_text)\n<span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> conference_help_doc:\n    <span class=\"hljs-built_in\">print</span> (token, <div style=\"display: inline;\" id=\"lemmatization_0\" class=\"highlights fea_lemmatization\">token.lemma_</div>)</code></pre></div>",
    "thr_13.py": "<div class=\"codeBlock hljs makefile\" id=\"thr_13\"><pre id=\"thr_13_code\" ><code class=\"python\"><span class=\"hljs-comment\"># Construction via add_pipe with default model</span>\ntok2vec = nlp.add_pipe(<span class=\"hljs-string\">\"tok2vec\"</span>)\n\n<span class=\"hljs-comment\"># Construction via add_pipe with custom model</span>\nconfig = {<span class=\"hljs-string\">\"model\"</span>: {<span class=\"hljs-string\">\"@architectures</span><span class=\"hljs-string\">\"</span>: <span class=\"hljs-string\">\"my_tok2vec\"</span>}}\nparser = nlp.add_pipe(<span class=\"hljs-string\">\"tok2vec\"</span>, config=config)\n\n<span class=\"hljs-comment\"># Construction from class</span>\n<div style=\"display: inline;\" id=\"word_vectors_0\" class=\"highlights fea_word_vectors\">from spacy.pipeline import Tok2Vec\ntok2vec = Tok2Vec(nlp.vocab, model)</div>\n<span class=\"hljs-comment\">#https://spacy.io/api/tok2vec</span></code></pre></div>",
    "thr_5.py": "<div class=\"codeBlock hljs coffeescript\" id=\"thr_5\"><pre id=\"thr_5_code\" ><code class=\"python\"><span class=\"hljs-keyword\">from</span> spacy.training <span class=\"hljs-keyword\">import</span> JsonlCorpus\n<span class=\"hljs-keyword\">import</span> spacy\n\n<div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">corpus = JsonlCorpus(<span class=\"hljs-string\">\"./texts.jsonl\"</span>)</div>\nnlp = spacy.blank(<span class=\"hljs-string\">\"en\"</span>)\ndata = corpus(nlp)\n\n<span class=\"hljs-comment\">#https://spacy.io/api/corpus</span></code></pre></div>",
    "thr_6.py": "<div class=\"codeBlock hljs typescript\" id=\"thr_6\"><pre id=\"thr_6_code\" ><code class=\"python\"><span class=\"hljs-keyword\">import</span> spacy\n<span class=\"hljs-keyword\">from</span> spacy.lang.en.stop_words <span class=\"hljs-keyword\">import</span> STOP_WORDS\n<span class=\"hljs-keyword\">from</span> <span class=\"hljs-built_in\">string</span> <span class=\"hljs-keyword\">import</span> punctuation\n<span class=\"hljs-keyword\">from</span> collections <span class=\"hljs-keyword\">import</span> Counter\n<span class=\"hljs-keyword\">from</span> heapq <span class=\"hljs-keyword\">import</span> nlargest\n\ndoc =<span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task. Machine learning algorithms build a mathematical model of sample data, known as \"</span>training data<span class=\"hljs-string\">\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory data analysis through unsupervised learning.In its application across business problems, machine learning is also referred to as predictive analytics.\"</span><span class=\"hljs-string\">\"\"</span>\n\nnlp = spacy.load(<span class=\"hljs-string\">'en'</span>)\ndoc = nlp(doc)\n\nkeyword = []\n<div style=\"display: inline;\" id=\"nlp_datasets_0\" class=\"highlights fea_nlp_datasets\">stopwords = list(STOP_WORDS)</div>\npos_tag = [<span class=\"hljs-string\">'PROPN'</span>, <span class=\"hljs-string\">'ADJ'</span>, <span class=\"hljs-string\">'NOUN'</span>, <span class=\"hljs-string\">'VERB'</span>]\n<span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> doc:\n    <span class=\"hljs-keyword\">if</span>(token.text <span class=\"hljs-keyword\">in</span> stopwords or token.text <span class=\"hljs-keyword\">in</span> punctuation):\n        <span class=\"hljs-keyword\">continue</span>\n    <span class=\"hljs-keyword\">if</span>(token.pos_ <span class=\"hljs-keyword\">in</span> pos_tag):\n        keyword.append(token.text)\n\nfreq_word = Counter(keyword)\n\nmax_freq = Counter(keyword).most_common(<span class=\"hljs-number\">1</span>)[<span class=\"hljs-number\">0</span>][<span class=\"hljs-number\">1</span>]\n<span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> freq_word.keys():  \n        freq_word[word] = (freq_word[word]/max_freq)\n\nsent_strength={}\n<span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> doc.sents:\n    <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> sent:\n        <span class=\"hljs-keyword\">if</span> word.text <span class=\"hljs-keyword\">in</span> freq_word.keys():\n            <span class=\"hljs-keyword\">if</span> sent <span class=\"hljs-keyword\">in</span> sent_strength.keys():\n                sent_strength[sent]+=freq_word[word.text]\n            <span class=\"hljs-attr\">else</span>:\n                sent_strength[sent]=freq_word[word.text]\nprint(sent_strength)\n\n<div style=\"display: inline;\" id=\"summarizer_0\" class=\"highlights fea_summarizer\">summarized_sentences = nlargest(<span class=\"hljs-number\">3</span>, sent_strength, key=sent_strength.get)</div>\n\nfinal_sentences = [ w.text <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> summarized_sentences ]\nsummary = <span class=\"hljs-string\">' '</span>.join(final_sentences)</code></pre></div>",
    "thr_25.py": "<div class=\"codeBlock hljs vbnet\" id=\"thr_25\"><pre id=\"thr_25_code\" ><code class=\"python\"><span class=\"hljs-keyword\">from</span> collections import Counter\ncomplete_text = (<span class=\"hljs-comment\">'Gus Proto is a Python developer currently'</span>\n    <span class=\"hljs-comment\">'working for a London-based Fintech company. He is'</span>\n    <span class=\"hljs-comment\">' interested in learning Natural Language Processing.'</span>\n    <span class=\"hljs-comment\">' There is a developer conference happening on 21 July'</span>\n    <span class=\"hljs-comment\">' 2019 in London. It is titled \"Applications of Natural'</span>\n    <span class=\"hljs-comment\">' Language Processing\". There is a helpline number '</span>\n    <span class=\"hljs-comment\">' available at +1-1234567891. Gus is helping organize it.'</span>\n    <span class=\"hljs-comment\">' He keeps organizing local Python meetups and several'</span>\n    <span class=\"hljs-comment\">' internal talks at his workplace. Gus is also presenting'</span>\n    <span class=\"hljs-comment\">' a talk. The talk will introduce the reader about \"Use'</span>\n    <span class=\"hljs-comment\">' cases of Natural Language Processing in Fintech\".'</span>\n    <span class=\"hljs-comment\">' Apart from his work, he is very passionate about music.'</span>\n    <span class=\"hljs-comment\">' Gus is learning to play the Piano. He has enrolled '</span>\n    <span class=\"hljs-comment\">' himself in the weekend batch of Great Piano Academy.'</span>\n    <span class=\"hljs-comment\">' Great Piano Academy is situated in Mayfair or the City'</span>\n    <span class=\"hljs-comment\">' of London and has world-class piano instructors.')</span>\n\ncomplete_doc = nlp(complete_text)\n# Remove <span class=\"hljs-keyword\">stop</span> words <span class=\"hljs-built_in\">and</span> punctuation symbols\nwords = [token.<span class=\"hljs-keyword\">text</span> <span class=\"hljs-keyword\">for</span> token <span class=\"hljs-keyword\">in</span> complete_doc\n         <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">not</span> token.is_stop <span class=\"hljs-built_in\">and</span> <span class=\"hljs-built_in\">not</span> token.is_punct]\n<div style=\"display: inline;\" id=\"word_frequency_0\" class=\"highlights fea_word_frequency\">word_freq = Counter(words)</div>\n# <span class=\"hljs-number\">5</span> commonly occurring words <span class=\"hljs-keyword\">with</span> their frequencies\ncommon_words = word_freq.most_common(<span class=\"hljs-number\">5</span>)\nprint (common_words)\n\n# Unique words\nunique_words = [word <span class=\"hljs-keyword\">for</span> (word, freq) <span class=\"hljs-keyword\">in</span> word_freq.items() <span class=\"hljs-keyword\">if</span> freq == <span class=\"hljs-number\">1</span>]\nprint (unique_words)</code></pre></div>",
    "thr_24.py": "<div class=\"codeBlock hljs go\" id=\"thr_24\"><pre id=\"thr_24_code\" ><code class=\"python\">nouns = []\nadjectives = []\n<span class=\"hljs-keyword\">for</span> token in about_doc:\n    <span class=\"hljs-keyword\">if</span> <div style=\"display: inline;\" id=\"Part_of_Speech_0\" class=\"highlights fea_Part_of_Speech\">token.pos_</div> == <span class=\"hljs-string\">'NOUN'</span>:\n        nouns.<span class=\"hljs-built_in\">append</span>(token)\n    <span class=\"hljs-keyword\">if</span> <div style=\"display: inline;\" id=\"n_grams_0\" class=\"highlights fea_n_grams\">token.pos_ == <span class=\"hljs-string\">'ADJ'</span>:</div>\n        adjectives.<span class=\"hljs-built_in\">append</span>(token)\n    <span class=\"hljs-built_in\">print</span> (token, <div style=\"display: inline;\" id=\"tagger_0\" class=\"highlights fea_tagger\">token.tag_</div>, token.pos_, spacy.explain(token.tag_))</code></pre></div>",
    "thr_11.py": "<div class=\"codeBlock hljs python\" id=\"thr_11\"><pre id=\"thr_11_code\" ><code class=\"python\"><span class=\"hljs-keyword\">from</span> skweak.base <span class=\"hljs-keyword\">import</span> SpanAnnotator\n<span class=\"hljs-keyword\">import</span> spacy\n<span class=\"hljs-keyword\">import</span> itertools\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">from</span> spacy.tokens <span class=\"hljs-keyword\">import</span> Doc, Span  <span class=\"hljs-comment\"># type: ignore</span>\n<span class=\"hljs-keyword\">from</span> typing <span class=\"hljs-keyword\">import</span> Tuple, Iterable, List\n\n<span class=\"hljs-comment\">####################################################################</span>\n<span class=\"hljs-comment\"># Labelling source based on neural models</span>\n<span class=\"hljs-comment\">####################################################################</span>\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ModelAnnotator</span>(<span class=\"hljs-params\">SpanAnnotator</span>):</span>\n    <span class=\"hljs-string\">\"\"\"Annotation based on a spacy NER model\"\"\"</span>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, name:<span class=\"hljs-built_in\">str</span>, model_path:<span class=\"hljs-built_in\">str</span>, \n                 disabled:List[<span class=\"hljs-built_in\">str</span>]=[<span class=\"hljs-string\">\"parser\"</span>, <span class=\"hljs-string\">\"tagger\"</span>, <span class=\"hljs-string\">\"lemmatizer\"</span>, <span class=\"hljs-string\">\"attribute_ruler\"</span>]</span>):</span>\n        <span class=\"hljs-string\">\"\"\"Creates a new annotator based on a Spacy model. \"\"\"</span>\n        \n        <span class=\"hljs-built_in\">super</span>(ModelAnnotator, self).__init__(name)\n        self.model = spacy.load(model_path, disable=disabled)\n\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">find_spans</span>(<span class=\"hljs-params\">self, doc: Doc</span>) -&gt; Iterable[Tuple[int, int, str]]:</span>\n        <span class=\"hljs-string\">\"\"\"Annotates one single document using the Spacy NER model\"\"\"</span>\n\n        <span class=\"hljs-comment\"># Create a new document (to avoid conflicting annotations)</span>\n        doc2 = self.create_new_doc(doc)\n        <span class=\"hljs-comment\"># And run the model</span>\n        <span class=\"hljs-keyword\">for</span> _, proc <span class=\"hljs-keyword\">in</span> self.model.pipeline:\n            doc2 = proc(doc2)\n        <span class=\"hljs-comment\"># Add the annotation</span>\n        <span class=\"hljs-keyword\">for</span> ent <span class=\"hljs-keyword\">in</span> doc2.ents:\n            <span class=\"hljs-keyword\">yield</span> ent.start, ent.end, ent.label_\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">pipe</span>(<span class=\"hljs-params\">self, docs: Iterable[Doc]</span>) -&gt; Iterable[Doc]:</span>\n        <span class=\"hljs-string\">\"\"\"Annotates the stream of documents based on the Spacy model\"\"\"</span>\n\n        stream1, stream2 = itertools.tee(docs, <span class=\"hljs-number\">2</span>)\n\n        <span class=\"hljs-comment\"># Remove existing entities from the document</span>\n        stream2 = (self.create_new_doc(d) <span class=\"hljs-keyword\">for</span> d <span class=\"hljs-keyword\">in</span> stream2)\n        \n        <span class=\"hljs-comment\"># And run the model</span>\n        <span class=\"hljs-keyword\">for</span> _, proc <span class=\"hljs-keyword\">in</span> self.model.pipeline:\n            stream2 = proc.pipe(stream2)\n        \n        <span class=\"hljs-keyword\">for</span> doc, doc_copy <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">zip</span>(stream1, stream2):\n\n            doc.spans[self.name] = []\n\n            <span class=\"hljs-comment\"># Add the annotation</span>\n            <span class=\"hljs-keyword\">for</span> ent <span class=\"hljs-keyword\">in</span> doc_copy.ents:\n                doc.spans[self.name].append(Span(doc, ent.start, ent.end, ent.label_))\n\n            <span class=\"hljs-keyword\">yield</span> doc\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">create_new_doc</span>(<span class=\"hljs-params\">self, doc: Doc</span>) -&gt; Doc:</span>\n        <span class=\"hljs-string\">\"\"\"Create a new, empty Doc (but with the same tokenisation as before)\"\"\"</span>\n\n        <span class=\"hljs-keyword\">return</span> spacy.tokens.Doc(self.model.vocab, [tok.text <span class=\"hljs-keyword\">for</span> tok <span class=\"hljs-keyword\">in</span> doc], <span class=\"hljs-comment\">#type: ignore</span>\n                               [tok.whitespace_ <span class=\"hljs-keyword\">for</span> tok <span class=\"hljs-keyword\">in</span> doc])\n\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">TruecaseAnnotator</span>(<span class=\"hljs-params\">ModelAnnotator</span>):</span>\n    <span class=\"hljs-string\">\"\"\"Spacy model annotator that preprocess all texts to convert them to a \n    \"truecased\" representation (see below)\"\"\"</span>\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, name:<span class=\"hljs-built_in\">str</span>, model_path:<span class=\"hljs-built_in\">str</span>, form_frequencies:<span class=\"hljs-built_in\">str</span>,\n                 disabled:List[<span class=\"hljs-built_in\">str</span>]=[<span class=\"hljs-string\">\"parser\"</span>, <span class=\"hljs-string\">\"tagger\"</span>, <span class=\"hljs-string\">\"lemmatizer\"</span>, <span class=\"hljs-string\">\"attribute_ruler\"</span>]</span>):</span>\n        <span class=\"hljs-string\">\"\"\"Creates a new annotator based on a Spacy model, and a dictionary containing\n        the most common case forms for a given word (to be able to truecase the document).\"\"\"</span>\n        \n        <span class=\"hljs-built_in\">super</span>(TruecaseAnnotator, self).__init__(name, model_path, disabled)\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(form_frequencies) <span class=\"hljs-keyword\">as</span> fd:\n            self.form_frequencies = json.load(fd)\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">create_new_doc</span>(<span class=\"hljs-params\">self, doc: Doc, min_prob: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.25</span></span>) -&gt; Doc:</span>\n        <span class=\"hljs-string\">\"\"\"Performs truecasing of the tokens in the spacy document. Based on relative \n        frequencies of word forms, tokens that \n        (1) are made of letters, with a first letter in uppercase\n        (2) and are not sentence start\n        (3) and have a relative frequency below min_prob\n        ... will be replaced by its most likely case (such as lowercase). \"\"\"</span>\n\n  <span class=\"hljs-comment\">#      print(\"running on\", doc[:10])</span>\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> self.form_frequencies:\n            <span class=\"hljs-keyword\">raise</span> RuntimeError(\n                <span class=\"hljs-string\">\"Cannot truecase without a dictionary of form frequencies\"</span>)\n\n        tokens = []\n        spaces = []\n        doctext = doc.text\n        <span class=\"hljs-keyword\">for</span> tok <span class=\"hljs-keyword\">in</span> doc:\n            toktext = tok.text\n\n            <span class=\"hljs-comment\"># We only change casing for words in Title or UPPER</span>\n            <span class=\"hljs-keyword\">if</span> tok.is_alpha <span class=\"hljs-keyword\">and</span> toktext[<span class=\"hljs-number\">0</span>].isupper():\n                cond1 = tok.is_upper <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\">len</span>(toktext) &gt; <span class=\"hljs-number\">2</span>  <span class=\"hljs-comment\"># word in uppercase</span>\n                cond2 = toktext[<span class=\"hljs-number\">0</span>].isupper(\n                ) <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> tok.is_sent_start  <span class=\"hljs-comment\"># titled word</span>\n                <span class=\"hljs-keyword\">if</span> cond1 <span class=\"hljs-keyword\">or</span> cond2:\n                    token_lc = toktext.lower()\n                    <span class=\"hljs-keyword\">if</span> token_lc <span class=\"hljs-keyword\">in</span> self.form_frequencies:\n                        frequencies = self.form_frequencies[token_lc]\n                        <span class=\"hljs-keyword\">if</span> frequencies.get(toktext, <span class=\"hljs-number\">0</span>) &lt; min_prob:\n                            alternative = <span class=\"hljs-built_in\">sorted</span>(\n                                frequencies.keys(), key=<span class=\"hljs-keyword\">lambda</span> x: frequencies[x])[-<span class=\"hljs-number\">1</span>]\n\n                            <span class=\"hljs-comment\"># We do not change from Title to to UPPER</span>\n                            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> tok.is_title <span class=\"hljs-keyword\">or</span> <span class=\"hljs-keyword\">not</span> alternative.isupper():\n                                toktext = alternative\n\n            tokens.append(toktext)\n\n            <span class=\"hljs-comment\"># Spacy needs to know whether the token is followed by a space</span>\n            <span class=\"hljs-keyword\">if</span> tok.i &lt; <span class=\"hljs-built_in\">len</span>(doc)-<span class=\"hljs-number\">1</span>:\n                spaces.append(doctext[tok.idx+<span class=\"hljs-built_in\">len</span>(tok)].isspace())\n            <span class=\"hljs-keyword\">else</span>:\n                spaces.append(<span class=\"hljs-literal\">False</span>)\n\n        <span class=\"hljs-comment\"># Creates a new document with the tokenised words and space information</span>\n        doc2 = Doc(self.<div style=\"display: inline;\" id=\"n_grams_0\" class=\"highlights fea_n_grams\">model.vocab</div>, words=tokens, spaces=spaces) <span class=\"hljs-comment\">#type: ignore</span>\n <span class=\"hljs-comment\">#       print(\"finished with doc\", doc2[:10])</span>\n        <span class=\"hljs-keyword\">return</span> doc2\n        <span class=\"hljs-comment\">#https://github.com/NorskRegnesentral/skweak/blob/main/skweak/spacy.py</span></code></pre></div>",
    "thr_19.py": "<div class=\"codeBlock hljs bash\" id=\"thr_19\"><pre id=\"thr_19_code\" ><code class=\"python\">conference_text = (<span class=\"hljs-string\">'There is a developer conference'</span>\n    <span class=\"hljs-string\">' happening on 21 July 2019 in London.'</span>)\nconference_doc = nlp(conference_text)\n<span class=\"hljs-comment\"># Extract Noun Phrases</span>\n<span class=\"hljs-keyword\">for</span> chunk <span class=\"hljs-keyword\">in</span> <div style=\"display: inline;\" id=\"n_grams_0\" class=\"highlights fea_n_grams\">conference_doc.noun_chunks</div>:\n    <span class=\"hljs-built_in\">print</span> (chunk)</code></pre></div>",
    "thr_8.py": "<div class=\"codeBlock hljs coffeescript\" id=\"thr_8\"><pre id=\"thr_8_code\" ><code class=\"python\"><span class=\"hljs-keyword\">import</span> spacy\n<span class=\"hljs-keyword\">import</span> contextualSpellCheck\n\nnlp = spacy.load(<span class=\"hljs-string\">'en_core_web_sm'</span>)\n<div style=\"display: inline;\" id=\"spellcheck_0\" class=\"highlights fea_spellcheck\">contextualSpellCheck.add_to_pipe(nlp)</div>\ndoc = nlp(<span class=\"hljs-string\">'Income was $9.4 milion compared to the prior year of $2.7 milion.'</span>)\n\n<span class=\"hljs-built_in\">print</span>(doc._.performed_spellCheck) <span class=\"hljs-comment\">#Should be True</span>\n<span class=\"hljs-built_in\">print</span>(doc._.outcome_spellCheck) <span class=\"hljs-comment\">#Income was $9.4 million compared to the prior year of $2.7 million.</span>\n<span class=\"hljs-comment\">#https://spacy.io/universe/project/contextualSpellCheck</span></code></pre></div>",
    "thr_7.py": "<div class=\"codeBlock hljs rust\" id=\"thr_7\"><pre id=\"thr_7_code\" ><code class=\"python\">import spacy\nfrom spacytextblob.spacytextblob import SpacyTextBlob\n\nnlp = spacy.load(<span class=\"hljs-symbol\">'en_core_web_sm</span>')\nnlp.add_pipe(<span class=\"hljs-symbol\">'spacytextblob</span>')\ntext = <span class=\"hljs-symbol\">'I</span> had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.'\ndoc = nlp(text)\n<div style=\"display: inline;\" id=\"sentiment_analysis_0\" class=\"highlights fea_sentiment_analysis\">doc._.polarity      # Polarity: -<span class=\"hljs-number\">0.125</span>\ndoc._.subjectivity</div>  # Sujectivity: <span class=\"hljs-number\">0.9</span>\n<div style=\"display: inline;\" id=\"text_scoring_0\" class=\"highlights fea_text_scoring\">doc._.assessments</div>   # Assessments: [([<span class=\"hljs-symbol\">'really</span>', <span class=\"hljs-symbol\">'horrible</span>'], -<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-literal\">None</span>), ([<span class=\"hljs-symbol\">'worst</span>', <span class=\"hljs-string\">'!'</span>], -<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-literal\">None</span>), ([<span class=\"hljs-symbol\">'really</span>', <span class=\"hljs-symbol\">'good</span>'], <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.6000000000000001</span>, <span class=\"hljs-literal\">None</span>), ([<span class=\"hljs-symbol\">'happy</span>'], <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-literal\">None</span>)]\n#https:<span class=\"hljs-comment\">//spacy.io/universe/project/spacy-textblob</span></code></pre></div>",
    "thr_9.py": "<div class=\"codeBlock hljs python\" id=\"thr_9\"><pre id=\"thr_9_code\" ><code class=\"python\"><span class=\"hljs-keyword\">import</span> spacy\n<span class=\"hljs-keyword\">from</span> spacy_langdetect <span class=\"hljs-keyword\">import</span> LanguageDetector\nnlp = spacy.load(<span class=\"hljs-string\">'en'</span>)\n<div style=\"display: inline;\" id=\"language_detection_0\" class=\"highlights fea_language_detection\">nlp.add_pipe(LanguageDetector(), name=<span class=\"hljs-string\">'language_detector'</span>, last=<span class=\"hljs-literal\">True</span>)</div>\ntext = <span class=\"hljs-string\">'This is an english text.'</span>\ndoc = nlp(text)\n<span class=\"hljs-comment\"># document level language detection. Think of it like average language of the document!</span>\nprint(doc._.language)\n<span class=\"hljs-comment\"># sentence level language detection</span>\n<span class=\"hljs-keyword\">for</span> sent <span class=\"hljs-keyword\">in</span> doc.sents:\n   print(sent, sent._.language)\n   <span class=\"hljs-comment\">#https://spacy.io/universe/project/spacy-langdetect</span></code></pre></div>"
  },
  "file concepts": {
    "fir_4.py": [
      "cat_Preprocessing",
      "fea_parsing",
      "fea_tokenization",
      "fea_lemmatization",
      "fea_tagger",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech",
      "fea_named_entity_recognition",
      "fea_dependency_parsing"
    ],
    "fir_16.py": [
      "cat_Preprocessing",
      "fea_parsing",
      "fea_tokenization",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "fir_17.py": [
      "cat_Preprocessing",
      "fea_parsing",
      "fea_tokenization",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "fir_23.py": [
      "cat_Preprocessing",
      "fea_parsing",
      "fea_tokenization",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "fir_1.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization",
      "fea_nlp_datasets"
    ],
    "fir_2.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_nlp_datasets",
      "fea_stemming"
    ],
    "fir_3.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization",
      "fea_nlp_datasets",
      "cat_Advanced_Analysis",
      "fea_summarizer"
    ],
    "fir_6.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization",
      "fea_tagger",
      "fea_n_grams",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "fir_8.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_nlp_datasets",
      "fea_stemming",
      "cat_Basic_Analysis",
      "fea_text_scoring",
      "cat_Advanced_Analysis",
      "fea_summarizer"
    ],
    "fir_9.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization",
      "fea_nlp_datasets",
      "cat_Advanced_Analysis",
      "fea_chatbot"
    ],
    "fir_10.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization"
    ],
    "fir_11.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "fir_12.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization",
      "fea_nlp_datasets",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "fir_13.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_nlp_datasets"
    ],
    "fir_14.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization",
      "fea_nlp_datasets"
    ],
    "fir_18.py": [
      "cat_Preprocessing",
      "fea_tokenization"
    ],
    "fir_19.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "cat_Basic_Analysis",
      "fea_text_similarity"
    ],
    "fir_20.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_nlp_datasets",
      "fea_stemming",
      "cat_Basic_Analysis",
      "fea_text_scoring"
    ],
    "fir_21.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_nlp_datasets",
      "fea_stemming",
      "cat_Basic_Analysis",
      "fea_text_scoring",
      "cat_Advanced_Analysis",
      "fea_summarizer"
    ],
    "fir_25.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization"
    ],
    "fir_29.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization",
      "fea_nlp_datasets",
      "cat_Basic_Analysis",
      "fea_text_scoring"
    ],
    "fir_30.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization",
      "fea_nlp_datasets",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech",
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "fir_24.py": [
      "cat_Preprocessing",
      "fea_lemmatization",
      "fea_nlp_datasets",
      "fea_word_frequency",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech",
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "fir_5.py": [
      "cat_Preprocessing",
      "fea_nlp_datasets",
      "fea_regular_expression"
    ],
    "fir_7.py": [
      "cat_Preprocessing",
      "fea_nlp_datasets"
    ],
    "fir_28.py": [
      "cat_Preprocessing",
      "fea_nlp_datasets",
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis",
      "fea_classification"
    ],
    "fir_22.py": [
      "cat_Preprocessing",
      "fea_word_frequency",
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "fir_27.py": [
      "cat_Preprocessing",
      "fea_word_frequency",
      "fea_tagger",
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "fir_26.py": [
      "cat_Preprocessing",
      "fea_n_grams"
    ],
    "fir_15.py": [
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "sec_7.py": [
      "cat_Preprocessing",
      "fea_parsing"
    ],
    "sec_10.py": [
      "cat_Preprocessing",
      "fea_parsing",
      "fea_tagger"
    ],
    "sec_2.py": [
      "cat_Preprocessing",
      "fea_lemmatization",
      "fea_text_simplify",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "sec_12.py": [
      "cat_Preprocessing",
      "fea_lemmatization",
      "cat_Basic_Analysis",
      "fea_spellcheck",
      "cat_Advanced_Analysis",
      "fea_translation",
      "fea_language_detection"
    ],
    "sec_6.py": [
      "cat_Preprocessing",
      "fea_tagger",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "sec_9.py": [
      "cat_Preprocessing",
      "fea_text_simplify",
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "sec_27.py": [
      "cat_Preprocessing",
      "fea_text_simplify",
      "fea_n_grams"
    ],
    "sec_1.py": [
      "cat_Preprocessing",
      "fea_n_grams"
    ],
    "sec_8.py": [
      "cat_Preprocessing",
      "fea_n_grams"
    ],
    "sec_17.py": [
      "cat_Basic_Analysis",
      "fea_spellcheck"
    ],
    "sec_26.py": [
      "cat_Basic_Analysis",
      "fea_text_scoring",
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis"
    ],
    "sec_29.py": [
      "cat_Basic_Analysis",
      "fea_text_scoring",
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis"
    ],
    "sec_15.py": [
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis"
    ],
    "sec_20.py": [
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis",
      "fea_classification"
    ],
    "sec_21.py": [
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis"
    ],
    "sec_24.py": [
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis"
    ],
    "sec_25.py": [
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis"
    ],
    "sec_28.py": [
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis"
    ],
    "sec_30.py": [
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis"
    ],
    "sec_14.py": [
      "cat_Advanced_Analysis",
      "fea_translation"
    ],
    "sec_16.py": [
      "cat_Advanced_Analysis",
      "fea_translation"
    ],
    "sec_19.py": [
      "cat_Advanced_Analysis",
      "fea_translation",
      "fea_language_detection"
    ],
    "sec_22.py": [
      "cat_Advanced_Analysis",
      "fea_translation"
    ],
    "sec_23.py": [
      "cat_Advanced_Analysis",
      "fea_translation",
      "fea_language_detection"
    ],
    "sec_11.py": [
      "cat_Advanced_Analysis",
      "fea_language_detection"
    ],
    "sec_18.py": [
      "cat_Advanced_Analysis",
      "fea_language_detection"
    ],
    "sec_4.py": [
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "sec_5.py": [
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "sec_13.py": [
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "thr_17.py": [
      "cat_Preprocessing",
      "fea_parsing",
      "fea_lemmatization",
      "fea_word_vectors",
      "fea_nlp_datasets",
      "cat_Advanced_Analysis",
      "fea_classification"
    ],
    "thr_10.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "cat_Basic_Analysis",
      "fea_text_similarity"
    ],
    "thr_12.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_lemmatization",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "thr_18.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "cat_Basic_Analysis",
      "fea_named_entity_recognition"
    ],
    "thr_20.py": [
      "cat_Preprocessing",
      "fea_tokenization"
    ],
    "thr_27.py": [
      "cat_Preprocessing",
      "fea_tokenization",
      "fea_regular_expression",
      "fea_text_simplify"
    ],
    "thr_22.py": [
      "cat_Preprocessing",
      "fea_lemmatization"
    ],
    "thr_26.py": [
      "cat_Preprocessing",
      "fea_lemmatization"
    ],
    "thr_13.py": [
      "cat_Preprocessing",
      "fea_word_vectors"
    ],
    "thr_5.py": [
      "cat_Preprocessing",
      "fea_nlp_datasets"
    ],
    "thr_6.py": [
      "cat_Preprocessing",
      "fea_nlp_datasets",
      "cat_Advanced_Analysis",
      "fea_summarizer"
    ],
    "thr_25.py": [
      "cat_Preprocessing",
      "fea_word_frequency"
    ],
    "thr_24.py": [
      "cat_Preprocessing",
      "fea_tagger",
      "fea_n_grams",
      "cat_Basic_Analysis",
      "fea_Part_of_Speech"
    ],
    "thr_11.py": [
      "cat_Preprocessing",
      "fea_n_grams"
    ],
    "thr_19.py": [
      "cat_Preprocessing",
      "fea_n_grams"
    ],
    "thr_8.py": [
      "cat_Basic_Analysis",
      "fea_spellcheck"
    ],
    "thr_7.py": [
      "cat_Basic_Analysis",
      "fea_text_scoring",
      "cat_Advanced_Analysis",
      "fea_sentiment_analysis"
    ],
    "thr_9.py": [
      "cat_Advanced_Analysis",
      "fea_language_detection"
    ]
  },
  "file info": {
    "fir_4.py": {
      "nlines": 427,
      "nchara": 30785
    },
    "fir_16.py": {
      "nlines": 186,
      "nchara": 11394
    },
    "fir_17.py": {
      "nlines": 215,
      "nchara": 14346
    },
    "fir_23.py": {
      "nlines": 119,
      "nchara": 9583
    },
    "fir_1.py": {
      "nlines": 62,
      "nchara": 3897
    },
    "fir_2.py": {
      "nlines": 61,
      "nchara": 5381
    },
    "fir_3.py": {
      "nlines": 230,
      "nchara": 18194
    },
    "fir_6.py": {
      "nlines": 542,
      "nchara": 44964
    },
    "fir_8.py": {
      "nlines": 169,
      "nchara": 40050
    },
    "fir_9.py": {
      "nlines": 64,
      "nchara": 6301
    },
    "fir_10.py": {
      "nlines": 64,
      "nchara": 6077
    },
    "fir_11.py": {
      "nlines": 80,
      "nchara": 4754
    },
    "fir_12.py": {
      "nlines": 108,
      "nchara": 8623
    },
    "fir_13.py": {
      "nlines": 158,
      "nchara": 17324
    },
    "fir_14.py": {
      "nlines": 160,
      "nchara": 17858
    },
    "fir_18.py": {
      "nlines": 178,
      "nchara": 13017
    },
    "fir_19.py": {
      "nlines": 180,
      "nchara": 12899
    },
    "fir_20.py": {
      "nlines": 242,
      "nchara": 18329
    },
    "fir_21.py": {
      "nlines": 144,
      "nchara": 13685
    },
    "fir_25.py": {
      "nlines": 74,
      "nchara": 6426
    },
    "fir_29.py": {
      "nlines": 119,
      "nchara": 9361
    },
    "fir_30.py": {
      "nlines": 439,
      "nchara": 34069
    },
    "fir_24.py": {
      "nlines": 123,
      "nchara": 8968
    },
    "fir_5.py": {
      "nlines": 143,
      "nchara": 12738
    },
    "fir_7.py": {
      "nlines": 215,
      "nchara": 13964
    },
    "fir_28.py": {
      "nlines": 50,
      "nchara": 4219
    },
    "fir_22.py": {
      "nlines": 37,
      "nchara": 2671
    },
    "fir_27.py": {
      "nlines": 33,
      "nchara": 2733
    },
    "fir_26.py": {
      "nlines": 40,
      "nchara": 4039
    },
    "fir_15.py": {
      "nlines": 435,
      "nchara": 25111
    },
    "sec_7.py": {
      "nlines": 5,
      "nchara": 683
    },
    "sec_10.py": {
      "nlines": 162,
      "nchara": 16542
    },
    "sec_2.py": {
      "nlines": 21,
      "nchara": 1792
    },
    "sec_12.py": {
      "nlines": 75,
      "nchara": 5423
    },
    "sec_6.py": {
      "nlines": 6,
      "nchara": 720
    },
    "sec_9.py": {
      "nlines": 50,
      "nchara": 5532
    },
    "sec_27.py": {
      "nlines": 98,
      "nchara": 7517
    },
    "sec_1.py": {
      "nlines": 21,
      "nchara": 2388
    },
    "sec_8.py": {
      "nlines": 6,
      "nchara": 671
    },
    "sec_17.py": {
      "nlines": 20,
      "nchara": 1373
    },
    "sec_26.py": {
      "nlines": 147,
      "nchara": 13678
    },
    "sec_29.py": {
      "nlines": 111,
      "nchara": 8876
    },
    "sec_15.py": {
      "nlines": 48,
      "nchara": 5194
    },
    "sec_20.py": {
      "nlines": 80,
      "nchara": 6910
    },
    "sec_21.py": {
      "nlines": 61,
      "nchara": 3753
    },
    "sec_24.py": {
      "nlines": 127,
      "nchara": 9000
    },
    "sec_25.py": {
      "nlines": 52,
      "nchara": 3712
    },
    "sec_28.py": {
      "nlines": 52,
      "nchara": 3472
    },
    "sec_30.py": {
      "nlines": 147,
      "nchara": 13371
    },
    "sec_14.py": {
      "nlines": 14,
      "nchara": 1650
    },
    "sec_16.py": {
      "nlines": 42,
      "nchara": 3889
    },
    "sec_19.py": {
      "nlines": 141,
      "nchara": 7667
    },
    "sec_22.py": {
      "nlines": 163,
      "nchara": 11450
    },
    "sec_23.py": {
      "nlines": 37,
      "nchara": 2815
    },
    "sec_11.py": {
      "nlines": 33,
      "nchara": 2506
    },
    "sec_18.py": {
      "nlines": 28,
      "nchara": 2630
    },
    "sec_4.py": {
      "nlines": 39,
      "nchara": 2994
    },
    "sec_5.py": {
      "nlines": 39,
      "nchara": 3301
    },
    "sec_13.py": {
      "nlines": 67,
      "nchara": 4194
    },
    "thr_17.py": {
      "nlines": 83,
      "nchara": 6607
    },
    "thr_10.py": {
      "nlines": 23,
      "nchara": 1770
    },
    "thr_12.py": {
      "nlines": 129,
      "nchara": 7019
    },
    "thr_18.py": {
      "nlines": 18,
      "nchara": 1742
    },
    "thr_20.py": {
      "nlines": 26,
      "nchara": 2326
    },
    "thr_27.py": {
      "nlines": 20,
      "nchara": 1723
    },
    "thr_22.py": {
      "nlines": 17,
      "nchara": 1530
    },
    "thr_26.py": {
      "nlines": 10,
      "nchara": 902
    },
    "thr_13.py": {
      "nlines": 11,
      "nchara": 894
    },
    "thr_5.py": {
      "nlines": 8,
      "nchara": 571
    },
    "thr_6.py": {
      "nlines": 40,
      "nchara": 3965
    },
    "thr_25.py": {
      "nlines": 30,
      "nchara": 2747
    },
    "thr_24.py": {
      "nlines": 8,
      "nchara": 874
    },
    "thr_11.py": {
      "nlines": 127,
      "nchara": 10367
    },
    "thr_19.py": {
      "nlines": 6,
      "nchara": 610
    },
    "thr_8.py": {
      "nlines": 10,
      "nchara": 909
    },
    "thr_7.py": {
      "nlines": 11,
      "nchara": 1738
    },
    "thr_9.py": {
      "nlines": 12,
      "nchara": 1074
    }
  }
}